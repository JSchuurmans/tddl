{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/bigdata/f_mnist/logs/baselines/1644945876/rn18_18_dNone_256_adam_l0.001_g0.1_sTrue')\n",
    "\n",
    "layer = 28\n",
    "logdir = path / f'features_layer{layer}_seed{seed}'\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "baseline_path = Path('/bigdata/f_mnist/logs/baselines/1644945876/rn18_18_dNone_256_adam_l0.001_g0.1_sTrue/cnn_best.pth')\n",
    "baseline_model = torch.load(path / \"cnn_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for path in paths:\n",
    "    with open(path / 'results_approximation_error.json') as json_file:\n",
    "        result = json.load(json_file)\n",
    "\n",
    "    with open(path / 'results_feature_metrics.json') as json_file:\n",
    "        feature_result = json.load(json_file)\n",
    "    \n",
    "    result.update(feature_result['mean'])\n",
    "    # print(result)\n",
    "    for k,v in result.items():\n",
    "        result[k] = v[0] if type(v) == list else v\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = Path(\"/bigdata/cifar10/logs/baselines/1646668631/rn18_18_dNone_128_adam_l0.001_g0.1_w0.0_sTrue\")\n",
    "with open(baseline_path/'results.json') as json_file:\n",
    "    baseline_result = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=\"rank\", y=\"relative_norm\",\n",
    "    hue=\"factorization\",\n",
    "    # style=\"rank\",\n",
    "    data=df,\n",
    "    palette=['orange', 'b'],\n",
    ")\n",
    "ax.set(xlabel='relative rank', ylabel='relative error on features: |B-F| / |B|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"relative_norm\", y=\"valid_acc_before_ft\",\n",
    "    hue=\"factorization\",\n",
    "    # style=\"rank\",\n",
    "    data=df,\n",
    "    palette=['orange', 'b'],\n",
    ")\n",
    "ax.axhline(baseline_result['best_valid_acc'], color='r')\n",
    "ax.set(xlabel='relative error on features: |B-F| / |B|', ylabel='Validation accuracy before fine-tuning')\n",
    "ax.set(ylim=(0.865, 0.925))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"relative_norm\", y=\"valid_acc\",\n",
    "    hue=\"factorization\",\n",
    "    # style=\"rank\",\n",
    "    data=df,\n",
    "    palette=['orange', 'b'],\n",
    ")\n",
    "ax.axhline(baseline_result['best_valid_acc'], color='r')\n",
    "ax.set(xlabel='relative error on features: |B-F| / |B|', ylabel='Validation accuracy after fine-tuning')\n",
    "ax.set(ylim=(0.865, 0.925))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"relative_norm\", y=\"test_acc\",\n",
    "    hue=\"factorization\",\n",
    "    # style=\"rank\",\n",
    "    data=df,\n",
    "    palette=['orange', 'b'],\n",
    ")\n",
    "ax.axhline(baseline_result['test_acc'], color='g')\n",
    "ax.set(xlabel='relative error on features: |B-F| / |B|', ylabel='Test accuracy after fine-tuning')\n",
    "ax.set(ylim=(0.865, 0.925))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:01<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tddl.features.extract import aggregate_results\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"/bigdata/cifar10/logs/decomposed/\")\n",
    "\n",
    "for nr in tqdm(os.listdir(path)):\n",
    "    path_nr = path / nr\n",
    "    dirs = [d for d in os.listdir(path_nr) if os.path.isdir(path_nr / d)]\n",
    "    path_modelname = path_nr / dirs[0]\n",
    "\n",
    "    path_features = path_modelname / 'features' \n",
    "    path_split = path_features / 'train'\n",
    "\n",
    "    try:\n",
    "        path_split.mkdir(exist_ok=False)\n",
    "    except:\n",
    "        ...\n",
    "    # files = os.listdir(path_features)\n",
    "    file_paths = [(path_features / f, path_split / f) for f in os.listdir(path_features) if not (path_features / f).is_dir()]\n",
    "    print(file_paths)\n",
    "    break\n",
    "    # aggregate_results(path_modelname / dirs[0], split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56ddcafc5f4a65ffc1eba06f4696d06fbf43c848b7a2cf81f3fe8a9e81fc5ea1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
