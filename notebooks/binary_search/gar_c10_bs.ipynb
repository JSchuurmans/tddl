{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 38,\n",
       " 'best_train_acc': 0.9749333333333333,\n",
       " 'best_valid_acc': 0.9078,\n",
       " 'best_valid_loss': 0.003568341651931405,\n",
       " 'test_acc': 0.891,\n",
       " 'test_loss': 0.004007616302371025,\n",
       " 'n_param': 557642,\n",
       " 'model_name': 'gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "baseline_path = Path(\"/bigdata/cifar10/logs/garipov/baselines/1647358615/gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue\")\n",
    "baseline_model = torch.load(baseline_path / \"cnn_best.pth\")\n",
    "with open(baseline_path/'results.json') as json_file:\n",
    "    baseline_result = json.load(json_file)\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaripovNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tddl.factorizations import number_layers, listify_numbered_layers, get_weights\n",
    "\n",
    "numbered_layers = number_layers(baseline_model)\n",
    "gar_layers = [2,4,6,8,10]\n",
    "layers = listify_numbered_layers(numbered_layers, layer_nrs=gar_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights(baseline_model, gar_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=38, maxsize=4096, currsize=38)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=8, maxsize=128, currsize=8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7787, 0.203125, tensor(0.5003, device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tddl.dbs import find_rank_given_error\n",
    "\n",
    "find_rank_given_error(layers[0][2], desired_error = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=43, maxsize=4096, currsize=43)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=10, maxsize=128, currsize=10)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=47, maxsize=4096, currsize=47)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=11, maxsize=128, currsize=11)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=50, maxsize=4096, currsize=50)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=12, maxsize=128, currsize=12)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=13, maxsize=128, currsize=13)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=11, maxsize=128, currsize=11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2735034305163528,\n",
       " [0.203125, 0.28125, 0.4375, 0.375, 0.02734375],\n",
       " tensor(0.5044, device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tddl.dbs import compress_layers_with_desired_error\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n",
    "\n",
    "compress_layers_with_desired_error(layers, desired_error=0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tddl.dbs import find_error_given_c\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "factorize_layer.cache_info() = CacheInfo(hits=6, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=11, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=15, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=18, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=26, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=13, maxsize=128, currsize=13)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=16, maxsize=128, currsize=16)\n",
      "0.2735034305163528\n",
      "0.22649656948364721\n",
      "True\n",
      "----------\n",
      "0.25\n",
      "factorize_layer.cache_info() = CacheInfo(hits=27, misses=61, maxsize=4096, currsize=61)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=14, maxsize=128, currsize=14)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=28, misses=62, maxsize=4096, currsize=62)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=15, maxsize=128, currsize=15)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=29, misses=66, maxsize=4096, currsize=66)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=16, maxsize=128, currsize=16)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=30, misses=68, maxsize=4096, currsize=68)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=17, maxsize=128, currsize=17)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=32, misses=68, maxsize=4096, currsize=68)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=18, maxsize=128, currsize=18)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=21, maxsize=128, currsize=21)\n",
      "0.6774041410080303\n",
      "-0.17740414100803026\n",
      "True\n",
      "----------\n",
      "0.375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=34, misses=69, maxsize=4096, currsize=69)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=19, maxsize=128, currsize=19)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=37, misses=71, maxsize=4096, currsize=71)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=20, maxsize=128, currsize=20)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=39, misses=74, maxsize=4096, currsize=74)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=21, maxsize=128, currsize=21)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=41, misses=76, maxsize=4096, currsize=76)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=22, maxsize=128, currsize=22)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=45, misses=76, maxsize=4096, currsize=76)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=23, maxsize=128, currsize=23)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=26, maxsize=128, currsize=26)\n",
      "0.4269280290939348\n",
      "0.07307197090606521\n",
      "True\n",
      "----------\n",
      "0.3125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=76, maxsize=4096, currsize=76)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=24, maxsize=128, currsize=24)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=48, misses=77, maxsize=4096, currsize=77)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=25, maxsize=128, currsize=25)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=51, misses=79, maxsize=4096, currsize=79)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=26, maxsize=128, currsize=26)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=54, misses=81, maxsize=4096, currsize=81)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=27, maxsize=128, currsize=27)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=58, misses=83, maxsize=4096, currsize=83)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=28, maxsize=128, currsize=28)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=31, maxsize=128, currsize=31)\n",
      "0.5415122964195667\n",
      "-0.04151229641956666\n",
      "True\n",
      "----------\n",
      "0.34375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=61, misses=84, maxsize=4096, currsize=84)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=29, maxsize=128, currsize=29)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=64, misses=86, maxsize=4096, currsize=86)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=30, maxsize=128, currsize=30)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=68, misses=87, maxsize=4096, currsize=87)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=72, misses=88, maxsize=4096, currsize=88)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=32, maxsize=128, currsize=32)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=77, misses=89, maxsize=4096, currsize=89)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=33, maxsize=128, currsize=33)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=36, maxsize=128, currsize=36)\n",
      "0.48262146681921375\n",
      "0.01737853318078625\n",
      "True\n",
      "----------\n",
      "0.328125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=81, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=34, maxsize=128, currsize=34)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=85, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=35, maxsize=128, currsize=35)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=87, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=36, maxsize=128, currsize=36)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=91, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=37, maxsize=128, currsize=37)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=96, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=38, maxsize=128, currsize=38)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=41, maxsize=128, currsize=41)\n",
      "0.5128182597437065\n",
      "-0.01281825974370654\n",
      "True\n",
      "----------\n",
      "0.3359375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=100, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=38, maxsize=128, currsize=38)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=104, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=38, maxsize=128, currsize=38)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=106, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=38, maxsize=128, currsize=38)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=111, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=10, misses=38, maxsize=128, currsize=38)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=116, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=11, misses=38, maxsize=128, currsize=38)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=2, misses=46, maxsize=128, currsize=46)\n",
      "0.5011727954494102\n",
      "-0.00117279544941018\n",
      "False\n",
      "CPU times: user 1min 3s, sys: 1min 30s, total: 2min 34s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "# with cache\n",
    "%time ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.2735034305163528\n",
      "0.22649656948364721\n",
      "True\n",
      "----------\n",
      "0.25\n",
      "0.6774041410080303\n",
      "-0.17740414100803026\n",
      "True\n",
      "----------\n",
      "0.375\n",
      "0.4269280290939348\n",
      "0.07307197090606521\n",
      "True\n",
      "----------\n",
      "0.3125\n",
      "0.5415122964195667\n",
      "-0.04151229641956666\n",
      "True\n",
      "----------\n",
      "0.34375\n",
      "0.48262146681921375\n",
      "0.01737853318078625\n",
      "True\n",
      "----------\n",
      "0.328125\n",
      "0.5128182597437065\n",
      "-0.01281825974370654\n",
      "True\n",
      "----------\n",
      "0.3359375\n",
      "0.5011727954494102\n",
      "-0.00117279544941018\n",
      "False\n",
      "CPU times: user 4min 38s, sys: 6min 42s, total: 11min 21s\n",
      "Wall time: 43.1 s\n"
     ]
    }
   ],
   "source": [
    "# no cache\n",
    "%time ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1699150/1395079106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_error_given_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/dbs.py\u001b[0m in \u001b[0;36mfind_error_given_c\u001b[0;34m(layers, desired_c, error, tollerance, max_error, min_error, max_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0machieved_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_layers_with_desired_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtollerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from tddl.dbs import find_error_given_c\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n",
    "ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "rank = 0.5\n",
    "errors = np.array([])\n",
    "for layer in layers:\n",
    "    with torch.no_grad():\n",
    "        fact_layer, error = factorize_layer(layer[2], 'tucker', rank, return_error=True)\n",
    "    errors = np.append(errors, float(error.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = errors.mean()\n",
    "max_error = errors.max()\n",
    "min_error = errors.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35240626633167266\n",
      "-0.41636698440207964\n",
      "0.9163669844020796\n",
      "True\n",
      "----------\n",
      "0.4085878893733025\n",
      "-0.1684683708838821\n",
      "0.6684683708838821\n",
      "True\n",
      "----------\n",
      "0.43667870089411737\n",
      "-0.07165294627383023\n",
      "0.5716529462738302\n",
      "True\n",
      "----------\n",
      "0.4507241066545248\n",
      "0.0006878249566724115\n",
      "0.4993121750433276\n",
      "True\n",
      "----------\n",
      "0.4577468095347285\n",
      "0.035934792027729645\n",
      "0.46406520797227035\n",
      "True\n",
      "----------\n",
      "0.4612581609748304\n",
      "0.043224653379549394\n",
      "0.4567753466204506\n",
      "True\n",
      "----------\n",
      "0.46301383669488133\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46389167455490676\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4643305934849195\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4645500529499259\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4646597826824291\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46471464754868064\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46474207998180644\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647557961983694\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647626543066508\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647660833607915\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647677978878619\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647686551513971\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476908378316467\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476929809904843\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476940525699034\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694588359613\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694856254468\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694990201895\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476950571756087\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695090662466\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695107405894\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695115777608\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951199634653\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695122056394\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951231028585\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951236260905\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695123887706\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951240185144\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124083918\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241166203\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124132971\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124141147\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241452347\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241472786\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241483005\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124148812\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149067\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149195\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241492587\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241492903\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493064\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149315\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493186\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493203\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493214\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149322\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_406364/2323451973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_error_given_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_406364/2046359927.py\u001b[0m in \u001b[0;36mfind_error_given_c\u001b[0;34m(layers, desired_c, error, tollerance, max_error, min_error, max_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_layers_with_desired_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtollerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_406364/3590224019.py\u001b[0m in \u001b[0;36mcompress_layers_with_desired_error\u001b[0;34m(layers, desired_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mparam_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfact_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_rank_given_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfact_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfact_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_406364/1777859090.py\u001b[0m in \u001b[0;36mfind_rank_given_error\u001b[0;34m(layer, desired_error, rank, tollerance, max_rank, min_rank, max_iter)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print(rank)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfact_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tucker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# print(error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_error\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/factorizations.py\u001b[0m in \u001b[0;36mfactorize_layer\u001b[0;34m(module, factorization, rank, decompose_weights, init_std, return_error, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         fact_module = tltorch.FactorizedConv.from_conv(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36mfrom_conv\u001b[0;34m(cls, conv_layer, rank, implementation, factorization, decompose_weights, decomposition_kwargs, fixed_rank_modes, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mkernel_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecomposition_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_tensors/factorized_tensors.py\u001b[0m in \u001b[0;36minit_from_tensor\u001b[0;34m(self, tensor, unsqueezed_modes, unsqueezed_init, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0munsqueezed_modes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, fixed_factors, n_iter_max, init, svd, tol, random_state, mask, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tucker_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         core, factors = partial_tucker(tensor, modes, rank=rank, n_iter_max=n_iter_max, init=init,\n\u001b[0m\u001b[1;32m    206\u001b[0m                             svd=svd, tol=tol, random_state=random_state, mask=mask, verbose=verbose)\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTuckerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mcore_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mfull_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_eigenvecs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_eigenvecs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;31m# If n_eigenvecs == min_dim, we don't want full_matrices=True, it's super slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[1;32m    126\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "find_error_given_c(layers, desired_c = 0.5, error=error, max_error=max_error, min_error=min_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48aac2a9a49c39ebb4503a423316524ff978d67c54926a1d8595b999b29100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
