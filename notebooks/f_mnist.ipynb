{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "from tddl.data.sets import DatasetFromSubset\n",
    "# from tddl.models.wrn import WideResNet\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dataset = datasets.FashionMNIST('/bigdata/f_mnist', train=True, download=True)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, (50000, 10000), generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataset = DatasetFromSubset(\n",
    "    train_dataset, transform=transform_train,\n",
    ")\n",
    "\n",
    "valid_dataset = DatasetFromSubset(\n",
    "    train_dataset, transform=transform_test,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "batch_size = 12"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "# if you change the seed, make sure that the randomly-applied transforms\n",
    "# properly show that the image can be both transformed and *not* transformed!\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "dataiter = iter(train_loader)\n",
    "dataiter_valid = iter(valid_loader)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "images, labels = dataiter.next()"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "img_grid = torchvision.utils.make_grid(images)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img * 0.3081 + 0.1307     # unnormalize\n",
    "    if type(img) == torch.Tensor:\n",
    "        npimg = img.numpy()\n",
    "    else:\n",
    "        npimg = img\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "images, labels = dataiter.next()\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB4CAYAAADrPanmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABMO0lEQVR4nO29eXBc93Xn+7m97wsa+0KAICmSomiKkiXRkmVrsZ6sLHaeR5PFL85mxxnP+NW43mRmYjs1malkXEnV2Hl2+XkyyrMT55XLduSRHTnSKLJiRaKsSCJFieK+AyDQ2NHofe/7/gDPj79ugiJANAiCvN8qFNCN7r6/++t7z+/8vud7zjFM08SCBQsWLKw/2NZ6ABYsWLBg4epgGXALFixYWKewDLgFCxYsrFNYBtyCBQsW1iksA27BggUL6xSWAbdgwYKFdYoVGXDDMD5sGMYJwzBOG4bxB80alAULFixYuDKMq9WBG4ZhB04CjwCjwD7g10zTPNq84VmwYMGChcthJR743cBp0zTPmqZZAr4HfLQ5w7JgwYIFC1eCYwXv7QHOa49HgXve7Q2xWMzcsGHDCg5pwYIFCzcf3n777RnTNNsan1+JAV8SDMP4NPBpgN7eXl588cXVPqQFCxYs3FCIRqPDiz2/EgM+BvRpj3svPFcH0zSfAJ4A2L17twlgGAY229WzN4lEgmq1imEYOBwObDYbpmlSq9UAqNVqmKaJaZo4HA4qlQqmaRIIBPB4PBiGcdnP1j/HZrO962vXEtVqVf1tt9sv+7parUapVFLn1Phem82G3W7HbrfjdDqbOsalzKU+luXOtcRvTNOkUCjgcDjUz3Kw1LlcS9xo1+VaYr3Mpdixd8NKDPg+YIthGBtZMNy/Cnx8KW+02WwEg8GrOmi1WuXJJ59kenoawzDYvHkzoVCIXC5HJpOhWq2SSCQoFAqUSiX6+/sZHR2lUCjwy7/8y2zevBm3233Zzy8UChQKBQC8Xm/TjVqzkEwmMU0Tu91+2bmsVqsUCgXGx8cpFApUq1Xsdjvz8/MUCgVqtRotLS1EIhHC4TCRSOSyC6tpmsu+0IvFIvl8HgCPx4PL5ar7f61WI5PJUKvVMAxD3fByHMMw6o6pL0KmaVIulwGoVCqcPn2atrY2YrEY0Wh0WeNMpVLUarUVXZerjVKpRC6XA8Dtdr/rNbyWkLk0DOO6nctyuUw2mwXA5XLh8XjWeESLI51O1y2Ii+GqDbhpmhXDMD4L/ANgB75lmuaRq/28paJWq/HCCy8QDAaJRqOcOHGC//W//hcOh4NQKMRrr73G9u3baW1txev10traSiqVYm5ujv3799Pf33/dXvzNxPnz5zl8+DDf+c53mJubqzPAxWIRQC1ONpsNt9tNe3s7//Jf/ku2b99OT0/PNRmnGE5A7ZoaDbc8bnyd3W5Xvzs7O6lWq1QqlWsybgsWrgTTNEmlUgA4HA78fv8l/9eh35979+7l1ltvxefzvesxVsSBm6b5LPDsSj5jmcejWq1y9OhRbrvtNoLBIPF4nPn5eWw2G/l8nlKpxMTEBE6nk/b2dmZmZigUCpimycTERJ0XdyNCzvOVV17hzTffpFQqUSwWlQcejUYJhULY7Xaq1SrDw8P4fD4CgQAzMzM8/fTTpFIpHn74YUKhEIZhXHEbtxLoxloM83LeCxd3dOKxFIvFa7ZIl8tl5dE1enJ2u12NsVwuU6vV3nXHZOHGgmmaTE1NYZomXq8Xj8dzRVopkUhw7tw5fvzjHzMwMLC6BvxaQ27O0dFRtmzZQqVSYXR0lGg0SrFYpFwu09nZSalUolqt0t7ezvT0NJVKBYfDwfT09A1nwHWvVfjuV155hb//+78nHo+ze/du/H4/8/PzpFIpurq6aGlpwTAMstks4+PjdHZ2EolEqFarPPvss+RyOfr7+9m9e/clx2o2XygGXM5DN+CN3rh43I2vNQwDn89HsVikWq2Sz+dxuVyrxm0Kh1qpVEin08zNzXHmzBk6OzvVLsFut+N2u9UNOz8/T7FYxOPxsH37dpxO55rxr6ZpqriQPt+yy1luDMHCpZA5Hh8fJ5fLEQwGiUQi+P1+dY00Oi7FYpFjx47x9NNP89xzz/HJT37yisdZV9/U/Pw8r776Kh/84AcxTZOTJ09y9OhR7r//fuLxOMeOHWPr1q1kMhl8Ph/VahWfz4dpmuTzefbu3cv8/Dx+v/+65baXC93Azc7O8rOf/YwvfvGL7N69mzvuuIOWlhY6Ojo4dOgQR44cwe12U6vVSKfTvP7667S2thKNRunv7yeZTLJnzx7S6TRf//rX+epXv4rP58PhcDTdC69UKpfQHY3GG+oD0lc6/2AwSKFQYGpqSu0eVgP5fJ7x8XG++tWvcuDAAbXjy2azVCoV3G43Dz74ILOzs0xOThKPx3E6nZTLZZxOJ/fccw+///u/z6ZNmwiHw6syxsuhUqmQy+V4/vnnOXPmDKlUCpfLRalUoqenh/e85z3s2bOnbvdgYekQpyOZTPLOO++Qy+U4evQoY2NjfPOb3+RrX/sagUCg7j2lUompqSn+6I/+iNnZWcrlMjt37rwkZrQY1pUBl1UqEAjwzjvvkEwmufXWW9m4cSOlUgnDMAiHw7S2thIMBrHb7dRqNdxuNx6Ph5aWFqampohEIkQikbU+naZibGyM1157jR/+8Ic88MADVKtV5ubmmJmZweVyUalU6O/vJx6PMz4+jmEYdHV1EQgEGBsbY25uDsMwcDqdanH7whe+wGc/+1kGBwdxuVx13v5KIXSY/ngxZYA8L1y5fmx5LLsPeb14l82COAD/+I//yOTkJBMTE8TjcU6dOoVpmsRiMQzDwOv1YrPZcDqdVCoV9Vw4HK7zuEdGRvjGN75BNBqltbWVRx99lC1btlzCkTYb+/fvZ9++fRw4cICzZ8+STCYpFotqTr1eL6FQiMHBQe68807uuuuuS3Zhq43G66tarXL27FmeeeYZzp8/j8/no1KpcO+997Jr1y6ut7wSwzAoFouk02kSiQRtbW20traqeT5w4ACRSERdK2+99Rbnzp1jdnaWdDqN1+vF7/cvme5dVwZcVBW5XE7Jxnp6eggEAkQiEXp7e5VUMBAIYLPZVOQeFgIJ6XRaqUxuJJw6dYq3336b8fFx3v/+9zMxMUEymSSbzSoeLRQKkUgkgIW58Pl8uN1uCoUCyWSSSqVCZ2cnoVAIj8fDyy+/zCOPPKLUHc2ELAYiARWDrnOEjQtFoxFvDHYu9p5mIJVKMTw8zHPPPcfc3ByJRILZ2VkV/BVPyev1qjHkcjlKpRI2m03tBmTrXCwWOXToEDabDZ/Pp+I3AwMDdHV1NX38gn379vHiiy/ys5/9TNGMohiBi7ued955h/n5eVwu1zU34AK5z2dnZ3nhhRd45plnOHPmDLFYjGw2y/z8PPPz83zgAx+gpaWl7ntYa2QyGaUSk52mOCs/+9nP8Pv9yoAfOHCAqakpKpWKcp5kEViKE7KuDLhs/fft20dXVxcDAwP09PRQKpXo6uoiGo2qYJLX68XlchGPx5VWvFAokMlklPzsRsJzzz3H0NAQAwMD2Gw2qtUq5XJZXTjiXW/bto1wOEw+n2doaAiXy6WM+MmTJ7HZbPj9fiKRCBs2bODAgQOEQiEefPDBphpHXUkiF7huwEVW2MjxC8Twy2vFQIquvZlj3bt3L9/73vd46623CIVCOJ1OfD6fGquMw+l0UiwWKRaLpFIpnE4nLpdLeY3lclnlI9hsNiqVCoVCgb/6q7/ir/7qr3j00Uf5yle+smrUxbFjxzh27Bherxe73U6pVMI0TTweD7lcDofDgdvtxuFwcObMGc6cObMq43g3SDzk3LlzPPfcc/zoRz/i1KlTas59Ph/JZJJnnnmGZ599lh07dvDZz36WXbt20d3dfV3QPqdPn2Z+fp5IJMLZs2cZGhpicnKSdDrNW2+9RSqVUo7lhg0bFCMgC2q5XF5yHGJdGfB0Os2BAweo1Wp0dHQQjUZJp9MEg0F1E586dYpwOEwoFKK9vZ1wOKyMWSgUqgss3QgwTZNSqUQ8Hmdubo6Wlhby+TxdXV1KCijzAwtqiNtuu41KpcKRI0cUNyu8G6CMpdvt5sSJEwQCAR588MGmjlmOI16KGDfdEDdy4kKn2Gy2S+iWRjWLeJYruaFN0ySZTHL8+HFGRkbUfFYqFYrFIslkUvHaouJpbW2ls7OTkZERvF6vuhFLpRJ+vx+73c7Y2BiRSASHw4HH46G/v5/p6WnGx8fZu3cv73vf+5oao5Fg/+zsrJJcZrNZkskk6XSa0dFRent7CYfD+P1+Ne+SE+F2u6+ZYczn8+zbt4/Pfe5zxONx7HY7Ho9HOSXj4+PUajVcLhe1Wo0DBw7w27/92zz66KN87nOf4/bbb19RkuDVQI/XTE9PEw6HyWQyvPbaa/z0pz9lYmKCTCaDaZq0trYqp6lSqZDNZuvoxHw+vyyGYF0ZcMMwcLlc9PX1KU7W5XLVbcNnZmYIBoN1SSJys7vdbkql0g2lFa5UKszMzOBwOAiHw3g8HgqFgsqurNVqVKtVXC4XDodDBUxqtRoOhwOv16uMqMvlUlpq4ezGx8eZmJho6pj1DLNGoyvPySKiv1a/URbTjst7dUO/UgN+6NAhRkZGKBaLOJ1OQqEQGzdu5LbbbgMWAusyd6+99hrd3d1Kk55IJEin0wD09/eza9cuYrEY//zP/8zZs2cpl8sqyO5wOEgmk7zwwgvcfffdTTPg8XicQ4cO8fLLLzM8PKwW62KxqGg0iSvBAl0UCoXI5/McP36cb33rW3zsYx8jEolck4SXcrnMiy++yNTUFOVyWamJ9NiG0+msS/5Kp9OcOXOGl156ife85z3XxIA3Xr+GYVAul/npT39Kd3c3ExMTjI2NkcvlsNvt+P1+HA4HbW1tuN1uRZuJWkl2b7lcDqfTya/8yq9cEuxcDOvOgMskiI5ZLipZxVKplNpGSzamjnw+f0MZ8HK5zPDwsEoUEJ5fLvxyuawMot1uJ5/PMzY2pgykz+dT2zahMoQTh4WMz/n5+Uv46ZWg0YCLoRaj2+hVi1cuW0zdO29M/pH3NkMuapomL774IvF4XMkGHQ4Hg4ODfOhDH8Lj8dQFArPZLBs3bqS3t5exsTFGR0eZm5sjn8/T0tLCnXfeqYJusqWWjFK73U4qlWLfvn1Nk7oWCgUOHDjAt7/9bV599VVlKHK5HMViURmPSCSC0+kkn8+TyWTwer3kcjkOHTrE4cOH2bJlC7fffvs1MeDFYpH9+/cDqN2yYRjqu2+EeLIzMzPs379/VXMWLge5dvP5PG+88QZ33HEHMzMzTE9PqzmHhWzkWCymqEGn06lKP+jfSzAY5Bd+4ReWFNReVwa8UCgQj8c5e/YsO3bsIBgM4vf7VW2UcrlMoVBQQcxyuczU1JTiK0+dOkUikbihOHDRfafTaWq1GnNzc3WeNKDmRuRNXV1d2Gw2UqlUXZDFNE1yuRzxeJwTJ05w2223EYvF8Hg8zM3NEYvFmuLdyLEEwhuLQdF1sh6PR+0IZDGW7aa+8xLjbbfbVf0bu92+ovGapsk//MM/UCqV1E5lamqKY8eOEY1G2bBhg6qtUyqV+JVf+RXK5TK5XI5PfOITBINBkskkBw8e5MiRIxw9ehS3282//tf/mmKxyIEDBxgeHlaOSaFQ4NSpU8rTXOnu4amnnuKHP/whL7zwAlu3bqVUKlEoFEin07jdbpVcFAgEGBkZUbuyiYkJxTcDfP7zn+eP//iPeeyxx9Rny/fTbJTLZQ4dOkS5XFZUmcfjUbsq4epldyn3ciqV4tChQys24Es5t8bvZnJyUqlIPvGJTzA6OsrQ0BDz8/MqE7xSqRAOh5VkU3bJ4XBYSXVHR0dVjKSjo4NisXjFxXxdGXDxDnt7ewkGgzgcDjU5Utzq0Ucfpaenh0qlwvDwMPPz89jtdrxeL4FAgLa2NqUWuBFQqVQYGhoin8+TTCYZGhri7rvvVp6oBKv0gKAYQgnqysovRiSdTpNKpRR/m81micfjRKPRpm1PxeCKNFSMpAScS6USJ06cUEk6wWDwkuQd2UaLmkUgxmklNITwk2LExEgDHD9+nNHRUbXYyM1crVa55ZZb2LFjR10pgq1bt3LnnXfS0tKCx+Ph/Pnz7Nu3j5MnT6pdkNPpxO12E41GOXv2LIODg4RCoaseP8DIyAilUomWlhZgoe6Hy+UiGAzidrvJ5XIqV0K+a5l//Z6an5/n4MGDbNu2jY0bN65oTEuFyDDF+5Y5bpSICiXULMrpcoa7MWAOFxMLX331VQ4ePEg2m+Vf/at/RTQaxev1KkMNqPnt7OykVqspdqBWq6naRKFQiLa2Nrq6upiYmCAQCFxx17uuDLh4Km63G7/fr7wfh8OhtuWdnZ1KxpVIJBQHLN6FcObNRrFYrOPoxEtYbdRqNWZmZpRhTiQSzMzM0NLSogyizh/q/LZ4MKIAKZfLSgKlB1KEN9++fXvTxy/jliCfzWajXC6TSCT40Y9+xI4dO1TCi76NFsOpBzflxnK73Zd4+ctFsVjk3LlzypDogdNsNquSdvREo76+PnXMXC5HpVIhlUoxNDRET08PuVyOQCBApVKho6OD+fl5hoaGlEZc8Pbbb6uSByvB7OwsmUxGzZMYOVH/OJ1OFSvxer11VJsUO5PrYnx8nPPnz6+qAdczXGUeq9WqkmPqtJnMvcz/ta6DIzLHeDxOLpdTdI/w9sFgkFgsRjqdVjSJZAq7XC6lvpqamlKsga6eSyQSS0q9X1dNjYXn9Xg8+P1+RaFIlFokUYlEgvHxcUZHR5VkSm7E5eJyRkD3Bmu1GolEgpGREU6dOsXs7Cz5fH5J5SBXilqtxtjYmNIkV6tV3nzzTSYnJ8nlcoo6ka19qVQik8moKoF6Ms3c3BzxeJyZmRnlncGCMTt+/HhTyxDoN2M2m6VQKKjvJ5lM8tZbb/GlL32JU6dOUS6XVW0T/aZtvIHFU5N5WAmSySTPPfecigXIwiLqnJaWFoLBoNoCAzz88MPcfffddHV1kUwmmZqaYt++ffy3//bf+MM//EP+9E//lG9961uMj4/zS7/0S9x9991qx1MqlRQF+PLLLzclcDw7O8vc3JzSfIuxFvmibiTFAEqMQQyHlKgYHx/n6NGFbokrVfdcDmKs8/m8+nzhlsVblZ2keLd6TCSXyzX1nmvMANavuZmZGQ4dOsT3v/99urq6ePjhh/n5n/95ZmZmsNlsdHZ2Mjg4qILfbrebbDarYiKyMz548CCHDh1SahuHw0G5XGZ2dnZJ1/C68sBlQmWLAgvcl5QtrVQq+Hw+UqkU8/PzeDweBgcH1XZ4bGxMUS5LQTwex+1209nZecn/xKsplUo8/fTTAOpCf/vttxkYGGDPnj3s2LGDzs7OVSuuJBeuyJPEmMsqn8/nlTRMtsWS8RUKhdQFKTePLHjlclkF2SSg1SwDrnu1gDqOPP7mN7/JX/zFX/CZz3yGT33qUwSDQaWNFWMtgb/GAKdQACuF3+/nnnvuYd++feTzebLZLKdPn+bee++lVqsxOzvLtm3b2LJlC16vl/HxcT784Q+TSqUYGRlhZmaGBx98kFtvvZWtW7eqpJR8Ps/BgweVfPMDH/gA3/nOd9i+fTudnZ2Ew2E++MEPLnrNLReJREIlaOk6e8kU1Q04oOIHYhRlvvP5PLOzs8zOzq54TO+GdDrN0NAQyWRS1YuRnZDf71elX8UZKZfL3HLLLdjtdubm5pidnSUej9PV1XVVNKlurBsXqenpaU6fPs1bb73F4OAgHR0deDweNm/ezOnTp2ltbSUUCjE7O6t2Tw899BB//dd/TV9fH5s2bWL37t3E43GVZ9HX16fm9OGHH8ZutzM9PU0qleKdd95h8+bNVxzzujLgkqYswTTxIoQWEA9Jav1u3bpV3fziOS2HQjl+/DiwcGE3BvCSySTxeJyDBw+qGsiyjd+5c6cKYL388sts3bqVzs5O2trarthQYrmQiy6bzZJOpymXy2zcuFGt8MAluw/ZkupepUAoKqnfLQZSjGwzoI9FdgeAypyNRCI89NBD/O7v/i6BQEAZbV2tItSPBCpl6y8emHiTVwuv18uuXbv4wz/8Q3V9nTx5kr6+Pl555RV+8IMfcP/997N582ZVf2ViYgKHw0FrayulUomZmRmy2SyTk5MMDg7y3ve+l0qlwte//nWSySS33XYbn/jEJ3jsscfo7OxUW+bu7u6mlHrQ6TEx4vK9w0U1kPCzspADyluX/+dyObUbWS1kMhlGR0ep1Wr09fVRLBYZHh5WC3SpVFILn5xLsVikv7+farXKxMQE4+PjqpT0ciFOmSCVSpFIJJiYmGByclKpicrlMhMTExiGQUdHB9PT05TLZVKpFG63W1VHdTgcfOpTn+LVV1/l6NGjxGIx2tvbsdvtzM7O0tHRQXt7u6JiNm7cqGzUUinAdWXA7Xa7SpXPZDJq2y3bPTFGpmni8/no7u5WXppE1ZeTyJPJZFRGlaS4yi7g3LlzvP7667z00kvs3r1beS+hUIju7m7Ffx4/fpzp6Wk2bdrErl27aG1tVfx4M5M1ZEtZrVZpaWlRuwPRzOqLj+51NxaLkvNwOBwqe1Oi/82CPo+Aonlg4abp7+/H7/dzyy23KOOjc55ilGT8utpEN04rgcvloqWlRc1ltVpl586dytsrFot0d3cTDAaVY3Ho0CH6+vpUgbChoSGmp6eZnJxUgXfTNBkfH2doaIg77riD97znPYRCIbVzaMbirnPCMkficetae/2xHluQOZXPcrlcake2mshms0xPT6tddjKZpFQq1e28AGW8DcMgn88TDAbVDnxiYoKtW7de1fFlvuT32NgYIyMjnDx5klKpRHt7Oz09PaRSKaampjAMg/b2dkVR2Ww2AoFAXb39D33oQ5w/f57JyUkSiYRaALLZLDabjb6+Pubm5piamlJlFCTHZSlYVwbc6/UyMDDAzMwM8XicYrFIR0cH/f396sus1Wp0d3fjcDjo7u7mzJkzausVi8WWlVX26KOPEo/H+R//43/gcrlIpVKk02llnHO5HLlcDsNY6Aw0MDDA9u3bVcU3h8NBV1eXKiIkiQabNm2ip6eHwcHBK46hcVvXCFnAxGMWrlACJrp3JUZQknqEhpDVXgJd4tlks9m6bXSz+XyhTcS7ktKsW7duZc+ePYq+kXPSg1x6dF8WRD2popnBagmUh8NhTNNUdWGeeuop2traCIfDdHV18f3vf5+dO3eyZ88ebrnlFn784x8zOztLS0sLr776Kj/5yU8oFovEYjHK5bLyFHV6rRkSPaHJdI+7sXCY/rfUjBeHQjxAUXh4PB5VHmA1IcIDoM5xkHGJekOPeeVyOfx+P6FQCNM0mZycvGqZcCKRYHh4mDfeeIORkREVjNy2bRvBYFBx1OfPnyeTyZDJZDh48CDT09O0tLQQjUbJ5/PcddddKlhtt9t5/PHHuf3223nyySdxOBxEIhGi0Si5XI6HHnqIRCLBd7/7XYaHh5WDuVQHZF0ZcNF15/N5HA4H1WqV8+fPk8/nmZiYYGJigscee0zVvj5x4gQzMzP4/X5V42E5HKl4rpLqLCqWSqWiOORAIEBvby8ej4cTJ07wpS99iW984xuqIFRHRwd33XUXU1NT7N27l2eeeYaOjg46Ojrw+Xx84AMfYGBggLa2SxpOA1e+kQ3DIBQKKV5Q6BJJINBLwUrxJNGXlstllaRTLpdJJpP09/erBg9jY2Ns2rQJl8vF+fPnm27AhZ4plUrMzc0xOTnJgQMHuO2229SuSfe2xQvTg8eSgCQLs/D/jX1AV4JGCZnP56Ovr49Dhw6xa9cutm3bxuOPP87jjz+uvLZUKsWv//qvE4vF6OrqwjRNvv71r/Pkk08qQ6Bfi7KANmPRKZfLjI6OqkC1GEJp5LHYvIjnLbEGkchJ0bhsNqtaFa6WkiuTySgDLtmi8t3CRfWMrsMuFAoqj8A0Taanpy9J3lsqDh8+TDwep7u7m8cff1wZU3EOarVaHTVWKBRU8pbP51N5Fn//938PLDicW7duVbuXLVu28MorryiGwGaz0dXVRaVS4dy5c9x+++309fURi8VUQPZKWFcGHC7qf2WrLwY1l8uRz+fp7e3lnXfeIZ1O10mlhBddzjZVVC+9vb309PQwPT3N/Py8kmYJzyU1nQOBALt376ZcLquyra2trWzfvp2+vj7uvvtuNYZkMsmJEyew2+1MTk6yYcMGent767aycoOLzOty8+H1epUXq6cYG4ahbkC4aPDECOpaW0Bd+A6Hg0AgQDweV9mH8t5GOuZqoCffACrzU8rcejyeOimgLhXUjakuH9THKQtSM1UzOoQqkzHOzc0xNzenHAfZQtvt9rqaI6Is6OjoIJ/PK1pO5qRZEFWUUBDigct3rS+AeoateOv6vOny00wmo3Zlq2HA9Z2VVObTVSY6XSrHlzLSMo+6emqpqFarKl+kr6+Pjo4OVS1Q/35kDL29vervTCZDW1ubuvZaW1vx+/1Kamqz2dQuS5ILRYXi8XiUk7Vt2zZaW1vp6uoiHA5z7ty5JdmpdWXARSqXy+WUpyXpvbJSdnV1qRUvFAqpWsyVSqUueLcUSO2LgYEBYrGY4qry+byqOSIyLdM06e3t5a677iKfz3PkyBFOnDjBxo0b6enpobu7m3vvvZdAIMD58+cVLyb1me12O7/1W7+lvjSbzUY0GlXn2NPTc1n5liSu6AZcblTZYgJqDmQRkWJKerBL+Dz99cKH5/N5AoHAist2NibjFAoF5ufnqdVq9Pf309bWRigUuiR9Wv+78cbS+Xwx4Ksl4ZQdTm9vryoU9fzzz3Ps2DF1E5ZKJUZGRjAMA7/fz9GjRzl37hzt7e1s3bqVs2fPqnnVz6cZEAOeSCQoFouq8JN+7cviJzSLjEE8dHlO6IhqtUoul2NmZoZAILAqXXskHwBQO2bZlejj1zX/cDFuAyhp4XJQqVQ4fPgw4XCYWCxGW1ubuh7l8+HiDqy3t1flolQqFXp6etQi19XVRWtrK9PT0xw5coTW1lZ8Pp/KDh8cHFQVUQcGBpRKTDqJeTwetaAsxU5d8VswDKMP+BugAzCBJ0zT/KphGC3A94EBYAj4ZdM0E8uauWVCjLY2NsXhCu8pFdWkMH0+n6/z5oT/XSq8Xi+33XYb77zzDqOjo0xPTyuPeHJyknPnzimP0eVykUwm1Uq+Y8cO5ubmOHfunNpqiVGWbvCnT59mfHyc8fFxXn75ZT74wQ+qC2hmZob5+Xny+Tx333033d3dl9SjkPMWBYp4AnrQUWo7O51OPB4P6XRaBVzkxkylUgSDQXVDRyIRAoEA0WhU6VhnZmYIhUJNMeDi3WSzWaLRKMPDw7z11ls88MADquDP7Oxsnfete+B6kE0+Ty543Zg3G1Ku4PDhw3z+859naGhIabk7OjrYuHEjnZ2dHDhwgA0bNlCr1ZiamiIajfLoo4/S29vLtm3b+MxnPsPU1FTTxydjlHK2skjoVJRAl17m83n1P/3+EP7fNE3VzrCvr29Vxl0oFBTtk8vlVLKULjpoXMR1es00zasy4BJY/tGPfkQkEuG+++5TgWjJNZGFTSpn9vT0qF21VG2UrFZ57X333acymuW5rVu31tVAkQB9uVzG7/czPT3NsWPHeOmll3jooYeu2LFpKZasAvw70zQPGIYRBN40DOMnwG8B/2ia5p8ahvEHwB8A/3FZM7dMiHclq7RpmkolIvK3QCCglAFSVD2fz6tCPbA8b0eyAl977TXOnj2rCvk7nU6SySRnz54lFAoRjUYVd6zz7aFQSKXVZjIZtQiFQiHe9773sWnTJhUg7O/vJxAIKF4bFm6mRCKh+lkuBomai0pHIuFST0LffmazWXWjyg0CKE9cUsYTiYRKsZfP0G/ylUK+A8lUkzlrbW1VW/7G4Ntij/W/9S3vatEnAN3d3XzkIx9hx44dxGIxqtUqGzdurAsAe71eJRnzer10dXUxODhINBpV1+9qJcSYpqkoRJkzXfGkH7cxs1XfAQpNKE5SpVLh6NGj3HXXXU0fMywUmpP+kfrCo+9S5Dpu3EnItX81FIrT6eSRRx7B6/UyOjrKwYMHmZ+fVxSt3MNieEXdJfXeheqR8chOQvJT5FwkTiVp9KJokvuqv7+fkZERzpw5oypgXglXNOCmaY4D4xf+ThuGcQzoAT4KPHDhZd8G/olrZMD1pA7R6NpsNtXrUoxQMplUxfQLhcKyOXDJjpufn1dcm9STkGSXtrY2JW2U4I7cNHrRpUqlQjKZVN04vF4vLS0tKvghOwO5iOVznE6nKhO72Lh171TKw0rijnimukpDj9ALTyxellyg4hHoyR4SwGmWAZfxyULjdrtpb29Xi+9iBnyx94uRadxurgZHKxB1glx3cs05nU6VSSg6fPnuxRgVi0W1i9MLdzUTsgPTdymNfLvQV1DfEAMuzl2jXr9arTI6OrpqKeti9PR7TMYqlGDjb1Fayf0jnvByIHkeO3fupKWlhaGhIUqlEvPz88zOznL+/Hn1Ork/4CKlGwwG1b2v2xpReckCKJRrJpMhlUqpEhVS2Gr79u1MTU2RSqXYvn37kpL/lkVkGYYxAOwGXgc6Lhh3gAkWKJbF3vNp4NMAvb29yzncJdAlT3Ax2DY7O6vqS0iBq3g8TiAQoK+vTwUzhbtcqg58bGyMbDZLuVzmkUceUcZOtjWydZZjZrNZJWUUlEolVcBdvHPdWOsRfcnWm5ubI5lM4nQ6FX8+ODh4WepHuEwJqIraQOZJeDXhv/UynVKO0zRNZfztdjuhUEgZJ/HeRJq4Usg8ihGWCooPPPAA4XC4TtbWGIzUdd66TK5RW95s46gvFlNTUzz77LMMDw8TDodV7RCpZ+HxeAiFQuzdu5dCoaD4eLmxJVGqmcXBdFSrVTKZjErEqlarysEQ4+52uy/R/zfy8eIg6QZ7bGxsVQ24eNBCXejBbrh0F1Yul4lEIoqiEJnv1WBwcJDBwUHuv/9+YCH7cmxsjCNHjjAyMqJaFAo9KYlw4k3LLkC8cjHuYrfE4RMt+Pz8vLJPbrebWCxGKBSiq6tL7QiuhCUbcMMwAsD/BD5nmmZKn1TTNE3DMBYlHE3TfAJ4AmD37t0rIiWdTietra1MTk7W1b6o1WoEg0FaW1sBVI1jnT8SY6R3SbkShAYplUqqW7RegEYuftM01U3a6A0Gg0EV0RbFQmMASeRacuHGYjHVIkpXolxu5yAGVzzw8+fPK29B9KiydRN5oXxePp9Xny8VHGWeIpGI8iiaHbQSryqXy3Hs2DEGBgZ45JFHlMHW1QaX40DlptEVO6JIaTYajYhhGBw5ckQtHI2KHhm3qHfkOTkHt9t9STCuWajVFpqZ6DsmveIgLCRM6ZmscLGyn9R2EQMEF+d6NQ24y+UiGo2yY8cOWltbVSnoyy1yIouVJsGbNm1SBdGaAYlTbd++vU4NdTmt/mLfpf5cI63XmOOhXz9SH/xKDtOS7krDMJwsGO/vmKb51IWnJw3D6DJNc9wwjC5gdSIyDdC5OfFqisUiPp9PqS0kWCcBBT27Sv8ClgrhMXVZk9wMeuBMHuvbPl36BChjLly47u1IJTK326105Fe6GOX9spg10iaSoSkKFafTqRYcoV7E2Ov6VDGIslBeaRFZDmSc5XKZsbExnE4n0WgUt9utMuqkPrh4raZpquQj/bHOheoe5GpJ3eTzZcHTv3en01mXuq5L9hpvZJ2+aDZkQdGNs77A6UoTCXqLp64vNqJSkuvG4XCobk6rgXvvvZeOjg4qlQrHjx9XksLG4zVSQZlMhi1btvDFL35R5WU0A7JoXc9YigrFAL4JHDNN8yvav54GfhP40wu//25VRtgAXbsqBrxQKCi9JVy8+MTLEepAj1gvBTqFIMcTA6nzYDKuRo5ON65w8YKQz/T7/XWBIvF8rgYynkqlQjAYVLSHeN66YZcECYklyE0tN3yj6mOxbfZKIAakWCxy+vRpWlpalExS5lZ00hJ0lbHJ2PUaKDr0RXM1jKMOWYCF/5YEGLnG5FrQA1zC2642RBevL+r6GODiLkEeC82mf99CY8lrl1ol72qwZcsWtmzZAiw0YBYpX+NipxtwWMigHBgYUA0nbiYsxQO/D/gEcMgwjLcvPPcFFgz33xqG8UlgGPjlVRmhBrnpz58/r3hEj8ejIr1SuF70y2LYhRKQgOZSPYienp6m1itZDQinKe3UZJcgkW3hP8Uj128+uTnEO49Go3UeL1zcelcqFbWQrRTi7Us7uI997GPqxpUAlr4AifxT+GS4WARLaC5dMiec42p5ioVCgdHRUdXZSI6pd1DRSxTIeAXi/a7WAlOrLRR0ky5CkuSm10WR774xMUsWGJHeCncrQfRUKrVq+nod58+fZ2pq6pIaRI0OkmEYTE9PMzMzs+pjuh6xFBXKK8DlrrSHmzucK0OSFDweD8FgEJ/PpxQdAwMDAEoLLpXthAqYnJysi7bfKJAbVrSzmzZtUsEcPX1aaAfhifW0aNM0Ve9HqYMyNTWlCjYBTUvgEGM3NzfHzMwM4XBYHUPOp1qtKl2/XgdFr5CnpzlDfZnaYDC46ttfPQYiOyDd29YXSxmXjDUej69adT9ZwPXdnVBzModizPXXyEIvOxyhXfRFSHj1xuBis5FOp5UaqxE6NWW320kkEkoifLNh3WVi6jVIAoGA8rwkmAGoJBQ9YCi1FW5U6NJJ4WL1IJbO/wvfKZlfckNLd3KRcI2OjtbdrI2BsKuFLpF8z3veo2qZC0QWJlz2YgZDxig/Mi75W3Tlqwk9CKlTJeIwNCYe6Wnh+m6i2dAXD512kLnSg8RyHsAlnYFkwZH5F6muxCFWc3eqL86Nwb7Gx9ls9oa+t98N68qAO51OOjo62LJliwp6zc/PYxiGMuwA7e3txGIxEomE4nqlqtlqZeitJQzDUDsOgL6+PhwOh2peK8ZQPEWhGOz2haaqYui8Xi+xWEw1dTh37py6iYSjb4ZXK15/R0cHn/nMZ+o+V7S1olDRA9Y6vy3pyeKJ6wG6a0F7icGW4wo1IeegQ/6vG3b9f6s1Pp2Dl/iHvqDo56GPQ/4nhl4oF6fTSX9/P6lUikKhsKrzLHJYKS97Och1YhnwdQYJZoleOBQKEYlE1E0sXKruGYmRu5G60sPFIkCSBPFf/st/WTJN1CAHVY9LpRLf/e531fPNDlyJ4V2svK98d6Iq0sfXOOalSLlWC0L1CPQ5F89V/59Oueg/q2nERZPeqMwRik2oE7vdrsojS94ALMRA5ubmVBxJvO/VzHSFpX2PMn/vVs3zRse6MuByEUplNLjYs09kg4BqDiqBLr2ucWNiwo0AWbRE/77cei+NEDqlra1NSRs7OzubHni73Gc1qg2uJzSqOHQslnC0lM9pNiROJDXrpdSqzXaxZKxpmnWp9nCxJIPcO+K1S1ai0G779+8nGo1esU7HSqAv1le6DhpzBW4mrCsDLtyhFLwRKkC4ceFRRZ0idEGxWFSUQTabvep6wdcr9ABfMwK0YsBDoZBSnjSLPlnvEMOip6YvhkZj3rhraJai592OL8lhjdmrutZbl8Tqxa3k9TabTWWbSimK8fFxVbd7taDvnC+Hxt3jzYh1ZcBTqRSvv/46hw4doq2tDb/fT7FYpLW1lc7OzjoP3OFwMDk5qVLKpbDMO++8Q1dXF93d3Wt8Ns1BrbbQIVuaOa9kd6EH2aSIlwQFh4aGbkgFz3IhCpi2trbLJoaJp/tukLrPqwG32822bdtIJpO0tLSohDBpiaardoC6OILNZlOlDOTnM5/5jFK2uN1uHnvssSV1k1oJ9CQpfcx6bRn5aYwr3ExYVwa8tbWVj33sYwQCgbqKX5Ixpqeh+v1+wuGw2uqFw2HcbjcPP/zwqpXDXAv4/X4++clPqp2I1DC5Gsj8Sbnbj3/844qeEQXCzWrAhasWL7Yx01JXoOjQve9GBcVqzWUsFuNLX/qSCuwlEgne//7309fXp5LH4KIBl/wI+Y71UsTVapXf+Z3fUc2lgWui8IHFaaZGEUJjmeGbDWtiwIX6WC7sdjuDg4M8+OCDSoYlVQLb2trUZ3o8HgYHB3ngQnGkSCSC3+/H5XKppsKXO76+6usJLdcT9DG5XC7uuecedQP6fL66JsHy+qUGhfTX3XvvvYo7Ff31cgLAjbWnr1fqSg8uLjZGnY+tVqu0trbyi7/4i5f8/3K43Nxv2bJFXb/6MRb7vpY7l36/XwWBPR4PH//4x+t6wup1NkQfro9VxlEulwkGg5dUxpMEsEboc1EsFq86jrFnzx5aW1tVLftGCax8rtTm3rp165Kvr/V2Xb4bjGtpoHbv3m2++OKL1+x4FixYsHAjIBqNvmma5nsbn78598MWLFiwcANgTSgUm812SWuw6wUiOQSWVTv8WkO6+FzPcyk1aWB9zKUFC+sNaxrEbOTdhOe6XPnId4NEpBtrNzS+Rm8ke7kxiQGXIknXI0RKaRjGintUrhZ0oyjJVVf7ObVajWQyWVewSlQzws/r6eNSS0XaXr0b9NruFiysJ6yJAZduFNKzUuRLkgmWSCTqpFjSNUZep0f8JQDjdrvx+XzEYjHlUemRcvFU29vbr1ujbGFxSOPl//Sf/hMbNmwgFAqRTqeZnJykt7eXjRs3kslkOHPmDJVKhUAgwNjYGPfffz+7d+9m06ZNa30KFiysCtbEgEv1PPm7XC4rb0kq3knPSb2foDRqkCxMKYgEF8uLJhKJuii+2+0mk8moPoWxWMwy4OsMiUSCn/3sZ3z3u9+tq/UdDodVZq0YbtM0yWaz1Go1zpw5w7lz5/j3//7fr/UpWLCwKliTIKZsdyU5QIpOiTcufKnej1G2ypLBphcv0vtM6tX3UqlUXcNTC+sTxWKReDxOqVTi7rvv5oMf/GBd+rdI4iT5wzAMNmzYQDabZXR0dI1Hb8HC6mHNrJpkfGUyGSYmJohGo+p50WnrbarEWItB1rOxRNsqulWpdz01NUVfX5/q1CPc9mrXMm6ELFaXyxbT605YuBTSpNfj8fChD32ItrY2Dh8+TDgcplAoqHZ6et3znTt3MjIysuop3xYsrCXWTIXi8/mYmJgglUrh8XhoaWlRdUqks4l00g4EAspYOxwOYrGYokWkU7rUD5aAlTQiljKy0p2kUCgoo3+tcObMGY4dO8aBAwdIJpOKAigWi0SjUTZs2MDOnTu544476oKslwvG3mwol8uqI/jXvvY1fD4fmUyGtra2usp4Ho+HbDZLPB5nfHwc0zTrGkVYsHCjYU0MeLVaZX5+njNnzhAMBtmwYQMej0dVTZNqaFJ4p1ar4fV6VTBLalC4XC71vBg7KXlpGAsd1+PxuOoqI/0znU7nqhlwUUZkMhnGx8d54oknVOf3UCjEjh071HlJVbi5uTleeOEFteC0trayZ88eNcZrvWO43pDJZBgeHubWW29l165dmKbJ3/3d36n2bwBzc3PkcjncbjebN2/mkUce4ac//anlgVu4obFmQcxMJkM2m6WlpYVIJKJ6GwKqPrGkypfLZdUtpFwuU61W1es9Ho9qWiz1j4UPzWQyTE5OEovFVGsx6RO5GtClaIlEgldffZV/+qd/Ytu2bUQiEbVjkCYTUixIDPnExASnTp3C4/HQ1dXFpk2blETuZjbgkrYdDAZVlUldGihUm06pSQGnm7XIkYWbA0s24IZh2IH9wJhpmr9gGMZG4HtADHgT+IRpmksqKlCr1RR10traSjgcrusA7/P5cDqdSl0gChTTNFUFQtH3Cs0iW2m32006nSabzTIxMUEgECCdThMMBnG5XKtW+KaxmNHx48f59re/zc6dO3n88ccplUr86Ec/4uTJkyqhZW5ujmKxyLZt29izZw933nknw8PDHD16lC9/+cv8+Z//OV6v95LGszcbpM75oUOHFCXW29uLz+dT5U/7+/vJ5/Pkcjni8Th/8zd/QzKZZNeuXWs9fAsWVg3L8cD/LXAMCF14/GfAn5um+T3DMP4C+CTw35fyQTabTfVePHPmDNPT02zdupWOjg4cDoeiScSjEm9L967EYOoetejE9+7dy5EjRwDo7+9XGvNQKFRHtzQLop7RH0tHmR//+McYhsHOnTv5nd/5Hf7yL/+SU6dOkUgkGBwc5Pd+7/dIp9McOHCAp556ilqtxoYNG/i1X/s1teu4mY03XKxPXiwWmZmZUUHfSqVCS0sLGzZsoFKpMDs7Sz6fVy3kZCdmwcKNiiUZcMMweoGfB/4r8H8ZC/v5h4CPX3jJt4H/zBINuBjlWq3GyZMnGR8f5zd+4zfqtsjiccPF5rGN5TjhogGX/09MTHDkyBHi8Th9fX243W6Vnbka3rdeZjSTyfD888+TzWY5ePAg09PTOBwOTp8+rWgAu92O3+8nm80yNjbGG2+8QSaT4eDBg+RyOeWdv/DCC0SjUQYGBlSz5rWAXvNaMhZlAX43HDp0CKfTSWdn54rHIMFr+TyXy8XMzAyAimcInQYoj9zhcFhBTAs3NJbqgf/fwH8A5G6IAfOmaYp7Mwr0LPZGwzA+DXwaoLe3Vz0vFMn58+fZu3cv/+Jf/Avy+XxducjGesCLGV+9YaxpmkxPT6t+f2K8hT/Wue9m8MqNpTOHh4f50pe+RCqVUs/7fD7GxsZIJBKMj4/T0tJCMBikWCxy4sQJfvKTn1AoFEgkEsRiMWq1GkNDQ0xPT+PxePjIRz6ikpuulSpFal4Xi0VVttc0TWZnZ6lWq7jdbrZv375oCVTpgPTMM8/Q39/PY489tuLxiMTS7XbT39+vkrOy2Sxut5tAIEA+n8fn86mFOhaLkc1mlYTUgoUbEVc04IZh/AIwZZrmm4ZhPLDcA5im+QTwBCyUkwWUF5pOpwmFQjz00EM88MADzM/PUy6XVer8lfrh6RRLNpsln8+zfft2fu/3fo/h4WGOHz9ONptVRexLpVJdo+OVFlfSx/b888/zgx/8gNOnT9Pb26sCpmLQpqenOX36NJFIhPvuu49bb72VN954g0qlgt/vp7e3t26BKZfLfOMb36BcLiup4WoY8MV6POZyOYaGhviTP/kT3nrrLVKpFNFolFAohGmabNiwgb/9279dtLlwPp/nhz/8ISdPnqSlpaVpY5TdkyiWXn/9dcbGxnjve9/L/fffz0svvYRpmqRSKebn5+no6CCTydDV1dWUMViwcD1iKR74fcBHDMP4OcDDAgf+VSBiGIbjghfeC4wt58BOp5ORkRFaWlq48847CQQCKgVaOMzGYleNkOQeMcai925vb6dQKHDixIm6JJ8rfd7Volarcfr0aY4fP057eztAHdfu8XjU2Nxut2ocIB2DpFGzHgiVhKX9+/fjdrv5whe+sCpcuE5NlctlnnrqKV5//XWOHj3K/Pw8ra2tdHR0YBgGoVCImZkZZmZmGB8fp7W1VcUnyuUyx44d49VXX2X//v10dHTU7bhWApfLRSQSIZVKcebMGXw+n9LLh8NhOjs7efvtt8nn83i9XjZu3MiuXbs4fPiw6kpjwcKNiCsacNM0Pw98HuCCB/77pmn+H4ZhPAk8zoIS5TeBv1vqQcVoZLNZYrEYvb29dY1XhWcVI345g6t7j/KZkswjvKgYmEqlovTlzYR42DMzMyQSCdWeSqdXhMMFVGkAfdGRrNTGObLZbCSTScbHx696bPrnLYZiscj8/DyJRIJkMslLL73E8ePHGRkZobW1VSmCarUaPp+PSCRCpVLhJz/5icpylRIG+/bt4/jx4yoRq1lwOByKc5dzkhiK3+8nFovh8/kolUpqoZRM3uu1UqMFC83ASnTg/xH4nmEYfwK8BXxzqW8Uw1upVLDb7UpVIgHJcrms9M+NPHhjqzBRGeiBTnmdyAzFyOrBwGYa8rm5Oebn55VWWegfGaOk0ZfLZbxer6rlIvp1Me5yzvI+qQtzNfW+GwPAcOncVatVZmZmePrpp/npT3/K8ePHcbvd+P1+tm3bVvd5UnOmvb2dYrHIH/3RHzE9PQ1AJBKhra2NtrY2YrEY3d3dJBIJZmdnlz3uxeBwOFRP03A4rFp8Sbuvzs5Otm/fzrFjx8jn86RSKU6dOkW1Wm0ajWPBwvWIZRlw0zT/CfinC3+fBe6+2gPXajXS6bTSdusGGy5SEMsxtI3FsBKJhKqXIR6ZLBKNySArOY/9+/czPj6uqidWq9W64KmMTZcb6nSJFOpq5OQdDgdzc3OcP39+WX0tJagrO5LFMDo6yle+8hVefPFFDMPA5/Mp7l7PVJWEKafTqbJinU4njz32GJlMRj3n9/splUpUq1USiQQ9PT20tbVd1Zw2wuv1MjAwQDab5YUXXlCJXsViEa/Xq1Q98/PzFAoFAOLxOFu2bCEWizVlDBYsXI9Ys+pJtVqNYrGo9NI6Py28tjxeLqRi4dTUFA6HQylUdHVLs7b4pmly7tw5kskkcFGzvFgDA90r1huzCm3UqJKx2Wzk83mV8COqmneDUC+LNcUtFovs27ePgwcPMjw8rGIQunwTUGV7ZSGQ+ZNiYlIsrFQqKWmkLAKSiOVyuZregcfj8eDz+WhpaaGnp4ehoSH1XUtGq8/nY3BwkNHRUQKBgGrsa8HCjYg160ovBkUMuFQKFOMjXuzVQLzZ+fn5Os9WeOdGWmal5xKPx1WNcqFrpIRt4zmIMdSNuaR862OSYG65XCaVSpHP5xf9vMXGk8lkVAVEOVapVCKRSPDkk0/y8ssvUygUGBwcpL29XfHYmUxGZTZKFUj5TH1XIfSPPmbTNBXd4/P51Dk0C7ITEAO+YcMGFefQFxSv10s4HCaZTOLz+a6oV7dgYT1jTWuhVCoVIpEIwWCQqakpAKVAWa7xlvdInRTZ8ot+WGqoLKYvXwlM0+TMmTOkUilliEX54HQ66/TbAt2r1akVKdalG9FarUYul2N8fFx5uO+GSqXCl7/8ZZXhKsa8UCiQy+WoVCoMDAwQjUbr6sZIETE9bd9utyt1jBhzoUwikYhK0tGNealUIpfLqZIHzYDb7aatrU1RNF6vl82bN9eV33W5XKRSKcrlsjrnQCCgyhRbsHAjYs0MeCKRqPPwMpmMMniL4UpUivy/WCwqwzQ3N0c2m1UlaYG6wv/NKhJ19uxZCoWCMtaLURiLjVf3XkX/7nQ6lUGUz8nn8xw7doy+vr53DWjG43GeffZZXnvtNbxerwr2icJFPNVgMKh06tJUo1qt1hURKxQKqjVdpVKhUCjUUULJZJJQKIRhGBQKBRV7kM5Kor1vNiqVCtPT07z88ssAandVrVa55557CIfD9PX1cejQIe677z76+/ubPgYLFq4XrFk52dnZWUWbyHPifS/XOxb1iWztJVmnUCgoA64nB0Fzt/eiKrlc04bLpfE3Zpnquw5dilitVhkdHb1iXY9sNsuxY8dIJpMqEOnxePB4PKpNnXj3jSoZQL1G6B8JZOqNngXyGpFIyo5BiowtZbewVNjtdlUTXo4hKiM5htPpJJVKUSwWVUav1+u1MjEt3NBYMwM+OTl5SVlX3bi+m/d2OUpCgn6SUi2KCJGg6dRJM2uiBINBUqkUpVJp0dR/PUipG3hd+iiadzGokr4uPxMTE1csg1utVtX5i7HWPeNGekrGJwsQXPwO9Boz8lpd3y20lBhV8d4lCUkCmc2Aw+EgGo2qYmaBQIBwOFyX0OPxeBgfH1eBa5/P19QxWLBwPWLNutIPDQ3R1tZGOBwG6uVvcDHYJ2gM8C0Gm82maow7nU66u7t56623CIfDqua4cLjNrAmez+eVMX43L1u8dDFyuu5bV97ozZrlMyYnJy/xghuxefNm/uzP/oynn36al156iaNHjzI0NKSCql6vl1gspvhvMegyFkBJIaUzkmSR2mw21f1IOiDJY4HsdDweD+FwuGn0hcvloqWlhVBooRBmPB5n3759wMXdVzgcVuUUhC4TzbgFCzcq1swDn56eZmBgQGmFxYAIL91opK/kketBTNM0cTqdtLW1kUwmVacfuGj8r2QMlwLxlKVKn4xbKAtR08j4DcNQC8hi/LveF1OXPQKMjY1dkUKx2+34fD4+/OEP8773vY9cLkcul2N0dFQVfzpz5gzZbFaNQ4K7YoyFdxfjLlSJqHl0D75QKNRx9ULXhMNhYrEYHR0dK55jgdQ5cblchMNhtmzZooKlprnQib6vrw+73U53dzenT5/G5/NdVRKUBQvrBWsmIywWi3R1dREMBq/YsGApwcZG79dutxMMBpWxakQzOHC9TrWMQbItFxu7rkFfjMIRIylGX9fCT0xMXNGAi4Y+FosRi8UU/XLLLbeoZgenTp1ienpaVRksFouq65EoeMRQS5aoUCPC08sioy9cNptNGfBIJEI0Gm2qAZf5ECloMBisK5VQKpVwu91qB5BOp61G0RZueKzJ1S286datWwkEApTLZeXFidFZThLIYlXxbDYbwWCQc+fOKTWF1BjXa5OsBJVKRVVQlLEXCgW6uroolUpks1mgvjmxeNa6kZb/OxwOCoWC+r/OkUsp1+VA3huJRFQZgU2bNq34vJcKCSiuFHIe0WhUdV/K5XJ1zS5qtRrj4+OqNMPIyIhqxWfBwo2KNePAR0dHaW1tVXptSRwRL09XR4jh0wNs8rz0yQSUkZaGwcKLirZaFBKVSqUpGmUx4JVKRfHb+XyetrY2RUmIPBKo4971BUuez+fzRKNRarUa8XhcGXC73U5LS8tN700KN+/z+fD7/fh8PrXbsdlsPPbYY2SzWQ4fPkwsFqOtrc0KYlq4obEmFqFSqXDu3Lm6RJfG+t9ivBdTjegqFV1ZIpyzLAKhUIh8Ps/IyAijo6P4fD51jGYYw1qtRjabrVOLiPd8ObWL7kXrpVz19Ho9W7RRoXKzwjAMFZCsVqukUikikYhaHKV0Qi6XUzs4oYIsWLhRsWYGfG5uTqVCSwafrgN/NzWHPNaNuGylJXPQbrfT29tLMBgkk8kwPDxMNBrFbrfj9XqbkqEnHnZjhme5XFaSQp2bf7csUDH+je8RiNKlWclH6xFScqFSqZBKpdi0aZP63h0OB4cOHSKfzxMKheq07hYs3KhYEwMeCAT4xV/8xbr2WOVyua6RQyN9ohs+CaotViYVYGJignA4zEMPPcQ999xDoVBQ3LIUXZLEkJWgXC4zMzPD9PS0asxQq9Xwer0qwOnxeFQmpM7ri6ctlQjhIkXgcrnU7kHOWc5B+oXejEilUirIK3pv8bKDwSBOp1Nllfp8vpu+GbSFGx9rcoV3dHTwla98hVAoRKlUIplM4vV6FZUghq0xsHk5iNGvVCoquUOel+JG7e3tdHZ20tHRQTgcbgo3Wq1WSafTAHWUx7Zt22hvbyeTydQtNI28fuNipdMonZ2dytsE6rqu36yQWi2GYdDR0cGePXtoa2tTgdqBgQE6OzvJ5/P4/f6bPmZg4cbHmhhwp9Op2m1VKpW6pgZAnfHWefHF0KhAER5cVBxS31oCmFJvpBnemRSf0su8ejweNmzYoBrt6mNslBA2Lky6blzklXpQV1LFb1ZIMwxYoEx0Iy015WWuvV6v5YFbuOGxple41HBerAjUuxnxRoOu65N1bXZjOnqzg4CVSoV0Oq24dbvdTmtrK9u2bSMSidR5y3qgUu88pJ+LzWZTC5rU49Y570wmc1MbcNk5iVxzampK0VNer5d0Os3c3JwqXtbseuQWLFxvWNM9piSQCK8rBkuXBS6m5tDpikYPVhoJiLJFePXVCGiVSiVmZ2dVES2n08mOHTvUAqIvSpIlCvV9P/XsRynfms/nyWQyKgtSzndubu6mpVAMw6jr3BQMBuno6FDfr0hS9QQkywO3cKNjSVe4YRgRwzB+YBjGccMwjhmG8T7DMFoMw/iJYRinLvxetqxDPCRJehGvWcq96g0JdOht0eT14t0Wi0VVyW+1b2DhwIXLttvtdHV1MTY2RjabVUW1dCMudI5kLuoSQanqp1dVFH05XNyx3Kzw+/0qNT6RSCilj2mazMzMqB2KdAWyPHALNzqWauG+CjxnmuY2YBdwDPgD4B9N09wC/OOFx8uCVMiT5BrdcF8OutZaXivGW35LKdXVNuCSECTevdPppL29nXg8TjqdVmoUuMjPS9EqSTrSszOBujR2MfSygEmC0s0KCW6LDly/TrLZrDLgpmmqvqgWLNzIuCKFYhhGGPgA8FsApmmWgJJhGB8FHrjwsm+z0Oz4Py7n4KFQCJ/PR1tbm7r5FgvyNRr2xhrPegXD9vb2ujKjq4lGGaPb7aarq4u9e/cyPDysOG19FyGNJsQQ6wlLshiYpkk+n1dyQVGipNNp1bT3ZoNpmoyOjjI8PMz8/DymadLR0aF2Md3d3aotXDabZfPmzXUNQyxNuIUbEcaVAnuGYdwOPAEcZcH7fhP4t8CYaZqRC68xgIQ8vhx2795tShd0vSa17oE2ct2Nz1043mUfN2rElwtd6nelz8nn8yQSCbXwOBwOgsGgKhQlKfaN0GmSxSDzoxv3Wq2mFjy/31+X0Xm9eprLmculfNb4+HhdNUcx4DabjWQySSaTqQtqRiKRJTV0aGZpYQsWVgPRaPRN0zTf2/j8UoKYDuAO4P80TfN1wzC+SgNdYpqmaRjGoiuBYRifBj4NKOmgbrAFzaQ7mtVt50qf43K5Fq24JzXOVwuNc7ceDFAzvpPLVTes1WoEg8FFa3+vh7mxYOFqsRSrOQqMmqb5+oXHP2DBoE8ahtEFcOH31GJvNk3zCdM032ua5ntbW1ubMWYLFixYsMASKBQAwzD2Ap8yTfOEYRj/GfBf+NesaZp/ahjGHwAtpmn+hyt8zjSQBWZWNuwbDq1Yc9IIa04uhTUnl+JmmZN+0zTbGp9cqgG/Hfh/ARdwFvhtFrz3vwU2AMPAL5umObeEz9q/GJdzM8Oak0thzcmlsObkUtzsc7KkRB7TNN8GFpukh5s6GgsWLFiwsGRYqWoWLFiwsE6xFgb8iTU45vUOa04uhTUnl8Kak0txU8/JkjhwCxYsWLBw/cGiUCxYsGBhneKaGXDDMD5sGMYJwzBOX5Ad3pQwDGPIMIxDhmG8bRjG/gvPrbgw2HqDYRjfMgxjyjCMw9pzi86DsYCvXbh23jEM4461G/nq4TJz8p8Nwxi7cL28bRjGz2n/+/yFOTlhGMajazPq1YVhGH2GYbxoGMZRwzCOGIbxby88f1NfK4JrYsANw7AD/w/wGHAr8GuGYdx6LY59neJB0zRv1+RPKy4Mtg7x18CHG5673Dw8Bmy58PNp4L9fozFea/w1l84JwJ9fuF5uN03zWYAL98+vAjsuvOcbF+6zGw0V4N+ZpnkrsAf4NxfO/Wa/VoBr54HfDZw2TfPshWJY3wM+eo2OvR7wURYKgnHh9y+t3VCuDUzTfBlozBu43Dx8FPgbcwGvARHJAr6RcJk5uRw+CnzPNM2iaZrngNMs3Gc3FEzTHDdN88CFv9MsVELt4Sa/VgTXyoD3AOe1x6MXnrsZYQLPG4bx5oU6MQAdpmmOX/h7Ali86MeNj8vNw81+/Xz2Ah3wLY1eu+nmxDCMAWA38DrWtQJYQcy1wPtN07yDha3evzEM4wP6P80FWdBNLw2y5kHhvwObgNuBceDLazqaNYJhGAHgfwKfM00zpf/vZr5WrpUBHwP6tMe9F5676WCa5tiF31PAD1nY9i6pMNhNgMvNw017/ZimOWmaZtU0zRrwl1ykSW6aOTEMw8mC8f6OaZpPXXjaula4dgZ8H7DFMIyNhmG4WAi+PH2Njn3dwDAMv2EYQfkb+N+AwyzMxW9eeNlvAn+3NiNcc1xuHp4GfuOCwmAPkNS2zzc0Gvjb/52F6wUW5uRXDcNwG4axkYWg3RvXenyrjQu9Br4JHDNN8yvav6xrBS42VFjtH+DngJPAGeCL1+q419MPMAgcvPBzROYBiLEQST8FvMBCZcc1H+8qz8V3WaAEyizwlJ+83DwABgsqpjPAIeC9az3+azgn/9+Fc36HBePUpb3+ixfm5ATw2FqPf5Xm5P0s0CPvAG9f+Pm5m/1akR8rE9OCBQsW1imsIKYFCxYsrFNYBtyCBQsW1iksA27BggUL6xSWAbdgwYKFdQrLgFuwYMHCOoVlwC1YsGBhncIy4BYsWLCwTmEZcAsWLFhYp/j/Ab45on+0NO1IAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "summary(model, (1,28,28))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             576\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "       BatchNorm2d-3           [-1, 64, 28, 28]             128\n",
      "            Conv2d-4           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 28, 28]             128\n",
      "            Conv2d-6           [-1, 64, 28, 28]          36,864\n",
      "       PreActBlock-7           [-1, 64, 28, 28]               0\n",
      "       BatchNorm2d-8           [-1, 64, 28, 28]             128\n",
      "            Conv2d-9           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 28, 28]             128\n",
      "           Conv2d-11           [-1, 64, 28, 28]          36,864\n",
      "      PreActBlock-12           [-1, 64, 28, 28]               0\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "           Conv2d-14          [-1, 128, 14, 14]           8,192\n",
      "           Conv2d-15          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-16          [-1, 128, 14, 14]             256\n",
      "           Conv2d-17          [-1, 128, 14, 14]         147,456\n",
      "      PreActBlock-18          [-1, 128, 14, 14]               0\n",
      "      BatchNorm2d-19          [-1, 128, 14, 14]             256\n",
      "           Conv2d-20          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 14, 14]             256\n",
      "           Conv2d-22          [-1, 128, 14, 14]         147,456\n",
      "      PreActBlock-23          [-1, 128, 14, 14]               0\n",
      "      BatchNorm2d-24          [-1, 128, 14, 14]             256\n",
      "           Conv2d-25            [-1, 256, 7, 7]          32,768\n",
      "           Conv2d-26            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-27            [-1, 256, 7, 7]             512\n",
      "           Conv2d-28            [-1, 256, 7, 7]         589,824\n",
      "      PreActBlock-29            [-1, 256, 7, 7]               0\n",
      "      BatchNorm2d-30            [-1, 256, 7, 7]             512\n",
      "           Conv2d-31            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-32            [-1, 256, 7, 7]             512\n",
      "           Conv2d-33            [-1, 256, 7, 7]         589,824\n",
      "      PreActBlock-34            [-1, 256, 7, 7]               0\n",
      "      BatchNorm2d-35            [-1, 256, 7, 7]             512\n",
      "           Conv2d-36            [-1, 512, 4, 4]         131,072\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      PreActBlock-40            [-1, 512, 4, 4]               0\n",
      "      BatchNorm2d-41            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-42            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-43            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      PreActBlock-45            [-1, 512, 4, 4]               0\n",
      "           Linear-46                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,170,122\n",
      "Trainable params: 11,170,122\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 8.76\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 51.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def ch_dict(mod):\n",
    "    return {name: mod for name, mod in mod.named_children()}\n",
    "\n",
    "def gen_rec_child(ch):\n",
    "    def rec_child(m, ch={}):\n",
    "        for name, mod in m.named_children():\n",
    "            check = len(ch_dict(mod)) \n",
    "            check is None:\n",
    "                {}\n",
    "            {}= blah\n",
    "        \n",
    "    return rec_child(ch)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# def recur(model)\n",
    "ch = {}\n",
    "def recur(mod, ch):\n",
    "    # ch = {}\n",
    "    for name, module in mod.named_children():\n",
    "        # ch[name] = module\n",
    "        print(name)\n",
    "        ch1 = ch_dict(module)\n",
    "        print(ch)\n",
    "        if len(ch1) is None:\n",
    "            continue\n",
    "        else:\n",
    "            ch[name] = ch1\n",
    "            ch = recur(module, ch1)\n",
    "\n",
    "        return ch\n",
    "\n",
    "        # if ch1 is None:\n",
    "        #     continue\n",
    "        # for k,v in ch1.items():\n",
    "        #     ch1[k] = ch_dict(v)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "dir(model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'in_planes',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'linear',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def print_child(m):\n",
    "    ch_dict(m)\n",
    "model.apply(print_child)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "stat_dic = model.state_dict()\n",
    "\n",
    "for k, v in stat_dic.items():\n",
    "    if 'conv' in k:\n",
    "        print(k)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1.weight\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.conv2.weight\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.conv2.weight\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.conv2.weight\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.conv2.weight\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.conv2.weight\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.conv2.weight\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.conv2.weight\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.conv2.weight\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "model[\"layer1\"][0][\"conv1\"]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'ResNet' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-81f3e61fa104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layer1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conv1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import copy\n",
    "import tltorch\n",
    "from tddl.utils.prime_factors import get_prime_factors\n",
    "\n",
    "# fact_model = copy.deepcopy(model)\n",
    "\n",
    "layer_nrs = [1]\n",
    "rank = 0.5\n",
    "factorization = 'tucker'\n",
    "decompose_weights = True\n",
    "td_init = 0.02\n",
    "\n",
    "for i, (module) in enumerate(model.modules()):\n",
    "    if i in layer_nrs:\n",
    "        print(f\"{module}\")\n",
    "        # if type(module) == torch.nn.modules.conv.Conv2d:\n",
    "        #     fact_layer = tltorch.FactorizedConv.from_conv(\n",
    "        #         module, \n",
    "        #         rank=rank, \n",
    "        #         decompose_weights=decompose_weights, \n",
    "        #         factorization=factorization\n",
    "        #     )\n",
    "        # elif type(module) == torch.nn.modules.linear.Linear:\n",
    "        #     fact_layer = tltorch.FactorizedLinear.from_linear(\n",
    "        #         module, \n",
    "        #         in_tensorized_features=get_prime_factors(module.in_features), \n",
    "        #         out_tensorized_features=get_prime_factors(module.out_features), \n",
    "        #         rank=rank,\n",
    "        #         factorization=factorization,\n",
    "        #     )\n",
    "        # if td_init:\n",
    "        #     fact_layer.weight.normal_(0, td_init)\n",
    "        # fact_model._modules[name] = fact_layer\n",
    "# print(fact_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(model.conv1)\n",
    "\n",
    "print(model.layer1[0].conv1)\n",
    "print(model.layer1[0].conv2)\n",
    "print(model.layer1[1].conv1)\n",
    "print(model.layer1[1].conv2)\n",
    "\n",
    "print(model.layer2[0].conv1)\n",
    "print(model.layer2[0].conv2)\n",
    "print(model.layer2[1].conv1)\n",
    "print(model.layer2[1].conv2)\n",
    "\n",
    "print(model.layer3[0].conv1)\n",
    "print(model.layer3[0].conv2)\n",
    "print(model.layer3[1].conv1)\n",
    "print(model.layer3[1].conv2)\n",
    "\n",
    "print(model.layer4[0].conv1)\n",
    "print(model.layer4[0].conv2)\n",
    "print(model.layer4[1].conv1)\n",
    "print(model.layer4[1].conv2)\n",
    "\n",
    "print(model.linear)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'ResNet' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ccc7cc32ac3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "[layer for layer in dir(model) if \"layer\" in layer]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['_make_layer', 'layer1', 'layer2', 'layer3', 'layer4']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "layers = [\"layer\"+str(i) for i in range(1,5)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "iterate = model.children()\n",
    "\n",
    "conv0 = next(iterate)\n",
    "c0 = conv0.children()\n",
    "try:\n",
    "    print(next(c0))\n",
    "except:\n",
    "    print(\"end of the line\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "end of the line\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "layer = next(iterate)\n",
    "print(layer)\n",
    "type(layer) == type(torch.nn.modules)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "model.modules()\n",
    "model.children()\n",
    "model.named_children()\n",
    "model.named_modules()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object Module.named_children at 0x7f999f05d820>"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "i = model.named_children()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "i = model.named_children()\n",
    "\n",
    "while True:\n",
    "    name, layer = next(i)\n",
    "    print(name)\n",
    "    # print(layer)\n",
    "    print(\"-\"*10)\n",
    "    \n",
    "    if \"layer\" in name:\n",
    "        it = layer.named_children()\n",
    "        for r in range(2):\n",
    "            name, layer = next(it)\n",
    "            print(name)\n",
    "            print(layer)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1\n",
      "----------\n",
      "bn1\n",
      "----------\n",
      "layer1\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer2\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer3\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer4\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "linear\n",
      "----------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "StopIteration",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-6352f6dfa0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# print(layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "next(iteraar)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('conv1',\n",
       " Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dir(model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'in_planes',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'linear',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "itertools\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def get_children(m):\n",
    "    return {k:v for k,v in m.named_children()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "dic1 = get_children(model)\n",
    "\n",
    "\n",
    "for k,v in model.named_children():\n",
    "    dic2 = get_children(v)\n",
    "    if len(dic2) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        for k2,v2 in v.named_children():\n",
    "            dic3 = get_children(v2)\n",
    "            if len(dic3) == 0:\n",
    "                continue\n",
    "            dic2[k2] = dic3\n",
    "        dic1[k] = dic2\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "dic1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def re(m):\n",
    "    dic = get_children(m)\n",
    "    flat = []\n",
    "    for k,v in model.named_children():\n",
    "        dic[k] = v\n",
    "        ch = get_children(v)\n",
    "        if len(ch):\n",
    "            \n",
    "\n",
    "    return dic\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "for i in []:\n",
    "    print(\"shit\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = dict(model.named_children())\n",
    "    flatt_children = {}\n",
    "    if children == {}:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                flatt_children[name] = get_children(child)\n",
    "            except TypeError:\n",
    "                flatt_children[name] = get_children(child)\n",
    "    return flatt_children"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "get_children(model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "dict(model.named_children())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer2': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer3': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer4': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "def nested_children(m: torch.nn.Module):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = nested_children(child)\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "nested_children(model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "conv = out['layer1']['0']['conv1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "import tltorch\n",
    "conv = tltorch.FactorizedConv.from_conv(\n",
    "    conv, \n",
    "    rank=0.5, \n",
    "    decompose_weights=True, \n",
    "    factorization='tucker',\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-91a59090fd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtltorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m conv = tltorch.FactorizedConv.from_conv(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecompose_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36mfrom_conv\u001b[0;34m(cls, conv_layer, rank, implementation, factorization, decompose_weights, decomposition_kwargs, fixed_rank_modes, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         instance = cls(in_channels, out_channels, kernel_size, \n\u001b[0m\u001b[1;32m    293\u001b[0m                        \u001b[0mfactorization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimplementation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                        padding=padding, stride=stride, fixed_rank_modes=fixed_rank_modes, bias=bias, **kwargs)\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, order, stride, padding, dilation, bias, has_bias, n_layers, factorization, rank, implementation, fixed_rank_modes)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# tensor of values for each parametrized conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_per_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36m_ensure_array\u001b[0;34m(layers_shape, order, value, one_per_order)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.layer1[0].conv1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "nested = nested_children(model)\n",
    "conv = nested['layer1']['0']['conv1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "conv"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "conv = tltorch.FactorizedConv.from_conv(\n",
    "    conv, \n",
    "    rank=0.5, \n",
    "    decompose_weights=True, \n",
    "    factorization='tucker',\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "conv"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FactorizedConv(\n",
       "  in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "  (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "model.layer1[0].conv1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "def decompose(m):\n",
    "    if type(m) == torch.nn.modules.conv.Conv2d:\n",
    "        m = tltorch.FactorizedConv.from_conv(\n",
    "            m, \n",
    "            rank=0.5, \n",
    "            decompose_weights=True, \n",
    "            factorization='tucker',\n",
    "        )\n",
    "    return m\n",
    "\n",
    "def d_nested_children(m: torch.nn.Module):\n",
    "    m = decompose(m)\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = d_nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = d_nested_children(child)\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "d_nested_children(model)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-b3f5dbb50578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-145-d746ef73b5a1>\u001b[0m in \u001b[0;36md_nested_children\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-d746ef73b5a1>\u001b[0m in \u001b[0;36md_nested_children\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-d746ef73b5a1>\u001b[0m in \u001b[0;36md_nested_children\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-d746ef73b5a1>\u001b[0m in \u001b[0;36md_nested_children\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0md_nested_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-d746ef73b5a1>\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         m = tltorch.FactorizedConv.from_conv(\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36mfrom_conv\u001b[0;34m(cls, conv_layer, rank, implementation, factorization, decompose_weights, decomposition_kwargs, fixed_rank_modes, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mkernel_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecomposition_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tltorch/tensor_factorizations/factorized_tensor.py\u001b[0m in \u001b[0;36minit_from_tensor\u001b[0;34m(self, tensor, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, fixed_factors, n_iter_max, init, svd, tol, random_state, mask, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tucker_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         core, factors = partial_tucker(tensor, modes, rank=rank, n_iter_max=n_iter_max, init=init,\n\u001b[0m\u001b[1;32m    206\u001b[0m                             svd=svd, tol=tol, random_state=random_state, mask=mask, verbose=verbose)\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTuckerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mcore_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/tenalg/__init__.py\u001b[0m in \u001b[0;36mdynamically_dispatched_fun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             warnings.warn(f'tenalg: defaulting to core tenalg backend, {name}'\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/tenalg/core_tenalg/n_mode_product.py\u001b[0m in \u001b[0;36mmulti_mode_dot\u001b[0;34m(tensor, matrix_or_vec_list, modes, skip, transpose)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_or_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_or_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdecrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/tenalg/core_tenalg/n_mode_product.py\u001b[0m in \u001b[0;36mmode_dot\u001b[0;34m(tensor, matrix_or_vector, mode, transpose)\u001b[0m\n\u001b[1;32m     68\u001b[0m                              'Provided array of dimension {} not in [1, 2].'.format(T.ndim(matrix_or_vector)))\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_or_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# We contracted with a vector, leading to a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/base.py\u001b[0m in \u001b[0;36munfold\u001b[0;34m(tensor, mode)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0munfolded_tensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;31m# We don't use `functools.wraps` here because some of the dispatched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "type(model.conv1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "type(model.conv1) == torch.nn.modules.conv.Conv2d"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "model._modules['layer1']._modules['0']._modules['conv1']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "conv = model._modules['layer1']._modules['0']._modules['conv1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "conv2 = model._modules['layer2']._modules['0']._modules['conv1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "conv2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "conv"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "conv = conv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "model._modules['layer1']._modules['0']._modules['conv1']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "def lr(m):\n",
    "    for name, mod in m.named_children():\n",
    "        if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "            mod = tltorch.FactorizedConv.from_conv(\n",
    "                mod, \n",
    "                rank=0.5, \n",
    "                decompose_weights=True, \n",
    "                factorization='tucker',\n",
    "            )\n",
    "            m._modules[name] = mod"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "def outer(layers):\n",
    "    def lr(m):\n",
    "        # i = 0\n",
    "        for name, mod in m.named_children():\n",
    "            if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "                if name in layers:\n",
    "                    mod = tltorch.FactorizedConv.from_conv(\n",
    "                        mod, \n",
    "                        rank=0.5, \n",
    "                        decompose_weights=True, \n",
    "                        factorization='tucker',\n",
    "                    )\n",
    "                    m._modules[name] = mod\n",
    "                # i += 1\n",
    "    return lr\n",
    "\n",
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(outer(['conv1']))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): FactorizedConv(\n",
       "    in_channels=1, out_channels=64, kernel_size=(3, 3), rank=(4, 1, 1, 1), order=2, padding=[1, 1], bias=False\n",
       "    (weight): TuckerTensor(shape=(64, 1, 3, 3), rank=(4, 1, 1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(94, 47, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(94, 47, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(189, 94, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(189, 94, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(377, 189, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(377, 189, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): FactorizedConv(\n",
       "    in_channels=1, out_channels=64, kernel_size=(3, 3), rank=(4, 1, 1, 1), order=2, padding=[1, 1], bias=False\n",
       "    (weight): TuckerTensor(shape=(64, 1, 3, 3), rank=(4, 1, 1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(94, 47, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(94, 47, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=64, out_channels=128, kernel_size=(1, 1), rank=(26, 13, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(128, 64, 1, 1), rank=(26, 13, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(189, 94, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(189, 94, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=128, out_channels=256, kernel_size=(1, 1), rank=(51, 26, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(256, 128, 1, 1), rank=(51, 26, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(377, 189, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(377, 189, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=256, out_channels=512, kernel_size=(1, 1), rank=(102, 51, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(512, 256, 1, 1), rank=(102, 51, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "def outer(layers):\n",
    "    i = 0\n",
    "    def lr(m):\n",
    "        nonlocal i\n",
    "        for l, (name, mod) in enumerate(m.named_children()):\n",
    "            print(l)\n",
    "            if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "                if i in layers:\n",
    "                    print('lr')\n",
    "                    mod = tltorch.FactorizedConv.from_conv(\n",
    "                        mod, \n",
    "                        rank=0.5, \n",
    "                        decompose_weights=True, \n",
    "                        factorization='tucker',\n",
    "                    )\n",
    "                    m._modules[name] = mod\n",
    "                i+=1\n",
    "    return lr\n",
    "\n",
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(outer([1]))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "no binding for nonlocal 'i' found (<ipython-input-171-70ee9956981c>, line 2)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-171-70ee9956981c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    nonlocal i\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m no binding for nonlocal 'i' found\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "410f5a2154215048c5c4a50456f2ab7ff5c84b265e9461f7a7c2c07eed30bc24"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}