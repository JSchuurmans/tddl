{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.6/site-packages/tensorly/backend/pytorch_backend.py:200: UserWarning: You are using an old version of PyTorch (1.7.1+cu101). We recommend upgrading to a newest one, e.g. >1.8.0.\n",
      "  warnings.warn(f'You are using an old version of PyTorch ({torch.__version__}). '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import tensorly as tl\n",
    "\n",
    "from tddl.models.resnet import PA_ResNet18\n",
    "from tddl.models.resnet_lr import low_rank_resnet18\n",
    "from tddl.models.utils import count_parameters\n",
    "from tddl.factorizations import factorize_network, number_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')\n",
    "\n",
    "cuda = \"0\"\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda\n",
    "\n",
    "cpu = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = cpu\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = cpu\n",
    "os.environ[\"OMP_NUM_THREADS\"] = cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/jetzeschuurman/gitProjects/phd/tddl/notebooks/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = \"/local/jetzeschuurman/f_mnist/logs/parn_18_d0.5_256_sgd_l0.1_g0.1_sTrue/1633280228/cnn_best\"\n",
    "\n",
    "# load pretrained model\n",
    "pretrained_model = torch.load(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11170122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_param = count_parameters(pretrained_model)\n",
    "pre_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': (0,\n",
       "  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (1,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'layer1': (2,\n",
       "  {'0': (3,\n",
       "    {'bn1': (4,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (5,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (6,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (7,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (8, Sequential())}),\n",
       "   '1': (9,\n",
       "    {'bn1': (10,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (11,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (12,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (13,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (14, Sequential())})}),\n",
       " 'layer2': (15,\n",
       "  {'0': (16,\n",
       "    {'bn1': (17,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (18,\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (19,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (20,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (21,\n",
       "      {'0': (22,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (23,\n",
       "    {'bn1': (24,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (25,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (26,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (27,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (28, Sequential())})}),\n",
       " 'layer3': (29,\n",
       "  {'0': (30,\n",
       "    {'bn1': (31,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (32,\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (33,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (34,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (35,\n",
       "      {'0': (36,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (37,\n",
       "    {'bn1': (38,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (39,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (40,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (41,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (42, Sequential())})}),\n",
       " 'layer4': (43,\n",
       "  {'0': (44,\n",
       "    {'bn1': (45,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (46,\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (47,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (48,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (49,\n",
       "      {'0': (50,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (51,\n",
       "    {'bn1': (52,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (53,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (54,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (55,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (56, Sequential())})}),\n",
       " 'linear': (57, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_layers(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "1 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "2 layer1 <class 'torch.nn.modules.container.Sequential'>\n",
      "3 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "4 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "5 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "6 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "7 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.6/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "9 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "10 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "11 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "12 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "13 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "14 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "15 layer2 <class 'torch.nn.modules.container.Sequential'>\n",
      "16 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "17 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "18 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "19 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "20 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "21 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "22 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "23 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "24 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "25 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "26 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "27 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "28 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "29 layer3 <class 'torch.nn.modules.container.Sequential'>\n",
      "30 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "31 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "32 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "33 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "34 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "35 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "36 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "37 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "38 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "39 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "40 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "41 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "42 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "43 layer4 <class 'torch.nn.modules.container.Sequential'>\n",
      "44 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "45 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "46 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "47 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "48 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "49 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "50 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "51 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "52 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "53 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "54 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "55 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "56 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "57 linear <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "fact_model = copy.deepcopy(pretrained_model)\n",
    "\n",
    "# TODO: do I also consider the skip conneciton layers?\n",
    "# For now not\n",
    "layers = [5, 7, 11, 13, 18, 20, 25, 27, 32, 34, 39, 41, 46, 48, 53, 55]\n",
    "factorization='tucker'\n",
    "rank=0.5\n",
    "decompose_weights=True\n",
    "\n",
    "decomposition_kwargs = {'init': 'random'} if factorization == 'cp' else {}\n",
    "fixed_rank_modes = 'spatial' if factorization == 'tucker' else None\n",
    "\n",
    "output = factorize_network(\n",
    "    fact_model,\n",
    "    layers=layers,\n",
    "    factorization=factorization,\n",
    "    rank=rank,\n",
    "    decompose_weights=decompose_weights,\n",
    "    return_error=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': (0,\n",
       "  None,\n",
       "  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (1,\n",
       "  None,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'layer1': (2,\n",
       "  None,\n",
       "  {'0': (3,\n",
       "    None,\n",
       "    {'bn1': (4,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (5,\n",
       "      tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (6,\n",
       "      tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (7,\n",
       "      tensor(3.0027, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (8,\n",
       "      tensor(3.0027, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())}),\n",
       "   '1': (9,\n",
       "    None,\n",
       "    {'bn1': (10,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (11,\n",
       "      tensor(3.4912, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (12,\n",
       "      tensor(3.4912, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (13,\n",
       "      tensor(3.5323, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (14,\n",
       "      tensor(3.5323, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer2': (15,\n",
       "  None,\n",
       "  {'0': (16,\n",
       "    None,\n",
       "    {'bn1': (17,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (18,\n",
       "      tensor(3.6274, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (19,\n",
       "      tensor(3.6274, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (20,\n",
       "      tensor(4.5748, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (21,\n",
       "      tensor(4.5748, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (22,\n",
       "        None,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (23,\n",
       "    None,\n",
       "    {'bn1': (24,\n",
       "      None,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (25,\n",
       "      tensor(5.0622, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (26,\n",
       "      tensor(5.0622, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (27,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (28,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer3': (29,\n",
       "  None,\n",
       "  {'0': (30,\n",
       "    None,\n",
       "    {'bn1': (31,\n",
       "      None,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (32,\n",
       "      tensor(5.4734, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (33,\n",
       "      tensor(5.4734, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (34,\n",
       "      tensor(6.1732, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (35,\n",
       "      tensor(6.1732, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (36,\n",
       "        None,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (37,\n",
       "    None,\n",
       "    {'bn1': (38,\n",
       "      None,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (39,\n",
       "      tensor(6.4285, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (40,\n",
       "      tensor(6.4285, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (41,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (42,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer4': (43,\n",
       "  None,\n",
       "  {'0': (44,\n",
       "    None,\n",
       "    {'bn1': (45,\n",
       "      None,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (46,\n",
       "      tensor(4.1123, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (47,\n",
       "      tensor(4.1123, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (48,\n",
       "      tensor(1.6981, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (49,\n",
       "      tensor(1.6981, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (50,\n",
       "        None,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (51,\n",
       "    None,\n",
       "    {'bn1': (52,\n",
       "      None,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (53,\n",
       "      tensor(1.3790, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (54,\n",
       "      tensor(1.3790, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (55,\n",
       "      tensor(1.1623, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (56,\n",
       "      tensor(1.1623, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'linear': (57, None, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 (5, tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv2 (7, tensor(3.0027, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (11, tensor(3.4912, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv2 (13, tensor(3.5323, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (18, tensor(3.6274, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))\n",
      "conv2 (20, tensor(4.5748, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (25, tensor(5.0622, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv2 (27, tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (32, tensor(5.4734, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))\n",
      "conv2 (34, tensor(6.1732, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (39, tensor(6.4285, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv2 (41, tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (46, tensor(4.1123, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))\n",
      "conv2 (48, tensor(1.6981, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv1 (53, tensor(1.3790, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n",
      "conv2 (55, tensor(1.1623, device='cuda:0', grad_fn=<CopyBackwards>), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))\n"
     ]
    }
   ],
   "source": [
    "def outer(output, layers):\n",
    "    list_errors = []\n",
    "    \n",
    "    def parse_errors(d, layers, \n",
    "        # list_errors=None,\n",
    "    ):\n",
    "        nonlocal list_errors\n",
    "        # if list_errors is None:\n",
    "        #     list_errors = []\n",
    "\n",
    "        for k, v in d.items():\n",
    "            # print(v[0])\n",
    "            if isinstance(v[2], dict):\n",
    "                parse_errors(v[2], layers)\n",
    "            elif v[0] in layers:\n",
    "                print(k,v)\n",
    "                list_errors.append(v)\n",
    "\n",
    "    parse_errors(output, layers)\n",
    "    return list_errors\n",
    "\n",
    "list_errors = outer(output, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_errors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TuckerTensor(shape=(64, 64, 3, 3), rank=(39, 39, 3, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuckertensor = fact_model.layer1[0].conv1.weight\n",
    "tuckertensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx = tuckertensor.to_tensor()\n",
    "approx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = pretrained_model.layer1[0].conv1.weight\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(approx-tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_error(\n",
    "    original, \n",
    "    approximation,\n",
    "    **kwargs,\n",
    "):\n",
    "    return torch.norm(original-approximation, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "errors_path = \"/local/jetzeschuurman/f_mnist/logs/erros.json\"\n",
    "\n",
    "with open(errors_path) as f:\n",
    "    errors = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  0.16598109900951385,\n",
       "  'Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [7,\n",
       "  0.25764283537864685,\n",
       "  'Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [11,\n",
       "  0.2802920341491699,\n",
       "  'Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [13,\n",
       "  0.2963773012161255,\n",
       "  'Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [18,\n",
       "  0.26150768995285034,\n",
       "  'Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)'],\n",
       " [20,\n",
       "  0.24951869249343872,\n",
       "  'Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [25,\n",
       "  0.3009827733039856,\n",
       "  'Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [27,\n",
       "  0.3131818175315857,\n",
       "  'Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [32,\n",
       "  0.31080150604248047,\n",
       "  'Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)'],\n",
       " [34,\n",
       "  0.27235156297683716,\n",
       "  'Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [39,\n",
       "  0.31715941429138184,\n",
       "  'Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [41,\n",
       "  0.2841430604457855,\n",
       "  'Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [46,\n",
       "  0.26713722944259644,\n",
       "  'Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)'],\n",
       " [48,\n",
       "  0.16175366938114166,\n",
       "  'Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [53,\n",
       "  0.17071042954921722,\n",
       "  'Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)'],\n",
       " [55,\n",
       "  0.17444397509098053,\n",
       "  'Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "yaml_path = Path(\"/home/jetzeschuurman/gitProjects/phd/tddl/configs/factorize.yml\")\n",
    "config_data = yaml.load(yaml_path.read_text(), Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n"
     ]
    }
   ],
   "source": [
    "if config_data['decompose_weights']:\n",
    "    print('y')\n",
    "else:\n",
    "    print('else')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mpath = [2, 0, 2]\n",
    "\n",
    "def get_module(model, mpath):\n",
    "    cmod = model\n",
    "    for p in mpath:\n",
    "        cs = list(cmod.named_children())\n",
    "        cmod = cs[p][1]\n",
    "    return cmod\n",
    "\n",
    "cmod = get_module(pretrained_model, mpath[:-1])\n",
    "print(cmod)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56ddcafc5f4a65ffc1eba06f4696d06fbf43c848b7a2cf81f3fe8a9e81fc5ea1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
