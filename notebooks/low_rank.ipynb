{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "import tltorch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "path = \"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\"\n",
    "model = torch.load(path)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def decompose_conv(m):\n",
    "    return tltorch.FactorizedConv.from_conv(\n",
    "        m, \n",
    "        rank=0.5, \n",
    "        decompose_weights=True, \n",
    "        factorization='tucker',\n",
    "    )\n",
    "\n",
    "\n",
    "def nested_children(m: torch.nn.Module, layers=['conv1']):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            if type(child) == torch.nn.modules.conv.Conv2d and name in layers:\n",
    "                m._modules[name] = decompose_conv(child)\n",
    "            try:\n",
    "                output[name] = nested_children(child, layers=layers)\n",
    "            except TypeError:\n",
    "                output[name] = nested_children(child, layers=layers)\n",
    "    return output\n",
    "\n",
    "\n",
    "def low_rank_tucker(model, **kwargs):\n",
    "    out = nested_children(model, **kwargs)\n",
    "\n",
    "model = torch.load(path)\n",
    "low_rank_tucker(model, layers=[\"conv2\"])\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): FactorizedConv(\n",
      "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def low_rank(m):\n",
    "    for name, mod in m.named_children():\n",
    "        if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "            mod = tltorch.FactorizedConv.from_conv(\n",
    "                mod, \n",
    "                rank=0.5, \n",
    "                decompose_weights=True, \n",
    "                factorization='tucker',\n",
    "            )\n",
    "            m._modules[name] = mod\n",
    "model = torch.load(path)\n",
    "model.apply(low_rank)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): FactorizedConv(\n",
       "    in_channels=1, out_channels=64, kernel_size=(3, 3), rank=(4, 1, 1, 1), order=2, padding=[1, 1], bias=False\n",
       "    (weight): TuckerTensor(shape=(64, 1, 3, 3), rank=(4, 1, 1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(94, 47, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(94, 47, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=64, out_channels=128, kernel_size=(1, 1), rank=(26, 13, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(128, 64, 1, 1), rank=(26, 13, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(189, 94, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(189, 94, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=128, out_channels=256, kernel_size=(1, 1), rank=(51, 26, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(256, 128, 1, 1), rank=(51, 26, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(377, 189, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(377, 189, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=256, out_channels=512, kernel_size=(1, 1), rank=(102, 51, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(512, 256, 1, 1), rank=(102, 51, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def decompose_conv(m):\n",
    "    return tltorch.FactorizedConv.from_conv(\n",
    "        m, \n",
    "        rank=0.5, \n",
    "        decompose_weights=True, \n",
    "        factorization='tucker',\n",
    "    )\n",
    "\n",
    "def d_nested_children(m: torch.nn.Module):\n",
    "    if type(m) == torch.nn.modules.conv.Conv2d:\n",
    "        m = decompose_conv(m)\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = d_nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = d_nested_children(child)\n",
    "    return output\n",
    "\n",
    "model = torch.load(path)\n",
    "d_nested_children(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_children(m: torch.nn.Module):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = get_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = get_children(child)\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def ch_dict(mod):\n",
    "    return {name: mod for name, mod in mod.named_children()}\n",
    "\n",
    "def gen_rec_child(ch):\n",
    "    def rec_child(m, ch={}):\n",
    "        for name, mod in m.named_children():\n",
    "            check = len(ch_dict(mod)) \n",
    "            check is None:\n",
    "                {}\n",
    "            {}= blah\n",
    "        \n",
    "    return rec_child(ch)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "model.modules()\n",
    "model.children()\n",
    "model.named_children()\n",
    "model.named_modules()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<generator object Module.named_children at 0x7f999f05d820>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "i = model.named_children()\n",
    "\n",
    "while True:\n",
    "    name, layer = next(i)\n",
    "    print(name)\n",
    "    # print(layer)\n",
    "    print(\"-\"*10)\n",
    "    \n",
    "    if \"layer\" in name:\n",
    "        it = layer.named_children()\n",
    "        for r in range(2):\n",
    "            name, layer = next(it)\n",
    "            print(name)\n",
    "            print(layer)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1\n",
      "----------\n",
      "bn1\n",
      "----------\n",
      "layer1\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer2\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer3\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "layer4\n",
      "----------\n",
      "0\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      ")\n",
      "1\n",
      "PreActBlock(\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (shortcut): Sequential()\n",
      ")\n",
      "linear\n",
      "----------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "StopIteration",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-84-6352f6dfa0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m     \u001b[0;31m# print(layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def get_children(m):\n",
    "    return {k:v for k,v in m.named_children()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "dic1 = get_children(model)\n",
    "\n",
    "\n",
    "for k,v in model.named_children():\n",
    "    dic2 = get_children(v)\n",
    "    if len(dic2) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        for k2,v2 in v.named_children():\n",
    "            dic3 = get_children(v2)\n",
    "            if len(dic3) == 0:\n",
    "                continue\n",
    "            dic2[k2] = dic3\n",
    "        dic1[k] = dic2\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "dic1"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential(\n",
       "     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   )},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def re(m):\n",
    "    dic = get_children(m)\n",
    "    flat = []\n",
    "    for k,v in model.named_children():\n",
    "        dic[k] = v\n",
    "        ch = get_children(v)\n",
    "        if len(ch):\n",
    "            \n",
    "\n",
    "    return dic\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = dict(model.named_children())\n",
    "    flatt_children = {}\n",
    "    if children == {}:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                flatt_children[name] = get_children(child)\n",
    "            except TypeError:\n",
    "                flatt_children[name] = get_children(child)\n",
    "    return flatt_children"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "get_children(model)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "dict(model.named_children())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer2': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer3': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'layer4': Sequential(\n",
       "   (0): PreActBlock(\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     )\n",
       "   )\n",
       "   (1): PreActBlock(\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (shortcut): Sequential()\n",
       "   )\n",
       " ),\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "def nested_children(m: torch.nn.Module):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = nested_children(child)\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "nested_children(model)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'layer1': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()},\n",
       "  '1': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer2': {'0': {'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer3': {'0': {'bn1': BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'layer4': {'0': {'bn1': BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': {'0': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)}},\n",
       "  '1': {'bn1': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'bn2': BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "   'conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "   'shortcut': Sequential()}},\n",
       " 'linear': Linear(in_features=512, out_features=10, bias=True)}"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "nested = nested_children(model)\n",
    "conv = nested['layer1']['0']['conv1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "def decompose(m):\n",
    "    if type(m) == torch.nn.modules.conv.Conv2d:\n",
    "        m = tltorch.FactorizedConv.from_conv(\n",
    "            m, \n",
    "            rank=0.5, \n",
    "            decompose_weights=True, \n",
    "            factorization='tucker',\n",
    "        )\n",
    "    return m\n",
    "\n",
    "def d_nested_children(m: torch.nn.Module):\n",
    "    m = decompose(m)\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = d_nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = d_nested_children(child)\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "def lr(m):\n",
    "    for name, mod in m.named_children():\n",
    "        if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "            mod = tltorch.FactorizedConv.from_conv(\n",
    "                mod, \n",
    "                rank=0.5, \n",
    "                decompose_weights=True, \n",
    "                factorization='tucker',\n",
    "            )\n",
    "            m._modules[name] = mod"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "def outer(layers):\n",
    "    def lr(m):\n",
    "        # i = 0\n",
    "        for name, mod in m.named_children():\n",
    "            if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "                if name in layers:\n",
    "                    mod = tltorch.FactorizedConv.from_conv(\n",
    "                        mod, \n",
    "                        rank=0.5, \n",
    "                        decompose_weights=True, \n",
    "                        factorization='tucker',\n",
    "                    )\n",
    "                    m._modules[name] = mod\n",
    "                # i += 1\n",
    "    return lr\n",
    "\n",
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(outer(['conv1']))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): FactorizedConv(\n",
       "    in_channels=1, out_channels=64, kernel_size=(3, 3), rank=(4, 1, 1, 1), order=2, padding=[1, 1], bias=False\n",
       "    (weight): TuckerTensor(shape=(64, 1, 3, 3), rank=(4, 1, 1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(94, 47, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(94, 47, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(189, 94, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(189, 94, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(377, 189, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(377, 189, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): FactorizedConv(\n",
       "    in_channels=1, out_channels=64, kernel_size=(3, 3), rank=(4, 1, 1, 1), order=2, padding=[1, 1], bias=False\n",
       "    (weight): TuckerTensor(shape=(64, 1, 3, 3), rank=(4, 1, 1, 1))\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(94, 47, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(94, 47, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=64, out_channels=128, kernel_size=(1, 1), rank=(26, 13, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(128, 64, 1, 1), rank=(26, 13, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(97, 97, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(97, 97, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(189, 94, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(189, 94, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=128, out_channels=256, kernel_size=(1, 1), rank=(51, 26, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(256, 128, 1, 1), rank=(51, 26, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(194, 194, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(194, 194, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(377, 189, 2, 2), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(377, 189, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): FactorizedConv(\n",
       "          in_channels=256, out_channels=512, kernel_size=(1, 1), rank=(102, 51, 1, 1), order=2, stride=[2, 2], bias=False\n",
       "          (weight): TuckerTensor(shape=(512, 256, 1, 1), rank=(102, 51, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(388, 388, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(388, 388, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def outer(layers):\n",
    "    i = 0\n",
    "    def lr(m):\n",
    "        nonlocal i\n",
    "        for l, (name, mod) in enumerate(m.named_children()):\n",
    "            print(l)\n",
    "            if type(mod) == torch.nn.modules.conv.Conv2d:\n",
    "                if i in layers:\n",
    "                    print('lr')\n",
    "                    mod = tltorch.FactorizedConv.from_conv(\n",
    "                        mod, \n",
    "                        rank=0.5, \n",
    "                        decompose_weights=True, \n",
    "                        factorization='tucker',\n",
    "                    )\n",
    "                    m._modules[name] = mod\n",
    "                i+=1\n",
    "    return lr\n",
    "\n",
    "model = torch.load(\"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\")\n",
    "model.apply(outer([1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "lr\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): PreActBlock(\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import tltorch\n",
    "\n",
    "def decompose_conv(m):\n",
    "    return tltorch.FactorizedConv.from_conv(\n",
    "        m, \n",
    "        rank=0.5, \n",
    "        decompose_weights=True, \n",
    "        factorization='tucker',\n",
    "    )\n",
    "\n",
    "def low_rank_tucker(model, **kwargs):\n",
    "    i = 0\n",
    "    def nested_children(m: torch.nn.Module, layers=[1]):\n",
    "        nonlocal i\n",
    "        # print(i)\n",
    "        children = dict(m.named_children())\n",
    "        output = {}\n",
    "\n",
    "        # this counts every layer\n",
    "        # layer0 with child group0 with child conv0 will all have different numbers\n",
    "        i+=1\n",
    "        \n",
    "        if children == {}:\n",
    "            # this counts only children who don't have children themselfs\n",
    "            # causing the same number to be used for nested modules \n",
    "            # layer0 with child group0 with child conv0 will all have the same number\n",
    "            # i+=1\n",
    "\n",
    "            # if module has no children; m is last child! :O\n",
    "            return m\n",
    "        else:\n",
    "        # look for children from children... to the last child!\n",
    "            for name, child in children.items():\n",
    "                print(i, name, type(child))\n",
    "                if type(child) == torch.nn.modules.conv.Conv2d and i in layers:\n",
    "                    m._modules[name] = decompose_conv(child)\n",
    "                try:\n",
    "                    output[name] = nested_children(child, layers=layers)\n",
    "                except TypeError:\n",
    "                    output[name] = nested_children(child, layers=layers)\n",
    "        return output\n",
    "    out = nested_children(model, **kwargs)\n",
    "\n",
    "path = \"/home/jetzeschuurman/gitProjects/phd/tddl/artifacts/f_mnist/parn_18_d0.5_256_sgd_l0.1_g0.1/1629473591/cnn_best\"\n",
    "model = torch.load(path)\n",
    "low_rank_tucker(model, layers=[6])\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "2 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "3 layer1 <class 'torch.nn.modules.container.Sequential'>\n",
      "4 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "5 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "6 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "7 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "8 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "9 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "10 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "11 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "12 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "13 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "14 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "15 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "16 layer2 <class 'torch.nn.modules.container.Sequential'>\n",
      "17 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "18 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "19 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "20 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "21 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "22 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "23 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "24 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "25 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "26 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "27 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "28 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "29 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "30 layer3 <class 'torch.nn.modules.container.Sequential'>\n",
      "31 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "32 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "33 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "34 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "35 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "36 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "37 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "38 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "39 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "40 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "41 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "42 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "43 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "44 layer4 <class 'torch.nn.modules.container.Sequential'>\n",
      "45 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "46 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "47 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "48 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "49 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "50 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "51 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "52 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "53 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "54 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "55 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "56 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "57 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "58 linear <class 'torch.nn.modules.linear.Linear'>\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): FactorizedConv(\n",
      "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def func(inp, *args, default=\"value\", **kwargs):\n",
    "    print(inp)\n",
    "    print(*args)\n",
    "    print(default)\n",
    "    print(**kwargs)\n",
    "\n",
    "def func2(inp, *args, default=\"value\", **kwargs):\n",
    "    print(\"2\", inp)\n",
    "    print(\"2\", *args)\n",
    "    print(\"2\", default)\n",
    "    print(\"2\", **kwargs)\n",
    "\n",
    "    func(inp, *args, **kwargs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "func(\"a\", \"b\", default=\"v\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a\n",
      "b\n",
      "v\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "func2(\"a\", \"b\", default=\"v\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 a\n",
      "2 b\n",
      "2 v\n",
      "2\n",
      "a\n",
      "b\n",
      "value\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from tddl.factorizations import number_layers\n",
    "\n",
    "out = number_layers(model, verbose=True, exclude=['layer1'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "1 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "2 layer1 <class 'torch.nn.modules.container.Sequential'>\n",
      "2 layer2 <class 'torch.nn.modules.container.Sequential'>\n",
      "3 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "4 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "5 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "6 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "7 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "8 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "9 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "10 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "11 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "12 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "13 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "14 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "15 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "16 layer3 <class 'torch.nn.modules.container.Sequential'>\n",
      "17 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "18 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "19 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "20 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "21 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "22 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "23 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "24 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "25 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "26 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "27 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "28 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "29 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "30 layer4 <class 'torch.nn.modules.container.Sequential'>\n",
      "31 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "32 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "33 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "34 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "35 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "36 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "37 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "38 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "39 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "40 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "41 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "42 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "43 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "44 linear <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "out"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1': (1,\n",
       "  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (2,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'layer1': (3,\n",
       "  {'0': (4,\n",
       "    {'bn1': (5,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (6,\n",
       "      {'weight': (7, {'factors': (8, FactorList(\n",
       "              (factor_0): Parameter containing: [torch.cuda.FloatTensor of size 64x49 (GPU 0)]\n",
       "              (factor_1): Parameter containing: [torch.cuda.FloatTensor of size 64x49 (GPU 0)]\n",
       "              (factor_2): Parameter containing: [torch.cuda.FloatTensor of size 3x2 (GPU 0)]\n",
       "              (factor_3): Parameter containing: [torch.cuda.FloatTensor of size 3x2 (GPU 0)]\n",
       "          ))})}),\n",
       "     'bn2': (9,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (10,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (11, Sequential())}),\n",
       "   '1': (12,\n",
       "    {'bn1': (13,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (14,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (15,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (16,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (17, Sequential())})}),\n",
       " 'layer2': (18,\n",
       "  {'0': (19,\n",
       "    {'bn1': (20,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (21,\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (22,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (23,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (24,\n",
       "      {'0': (25,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (26,\n",
       "    {'bn1': (27,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (28,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (29,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (30,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (31, Sequential())})}),\n",
       " 'layer3': (32,\n",
       "  {'0': (33,\n",
       "    {'bn1': (34,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (35,\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (36,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (37,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (38,\n",
       "      {'0': (39,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (40,\n",
       "    {'bn1': (41,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (42,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (43,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (44,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (45, Sequential())})}),\n",
       " 'layer4': (46,\n",
       "  {'0': (47,\n",
       "    {'bn1': (48,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (49,\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (50,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (51,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (52,\n",
       "      {'0': (53,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (54,\n",
       "    {'bn1': (55,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (56,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (57,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (58,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (59, Sequential())})}),\n",
       " 'linear': (60, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): FactorizedConv(\n",
      "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(49, 49, 2, 2), order=2, padding=[1, 1], bias=False\n",
      "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(49, 49, 2, 2))\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "410f5a2154215048c5c4a50456f2ab7ff5c84b265e9461f7a7c2c07eed30bc24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}