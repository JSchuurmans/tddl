{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import tensorly as tl\n",
    "\n",
    "from tddl.models.utils import count_parameters\n",
    "from tddl.factorizations import factorize_network, number_layers\n",
    "from tddl.utils.hardware import select_hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')\n",
    "\n",
    "select_hardware(\n",
    "    cuda=\"0\",\n",
    "    cpu=\"2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/jetzeschuurman/gitProjects/phd/tddl/notebooks/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = \"/local/jetzeschuurman/f_mnist/logs/parn_18_d0.5_256_sgd_l0.1_g0.1_sTrue/1633280228/cnn_best\"\n",
    "\n",
    "# load pretrained model\n",
    "pretrained_model = torch.load(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11170122"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_param = count_parameters(pretrained_model)\n",
    "pre_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': (0,\n",
       "  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (1,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'layer1': (2,\n",
       "  {'0': (3,\n",
       "    {'bn1': (4,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (5,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (6,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (7,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (8, Sequential())}),\n",
       "   '1': (9,\n",
       "    {'bn1': (10,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (11,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (12,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (13,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (14, Sequential())})}),\n",
       " 'layer2': (15,\n",
       "  {'0': (16,\n",
       "    {'bn1': (17,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (18,\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (19,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (20,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (21,\n",
       "      {'0': (22,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (23,\n",
       "    {'bn1': (24,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (25,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (26,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (27,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (28, Sequential())})}),\n",
       " 'layer3': (29,\n",
       "  {'0': (30,\n",
       "    {'bn1': (31,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (32,\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (33,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (34,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (35,\n",
       "      {'0': (36,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (37,\n",
       "    {'bn1': (38,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (39,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (40,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (41,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (42, Sequential())})}),\n",
       " 'layer4': (43,\n",
       "  {'0': (44,\n",
       "    {'bn1': (45,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (46,\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (47,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (48,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (49,\n",
       "      {'0': (50,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (51,\n",
       "    {'bn1': (52,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (53,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (54,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (55,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (56, Sequential())})}),\n",
       " 'linear': (57, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_layers(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "1 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "2 layer1 <class 'torch.nn.modules.container.Sequential'>\n",
      "3 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "4 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "5 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.6/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "7 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "8 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "9 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "10 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "11 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "12 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "13 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "14 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "15 layer2 <class 'torch.nn.modules.container.Sequential'>\n",
      "16 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "17 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "18 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "19 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "20 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "21 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "22 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "23 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "24 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "25 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "26 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "27 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "28 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "29 layer3 <class 'torch.nn.modules.container.Sequential'>\n",
      "30 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "31 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "32 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "33 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "34 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "35 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "36 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "37 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "38 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "39 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "40 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "41 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "42 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "43 layer4 <class 'torch.nn.modules.container.Sequential'>\n",
      "44 0 <class 'tddl.models.resnet.PreActBlock'>\n",
      "45 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "46 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "47 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "48 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "49 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "50 0 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "51 1 <class 'tddl.models.resnet.PreActBlock'>\n",
      "52 bn1 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "53 conv1 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "54 bn2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "55 conv2 <class 'torch.nn.modules.conv.Conv2d'>\n",
      "56 shortcut <class 'torch.nn.modules.container.Sequential'>\n",
      "57 linear <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "fact_model = copy.deepcopy(pretrained_model)\n",
    "\n",
    "# TODO: do I also consider the skip conneciton layers?\n",
    "# For now not\n",
    "layers = [5, 7, 11, 13, 18, 20, 25, 27, 32, 34, 39, 41, 46, 48, 53, 55]\n",
    "factorization='tucker'\n",
    "rank=0.5\n",
    "decompose_weights=True\n",
    "\n",
    "decomposition_kwargs = {'init': 'random'} if factorization == 'cp' else {}\n",
    "fixed_rank_modes = 'spatial' if factorization == 'tucker' else None\n",
    "\n",
    "output = factorize_network(\n",
    "    fact_model,\n",
    "    layers=layers,\n",
    "    factorization=factorization,\n",
    "    rank=rank,\n",
    "    decompose_weights=decompose_weights,\n",
    "    return_error=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': (0,\n",
       "  None,\n",
       "  Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (1,\n",
       "  None,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'layer1': (2,\n",
       "  None,\n",
       "  {'0': (3,\n",
       "    None,\n",
       "    {'bn1': (4,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (5,\n",
       "      tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (6,\n",
       "      tensor(1.9908, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (7,\n",
       "      tensor(3.0027, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (8,\n",
       "      tensor(3.0027, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())}),\n",
       "   '1': (9,\n",
       "    None,\n",
       "    {'bn1': (10,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (11,\n",
       "      tensor(3.4912, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (12,\n",
       "      tensor(3.4912, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (13,\n",
       "      tensor(3.5323, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (14,\n",
       "      tensor(3.5323, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer2': (15,\n",
       "  None,\n",
       "  {'0': (16,\n",
       "    None,\n",
       "    {'bn1': (17,\n",
       "      None,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (18,\n",
       "      tensor(3.6274, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (19,\n",
       "      tensor(3.6274, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (20,\n",
       "      tensor(4.5748, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (21,\n",
       "      tensor(4.5748, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (22,\n",
       "        None,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (23,\n",
       "    None,\n",
       "    {'bn1': (24,\n",
       "      None,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (25,\n",
       "      tensor(5.0622, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (26,\n",
       "      tensor(5.0622, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (27,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (28,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer3': (29,\n",
       "  None,\n",
       "  {'0': (30,\n",
       "    None,\n",
       "    {'bn1': (31,\n",
       "      None,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (32,\n",
       "      tensor(5.4734, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (33,\n",
       "      tensor(5.4734, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (34,\n",
       "      tensor(6.1732, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (35,\n",
       "      tensor(6.1732, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (36,\n",
       "        None,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (37,\n",
       "    None,\n",
       "    {'bn1': (38,\n",
       "      None,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (39,\n",
       "      tensor(6.4285, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (40,\n",
       "      tensor(6.4285, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (41,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (42,\n",
       "      tensor(4.8250, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'layer4': (43,\n",
       "  None,\n",
       "  {'0': (44,\n",
       "    None,\n",
       "    {'bn1': (45,\n",
       "      None,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (46,\n",
       "      tensor(4.1123, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn2': (47,\n",
       "      tensor(4.1123, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (48,\n",
       "      tensor(1.6981, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (49,\n",
       "      tensor(1.6981, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      {'0': (50,\n",
       "        None,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False))})}),\n",
       "   '1': (51,\n",
       "    None,\n",
       "    {'bn1': (52,\n",
       "      None,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv1': (53,\n",
       "      tensor(1.3790, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (54,\n",
       "      tensor(1.3790, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'conv2': (55,\n",
       "      tensor(1.1623, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'shortcut': (56,\n",
       "      tensor(1.1623, device='cuda:0', grad_fn=<CopyBackwards>),\n",
       "      Sequential())})}),\n",
       " 'linear': (57, None, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "errors_path = \"/local/jetzeschuurman/f_mnist/logs/erros.json\"\n",
    "\n",
    "with open(errors_path) as f:\n",
    "    errors = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.cpu()\n",
    "\n",
    "res = fact_model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_param = [param for param in fact_model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fact_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv1.weight',\n",
       " Parameter containing:\n",
       " tensor([[[[-1.4902e-01,  2.8401e-01, -9.5481e-02],\n",
       "           [ 3.4867e-02,  4.3530e-01,  3.4018e-02],\n",
       "           [ 2.6803e-01, -2.4621e-01,  8.4183e-04]]],\n",
       " \n",
       " \n",
       "         [[[-6.1156e-01, -3.9539e-01, -5.7530e-01],\n",
       "           [ 1.2588e-01,  2.9693e-01,  2.7905e-02],\n",
       "           [ 5.0103e-01,  3.8716e-01,  7.1203e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 8.4599e-03, -1.7036e-01,  2.4733e-02],\n",
       "           [-3.3256e-02, -3.5303e-01, -5.7239e-02],\n",
       "           [ 8.7161e-02, -2.2029e-01,  2.8481e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2420e-01, -1.0697e-01, -6.0135e-02],\n",
       "           [-8.7881e-02, -2.8268e-01, -1.9654e-01],\n",
       "           [-2.5943e-02, -2.2010e-01,  7.1406e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.7283e-02,  4.7559e-01,  1.3859e-01],\n",
       "           [-4.1556e-01, -4.4288e-01,  1.9513e-02],\n",
       "           [ 3.5110e-01,  2.6675e-01, -3.7744e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1480e-01,  3.4332e-01,  2.7545e-02],\n",
       "           [ 1.6841e-01, -2.6461e-01, -2.8250e-01],\n",
       "           [ 5.1656e-02, -3.6538e-01, -3.9081e-01]]],\n",
       " \n",
       " \n",
       "         [[[-6.7691e-02, -1.3449e-02,  1.6824e-02],\n",
       "           [-1.9783e-01, -1.4528e-01, -1.1210e-01],\n",
       "           [ 4.0240e-04,  6.3331e-02,  7.5268e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.5065e-01,  9.9542e-02, -5.0099e-02],\n",
       "           [-3.7392e-01, -2.5465e-01, -2.2379e-01],\n",
       "           [-3.1833e-01,  2.1120e-01,  2.4666e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.0989e-01,  4.7885e-01,  1.1685e-02],\n",
       "           [-7.6742e-02,  2.2922e-01, -1.7794e-03],\n",
       "           [ 6.1974e-01, -6.2001e-01, -1.7135e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.7927e-01,  3.1905e-01,  2.2640e-01],\n",
       "           [-4.6562e-01, -1.7949e-01, -5.0414e-03],\n",
       "           [-2.3485e-01, -1.2152e-01,  9.6920e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.0954e-02,  8.0059e-02, -1.8142e-01],\n",
       "           [-1.7767e-01, -5.8963e-02,  4.4299e-02],\n",
       "           [-1.0967e-01, -4.5178e-02, -5.5098e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.0373e-01,  2.4278e-01,  4.3133e-02],\n",
       "           [ 5.3346e-01, -2.6075e-02, -2.4670e-01],\n",
       "           [ 1.2845e-01, -3.3719e-01,  1.1280e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.4123e-03,  4.2232e-01,  1.4429e-01],\n",
       "           [ 3.8791e-01, -6.0859e-01,  2.5307e-01],\n",
       "           [ 1.3790e-01, -5.6487e-01,  2.6370e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7457e-02,  7.6026e-03, -1.0770e-01],\n",
       "           [ 3.0340e-02, -8.8556e-02, -1.5843e-01],\n",
       "           [-4.8413e-02, -1.0758e-02, -1.6218e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1750e-01, -8.4272e-02, -4.4027e-02],\n",
       "           [ 2.9116e-02,  9.1027e-01,  3.7379e-01],\n",
       "           [-6.2657e-02,  4.0621e-01,  1.1741e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9488e-01,  4.5388e-01,  2.2998e-01],\n",
       "           [ 2.0342e-02,  5.2261e-01,  1.2667e-01],\n",
       "           [-3.3265e-01,  1.7800e-02, -2.8977e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5486e-01, -2.4235e-01,  1.2800e-02],\n",
       "           [-2.3175e-01, -6.0705e-01, -5.3220e-01],\n",
       "           [ 2.1225e-01, -1.3912e-01,  1.0169e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2385e-01, -4.3169e-01, -1.7276e-01],\n",
       "           [-2.4355e-02, -5.7512e-01, -1.4348e-01],\n",
       "           [-4.1905e-04, -1.8068e-01,  2.9516e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.9850e-02,  1.4088e-01, -5.9686e-02],\n",
       "           [ 1.6394e-01,  1.9054e-01, -3.3154e-01],\n",
       "           [-9.0346e-02, -2.0491e-01, -3.4138e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5953e-01,  2.1703e-01,  6.1721e-02],\n",
       "           [-2.6287e-01, -2.5322e-01,  8.4744e-02],\n",
       "           [-1.6077e-01, -3.3591e-01,  1.2555e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.8378e-01, -1.7013e-01,  3.7781e-01],\n",
       "           [ 6.1115e-01,  1.1097e+00, -2.8164e-03],\n",
       "           [-2.0076e-01, -6.8013e-01, -5.7769e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.9924e-01,  1.0602e-01,  2.0868e-02],\n",
       "           [-2.5698e-01,  3.9136e-01, -1.5295e-01],\n",
       "           [-9.3320e-02, -1.7501e-01,  1.4571e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.2294e-01,  2.2727e-01, -3.2359e-01],\n",
       "           [ 5.1498e-01,  2.6030e-01, -4.2726e-01],\n",
       "           [ 4.8175e-01, -3.3656e-01, -6.7776e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.3985e-01, -1.3165e-01, -2.1193e-02],\n",
       "           [ 2.1887e-01, -7.6892e-02, -2.7596e-01],\n",
       "           [ 3.7541e-01,  3.0339e-01, -3.0974e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.2639e-01, -1.3864e-01,  1.4724e-02],\n",
       "           [-3.0420e-01, -4.9357e-01,  2.6519e-01],\n",
       "           [-2.3111e-01,  5.3728e-01,  1.2253e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.6198e-01,  1.2383e-01, -2.0274e-01],\n",
       "           [-2.2837e-01,  4.3233e-01, -2.8202e-01],\n",
       "           [-1.7905e-02,  8.5675e-02, -2.2987e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.9473e-01, -2.4385e-02, -5.2437e-02],\n",
       "           [-3.6310e-01,  2.9724e-01, -9.1116e-02],\n",
       "           [-5.1656e-02,  7.9288e-02,  3.0426e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7369e-01, -8.5487e-02, -5.6788e-02],\n",
       "           [-7.4040e-02,  5.8805e-01, -6.1230e-02],\n",
       "           [-1.9303e-01,  1.5409e-01, -1.9942e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8368e-02, -3.5762e-01,  5.1346e-02],\n",
       "           [-1.9331e-02, -6.0348e-01, -1.5779e-01],\n",
       "           [ 7.5929e-02, -8.6931e-02,  1.3432e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.0170e-01,  3.8586e-01, -2.2643e-01],\n",
       "           [-2.0091e-01,  1.9802e-01,  2.9680e-01],\n",
       "           [-6.5895e-01, -2.4841e-01, -1.9565e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.9422e-01,  4.0546e-02,  1.4932e-01],\n",
       "           [ 3.7320e-02,  8.0723e-01, -4.5625e-01],\n",
       "           [ 4.0007e-01, -6.7450e-01,  6.0498e-03]]],\n",
       " \n",
       " \n",
       "         [[[-8.7805e-04, -1.1428e-01, -2.2023e-02],\n",
       "           [-1.5397e-01,  3.8196e-01, -2.6917e-01],\n",
       "           [-2.4005e-01,  3.1757e-01, -3.6489e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.7569e-01, -1.7717e-01,  1.5154e-01],\n",
       "           [ 3.1327e-01, -3.6693e-01, -3.9721e-01],\n",
       "           [ 1.6754e-01,  2.7370e-01, -6.2417e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.3532e-01,  2.2057e-01, -1.1766e-01],\n",
       "           [-2.1457e-01,  8.9078e-02,  7.0350e-02],\n",
       "           [ 3.1185e-01,  2.7086e-01,  3.3725e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.2933e-01, -1.6502e-01, -3.3500e-02],\n",
       "           [-8.1407e-02, -7.0285e-02,  2.6652e-01],\n",
       "           [-2.2722e-01, -1.4530e-01,  6.8340e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2193e-01,  2.3508e-01,  9.8131e-02],\n",
       "           [-1.5017e-01, -1.8072e-01,  9.0495e-02],\n",
       "           [-5.7690e-02, -4.8284e-01, -2.7299e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.4119e-02,  2.4902e-02,  1.0654e-02],\n",
       "           [-7.4146e-02, -7.1282e-02,  1.3729e-02],\n",
       "           [-3.9442e-02, -6.0471e-02, -3.4817e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.8013e-02,  1.1105e-01, -7.0793e-03],\n",
       "           [ 4.2509e-02, -6.7218e-03, -1.8693e-01],\n",
       "           [ 9.9031e-03, -2.3470e-01, -3.5898e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.9627e-02, -3.4235e-03,  1.1899e-01],\n",
       "           [-2.2527e-01, -1.5191e-01,  1.0873e-01],\n",
       "           [-1.0685e-01, -2.1868e-01,  2.9676e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1283e-01,  7.7621e-02, -2.6878e-01],\n",
       "           [ 1.0752e-01,  3.0905e-01, -4.8927e-01],\n",
       "           [ 2.2993e-01,  2.2328e-01, -3.3294e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.1231e-01,  1.2341e-01,  2.8105e-02],\n",
       "           [ 1.3616e-01, -1.9162e-01, -8.4145e-02],\n",
       "           [ 1.4548e-01, -8.5677e-02, -1.5070e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.3856e-02,  2.1405e-01,  1.4167e-01],\n",
       "           [-2.8392e-01,  9.0418e-02, -2.4726e-01],\n",
       "           [-1.9017e-01, -1.2832e-01,  6.6602e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4752e-02, -2.8124e-01, -2.0009e-01],\n",
       "           [-2.3971e-01, -2.6070e-01, -1.5954e-01],\n",
       "           [ 2.6350e-01,  4.6177e-01, -3.7294e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3364e-01,  4.6630e-02,  1.2256e-01],\n",
       "           [-1.9169e-01, -3.6499e-01,  4.3259e-01],\n",
       "           [-3.8280e-02, -3.4520e-01,  1.5974e-01]]],\n",
       " \n",
       " \n",
       "         [[[-5.0369e-01,  1.8320e-01,  2.3761e-01],\n",
       "           [-8.8199e-01,  8.9913e-01,  2.9488e-01],\n",
       "           [-4.5943e-01,  5.0781e-01,  2.7942e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7393e-02, -1.1299e-01,  1.8231e-01],\n",
       "           [ 2.0104e-02, -3.5322e-01, -7.1154e-02],\n",
       "           [-3.1592e-02, -2.1267e-01, -7.3913e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7436e-01,  3.0196e-02,  1.4430e-01],\n",
       "           [-4.1800e-01, -2.3291e-01, -1.7527e-01],\n",
       "           [-1.5571e-01,  1.2357e-01, -2.6725e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5936e-01,  2.5434e-01, -6.8758e-01],\n",
       "           [-2.8364e-01,  4.7492e-01,  1.1487e-02],\n",
       "           [-3.4607e-01, -4.2314e-01,  6.7823e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.2217e-02, -1.7215e-02, -2.0443e-01],\n",
       "           [-1.0595e-01, -2.2349e-01,  6.8934e-02],\n",
       "           [ 7.3360e-02, -1.4379e-01,  6.0849e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.0217e-01, -8.8994e-01, -4.0790e-01],\n",
       "           [ 1.3132e-01,  7.0272e-01,  7.2151e-02],\n",
       "           [-4.3785e-01,  3.8134e-01,  1.4703e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.5961e-02, -3.2483e-01,  3.4052e-01],\n",
       "           [-1.7054e-01, -6.4888e-01, -2.9364e-01],\n",
       "           [ 9.7313e-02,  7.6206e-03, -4.7137e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2658e-01,  2.9813e-01,  2.7197e-01],\n",
       "           [ 5.7804e-03, -1.8077e-01,  2.2393e-01],\n",
       "           [-1.9454e-01, -4.0220e-01,  3.4940e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.6136e-01, -7.6621e-02, -1.4952e-01],\n",
       "           [ 2.1638e-01, -6.6309e-03, -2.2310e-01],\n",
       "           [-1.4012e-01,  3.5484e-02, -2.9244e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.9893e-01, -3.7163e-02,  1.4221e-01],\n",
       "           [-2.2993e-02,  4.6442e-01, -3.5028e-01],\n",
       "           [ 2.7849e-01,  7.0167e-01,  1.7023e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1230e-01,  4.0267e-01, -2.9533e-01],\n",
       "           [-6.4232e-01, -5.0643e-01,  5.0220e-02],\n",
       "           [ 2.3505e-01,  1.8273e-01,  6.5987e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6156e-02, -3.9126e-02, -2.2906e-02],\n",
       "           [-4.8768e-02, -1.4694e-01, -1.3974e-01],\n",
       "           [ 2.0036e-02, -1.7975e-01, -1.1716e-01]]],\n",
       " \n",
       " \n",
       "         [[[-8.5793e-02, -4.4371e-01, -1.8605e-01],\n",
       "           [ 6.9544e-02, -3.3086e-01,  5.7867e-03],\n",
       "           [ 6.2062e-02, -6.8269e-02,  1.5552e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.0361e-02, -1.0341e-01,  1.1679e-01],\n",
       "           [ 4.5132e-03,  2.0000e-01, -2.0086e-01],\n",
       "           [-1.7424e-01,  1.9330e-02, -3.1296e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.1722e-01,  4.9152e-01,  3.7298e-01],\n",
       "           [ 3.1525e-01, -3.4144e-01, -1.1648e-01],\n",
       "           [-4.2886e-02, -2.9275e-01, -2.5983e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.3447e-01, -4.8331e-01, -2.9809e-01],\n",
       "           [ 2.8465e-01, -3.9327e-02, -2.4536e-01],\n",
       "           [ 4.2219e-02,  3.5476e-01, -7.7833e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.3644e-02, -1.0839e-01, -6.4790e-03],\n",
       "           [ 6.1498e-03, -8.5618e-02, -2.4216e-02],\n",
       "           [ 8.7288e-04, -6.5114e-02, -7.5383e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1429e-01, -1.7201e-01,  8.9100e-03],\n",
       "           [-2.2060e-01, -4.3752e-01, -5.5348e-01],\n",
       "           [ 2.4587e-02, -6.9155e-03, -1.4511e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.3987e-01,  2.9458e-01, -1.5305e-01],\n",
       "           [ 1.0325e-01,  3.8013e-01, -5.2084e-01],\n",
       "           [ 4.9100e-02,  2.9663e-02, -2.9913e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.1526e-01, -4.8768e-01,  2.2931e-01],\n",
       "           [-2.9846e-01,  3.8159e-01,  1.3030e-01],\n",
       "           [ 9.8189e-02,  1.4614e-01, -1.9093e-01]]]], requires_grad=True))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_param[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56ddcafc5f4a65ffc1eba06f4696d06fbf43c848b7a2cf81f3fe8a9e81fc5ea1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
