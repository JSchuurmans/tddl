{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd056ddcafc5f4a65ffc1eba06f4696d06fbf43c848b7a2cf81f3fe8a9e81fc5ea1",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "410f5a2154215048c5c4a50456f2ab7ff5c84b265e9461f7a7c2c07eed30bc24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import tensorly as tl\n",
    "from tddl.models.vgg import ModifiedVGG16Model\n",
    "from tddl.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:886: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: /bigdata/dogs-vs-cats/train/\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-73c64c6767e0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModifiedVGG16Model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.99\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mtrainer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gitProjects/phd/tddl/src/tddl/trainer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, train_path, test_path, model, optimizer)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mTrainer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_data_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_data_loader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gitProjects/phd/tddl/src/tddl/data.py\u001B[0m in \u001B[0;36mloader\u001B[0;34m(path, batch_size, num_workers, pin_memory)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mnormalize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNormalize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0.485\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.456\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.406\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0.229\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.224\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.225\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     return data.DataLoader(\n\u001B[0;32m---> 18\u001B[0;31m         datasets.ImageFolder(path,\n\u001B[0m\u001B[1;32m     19\u001B[0m                              transforms.Compose([\n\u001B[1;32m     20\u001B[0m                                  \u001B[0mtransforms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mResize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m256\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    251\u001B[0m             \u001B[0mis_valid_file\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mCallable\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m     ):\n\u001B[0;32m--> 253\u001B[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001B[0m\u001B[1;32m    254\u001B[0m                                           \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m                                           \u001B[0mtarget_transform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtarget_transform\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextensions\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m                 \u001B[0mmsg\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m\"Supported extensions are: {}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\",\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mextensions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Found 0 files in subfolders of: /bigdata/dogs-vs-cats/train/\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
     ]
    }
   ],
   "source": [
    "train_path = \"/bigdata/dogs-vs-cats/train/\"\n",
    "test_path = \"/bigdata/dogs-vs-cats/test1/\"\n",
    "\n",
    "\n",
    "model = ModifiedVGG16Model().cuda()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.0001, momentum=0.99)\n",
    "trainer = Trainer(train_path, test_path, model, optimizer)\n",
    "\n",
    "trainer.train(epoches = 10)\n",
    "torch.save(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}