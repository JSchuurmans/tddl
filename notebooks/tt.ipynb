{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tltorch/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n",
      "  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "import tltorch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = np.prod(shape)\n",
    "\n",
    "def count_parameters_tt(shape, rank):\n",
    "    parameters = 0\n",
    "    for i,s in enumerate(shape):\n",
    "        r_0 = rank[i]\n",
    "        r_1 = rank[i+1]\n",
    "        parameters += r_0*s*r_1\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/bigdata/cifar10/logs/baselines/1646668631/rn18_18_dNone_128_adam_l0.001_g0.1_w0.0_sTrue/cnn_best.pth\"\n",
    "model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': (0,\n",
       "  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " 'bn1': (1,\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " 'relu': (2, ReLU(inplace=True)),\n",
       " 'maxpool': (3,\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
       " 'layer1': (4,\n",
       "  {'0': (5,\n",
       "    {'conv1': (6,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn1': (7,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (8, ReLU(inplace=True)),\n",
       "     'conv2': (9,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (10,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))}),\n",
       "   '1': (11,\n",
       "    {'conv1': (12,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn1': (13,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (14, ReLU(inplace=True)),\n",
       "     'conv2': (15,\n",
       "      Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (16,\n",
       "      BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       " 'layer2': (17,\n",
       "  {'0': (18,\n",
       "    {'conv1': (19,\n",
       "      Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn1': (20,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (21, ReLU(inplace=True)),\n",
       "     'conv2': (22,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (23,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'downsample': (24,\n",
       "      {'0': (25,\n",
       "        Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       "       '1': (26,\n",
       "        BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       "   '1': (27,\n",
       "    {'conv1': (28,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn1': (29,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (30, ReLU(inplace=True)),\n",
       "     'conv2': (31,\n",
       "      Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (32,\n",
       "      BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       " 'layer3': (33,\n",
       "  {'0': (34,\n",
       "    {'conv1': (35,\n",
       "      Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn1': (36,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (37, ReLU(inplace=True)),\n",
       "     'conv2': (38,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (39,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'downsample': (40,\n",
       "      {'0': (41,\n",
       "        Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       "       '1': (42,\n",
       "        BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       "   '1': (43,\n",
       "    {'conv1': (44,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn1': (45,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (46, ReLU(inplace=True)),\n",
       "     'conv2': (47,\n",
       "      Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (48,\n",
       "      BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       " 'layer4': (49,\n",
       "  {'0': (50,\n",
       "    {'conv1': (51,\n",
       "      Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       "     'bn1': (52,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (53, ReLU(inplace=True)),\n",
       "     'conv2': (54,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (55,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'downsample': (56,\n",
       "      {'0': (57,\n",
       "        Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       "       '1': (58,\n",
       "        BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       "   '1': (59,\n",
       "    {'conv1': (60,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn1': (61,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "     'relu': (62, ReLU(inplace=True)),\n",
       "     'conv2': (63,\n",
       "      Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       "     'bn2': (64,\n",
       "      BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))})}),\n",
       " 'avgpool': (65, AdaptiveAvgPool2d(output_size=(1, 1))),\n",
       " 'fc': (66, Linear(in_features=512, out_features=10, bias=True))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tddl.factorizations import number_layers\n",
    "\n",
    "number_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer3[0].downsample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\n",
    "    15: model.layer1[1].conv2,\n",
    "    19: model.layer2[0].conv1,\n",
    "    28: model.layer2[1].conv1,\n",
    "    38: model.layer3[0].conv2,\n",
    "    41: model.layer3[0].downsample[0],\n",
    "    44: model.layer3[1].conv1,\n",
    "    60: model.layer4[1].conv1,\n",
    "    63: model.layer4[1].conv2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac, tucker, tensor_train\n",
    "from torch.linalg import norm\n",
    "\n",
    "tensor = layers[15].weight\n",
    "\n",
    "tt_tensors = tensor_train(tensor, rank=[1,32,9,3,1])\n",
    "\n",
    "approximation = tt_tensors.to_tensor()\n",
    "error = norm(tensor-approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank (1, 32, 9, 3, 1)\n",
      "shape (64, 64, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print('rank',tt_tensors.rank)\n",
    "print('shape',tt_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param_tt = count_parameters_tt(rank=tt_tensors.rank, shape=tt_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param = np.prod(tt_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579969618055556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_param_tt/n_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4570, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error/norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = model.layer4[0].conv2\n",
    "rank = 0.5\n",
    "decompose_weights = True\n",
    "factorization = 'tt'\n",
    "\n",
    "conv_tt = tltorch.FactorizedConv.from_conv(\n",
    "    conv, \n",
    "    rank=rank, \n",
    "    decompose_weights=decompose_weights, \n",
    "    factorization=factorization,\n",
    "    # decomposition_kwargs={\"init\":\"random\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizedConv(\n",
       "  in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(1, 1073, 13, 1073, 1), order=2, padding=[1, 1], bias=False\n",
       "  (weight): TTTensor(shape=(512, 3, 3, 512), rank=(1, 512, 13, 39, 1))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = conv_tt.weight.rank\n",
    "shape = conv_tt.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 13, 39, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 3, 3, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0.5 #(1,256,512,256,1)\n",
    "decompose_weights = True\n",
    "factorization = 'tt'\n",
    "\n",
    "conv_tt_r = tltorch.FactorizedConv.from_conv(\n",
    "    layers[15], \n",
    "    rank=rank, \n",
    "    decompose_weights=decompose_weights, \n",
    "    factorization=factorization,\n",
    "    # decomposition_kwargs={\"init\":\"random\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_tt_r.input_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 101, 9, 101, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_tt_r.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 3, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_tt_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTTensor(shape=(64, 3, 3, 64), rank=(1, 64, 9, 27, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_tt_r.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8161, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximation_tt = conv_tt_r.weight.to_tensor()\n",
    "tensor = layers[15].weight\n",
    "error = norm(torch.moveaxis(approximation_tt,3,0)-tensor)/norm(tensor)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8161, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximation_tt = conv_tt_r.weight.to_tensor()\n",
    "tensor = layers[15].weight\n",
    "error = norm(approximation_tt.permute(3,0,1,2)-tensor)/norm(tensor)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximation_tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[44].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[41].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_nr = 63\n",
      "(1, 512, 526, 512, 1)\n",
      "param 0.9071180555555556\n",
      "error tensor(0.1479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "layer_nr = 63\n",
    "layer = layers[layer_nr]\n",
    "\n",
    "conv_tt = tltorch.FactorizedConv.from_conv(\n",
    "    layer, \n",
    "    rank=80.0, \n",
    "    decompose_weights=True, \n",
    "    factorization='tt',\n",
    "    # decomposition_kwargs={\"init\":\"random\"},\n",
    ")\n",
    "# print(conv_tt.rank)\n",
    "print(f'{layer_nr = }')\n",
    "print(conv_tt.weight.rank)\n",
    "\n",
    "# print(conv_tt.shape)\n",
    "# print(conv_tt.weight.shape)\n",
    "\n",
    "n_param_tt = count_parameters_tt(rank=conv_tt.weight.rank, shape=conv_tt.weight.shape)\n",
    "n_param = np.prod(layer.weight.shape)\n",
    "print(\"param\", n_param_tt/n_param)\n",
    "\n",
    "approximation_tt = conv_tt.weight.to_tensor()\n",
    "tensor = layer.weight\n",
    "error = norm(torch.moveaxis(approximation_tt,3,0)-tensor)/norm(tensor)\n",
    "print(\"error\", error)\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = { # layer: {target_percentage: (tt_rank)} # relative_rank: approximation error\n",
    "    '15':{\n",
    "        10: (1, 40, 4, 40, 1), # 0.16: 0.9043\n",
    "        25: (1, 118, 11, 118, 1), # 0.61: 0.7851\n",
    "        50: (1, 296, 26, 296, 1), # 2.30: 0.5976\n",
    "        75: (1, 564, 51, 564, 1),\n",
    "        90: (1, 730, 65, 730, 1),\n",
    "    },\n",
    "    '19':{\n",
    "        10: (1, 63, 6, 123, 1), # 0.31: 0.8788\n",
    "        25: (1, 217, 19, 424, 1), # 1.43: 0.6974\n",
    "        50: (1, 407, 36, 796, 1), # 3.52: 0.5383\n",
    "    },\n",
    "    '28':{\n",
    "        10: (1, 94, 4, 94, 1), # 0.18: 0.9568\n",
    "        25: (1, 468, 21, 468, 1), # 1.22: 0.8201\n",
    "        50: (1, 1168, 53, 1168, 1), # 4.57: 0.6437\n",
    "    },\n",
    "    '38':{\n",
    "        10: (1, 207, 5, 207, 1), # 0.19: 0.9612\n",
    "        25: (1, 1837, 43, 1837, 1), # 2.39: 0.7571\n",
    "        50: (1, 4600, 107, 4600, 1), # 8.98: 0.5704\n",
    "    },\n",
    "    '41':{\n",
    "        10: (1, 23, 1, 46, 1), # 0.45: 0.9775\n",
    "        25: (1, 62, 1, 123, 1), # 1.21: 0.9775\n",
    "        50: (1, 122, 2, 243, 1), # 2.40: 0.9590\n",
    "    },\n",
    "    '44':{\n",
    "        10: (1, 207, 5, 207, 1), # 0.19: 0.9518\n",
    "        25: (1, 1837, 43, 1837, 1), # 2.39: 0.7340\n",
    "        50: (1, 4600, 107, 4600, 1), # 8.98: 0.5535\n",
    "    },\n",
    "    '60':{\n",
    "        10: (1, 425, 5, 425, 1), # 0.19: 0.5757\n",
    "        25: (1, 7338, 85, 7338, 1), # 4.78: 0.3342\n",
    "        50: (1, 18323, 213, 18323, 1), # 17.90: 0.2561\n",
    "    },\n",
    "    '63':{\n",
    "        10: (1, 425, 5, 425, 1), # 0.19: 0.5394\n",
    "        25: (1, 7338, 85, 7338, 1), # 4.78: 0.3132\n",
    "        50: (1, 18323, 213, 18323, 1), # 17.90: 0.2446\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 223, 20, 223, 1)\n",
      "(64, 3, 3, 64)\n",
      "param 0.4171006944444444\n",
      "error tensor(0.6635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(64, 3, 3, 64)\n",
      "param 2.2222222222222223\n",
      "error tensor(1.7427e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 225, 20, 439, 1)\n",
      "(64, 3, 3, 128)\n",
      "param 0.2606336805555556\n",
      "error tensor(0.6862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(64, 3, 3, 128)\n",
      "param 1.7777777777777777\n",
      "error tensor(1.8776e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 545, 25, 545, 1)\n",
      "(128, 3, 3, 128)\n",
      "param 0.2794664171006944\n",
      "error tensor(0.7938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(128, 3, 3, 128)\n",
      "param 2.2222222222222223\n",
      "error tensor(2.0746e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 1282, 30, 1282, 1)\n",
      "(256, 3, 3, 256)\n",
      "param 0.2029690212673611\n",
      "error tensor(0.8151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(256, 3, 3, 256)\n",
      "param 2.2222222222222223\n",
      "error tensor(2.3903e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 77, 1, 153, 1)\n",
      "(128, 1, 1, 256)\n",
      "param 0.31097412109375\n",
      "error tensor(0.9775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(128, 1, 1, 256)\n",
      "param 2.5\n",
      "error tensor(1.8462e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 1282, 30, 1282, 1)\n",
      "(256, 3, 3, 256)\n",
      "param 0.2029690212673611\n",
      "error tensor(0.7913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(256, 3, 3, 256)\n",
      "param 2.2222222222222223\n",
      "error tensor(2.2335e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 2887, 34, 2887, 1)\n",
      "(512, 3, 3, 512)\n",
      "param 0.15979173448350695\n",
      "error tensor(0.4094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(512, 3, 3, 512)\n",
      "param 1.5243055555555556\n",
      "error tensor(0.0551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n",
      "(1, 2887, 34, 2887, 1)\n",
      "(512, 3, 3, 512)\n",
      "param 0.15979173448350695\n",
      "error tensor(0.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n",
      "(1, 1000, 1000, 1000, 1)\n",
      "(512, 3, 3, 512)\n",
      "param 1.5243055555555556\n",
      "error tensor(0.0539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for layer in layers.values():\n",
    "    conv_tt = tltorch.FactorizedConv.from_conv(\n",
    "        layer, \n",
    "        rank=1.5, \n",
    "        decompose_weights=True, \n",
    "        factorization='tt',\n",
    "        # decomposition_kwargs={\"init\":\"random\"},\n",
    "    )\n",
    "    print(conv_tt.rank)\n",
    "    print(conv_tt.shape)\n",
    "\n",
    "    n_param_tt = count_parameters_tt(rank=conv_tt.weight.rank, shape=conv_tt.weight.shape)\n",
    "    n_param = np.prod(layer.weight.shape)\n",
    "    print(\"param\", n_param_tt/n_param)\n",
    "\n",
    "    approximation_tt = conv_tt.weight.to_tensor()\n",
    "    tensor = layer.weight\n",
    "    error = norm(torch.moveaxis(approximation_tt,3,0)-tensor)/norm(tensor)\n",
    "    print(\"error\", error)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    o,i,w,h = layer.weight.shape\n",
    "\n",
    "    conv_tt_r = tltorch.FactorizedConv.from_conv(\n",
    "        layer,\n",
    "        # rank=(1,round(o/2),w*h,round(i/2),1),\n",
    "        rank = (1,1000,1000,1000,1),\n",
    "        decompose_weights=True, \n",
    "        factorization='tt',\n",
    "        # decomposition_kwargs={\"init\":\"random\"},\n",
    "    )\n",
    "    print(conv_tt_r.rank)\n",
    "    print(conv_tt_r.shape)\n",
    "\n",
    "    n_param_tt_r = count_parameters_tt(rank=conv_tt_r.weight.rank, shape=conv_tt_r.weight.shape)\n",
    "    print(\"param\", n_param_tt_r/n_param)\n",
    "    approximation_tt_r = conv_tt_r.weight.to_tensor()\n",
    "    error_r = norm(torch.moveaxis(approximation_tt_r,3,0)-tensor)/norm(tensor)\n",
    "    print(\"error\", error_r)\n",
    "    print(\"=\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "garipov_cifar = torch.load('/bigdata/cifar10/logs/garipov/baselines/1647358615/gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue/cnn_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "garipov_layers = {\n",
    "    2: garipov_cifar.conv2,\n",
    "    4: garipov_cifar.conv3,\n",
    "    6: garipov_cifar.conv4,\n",
    "    8: garipov_cifar.conv5,\n",
    "    10: garipov_cifar.conv6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_nr = 10\n",
      "(1, 128, 130, 128, 1)\n",
      "param 0.8993055555555556\n",
      "error tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "layer_nr = 10\n",
    "layer = garipov_layers[layer_nr]\n",
    "\n",
    "conv_tt = tltorch.FactorizedConv.from_conv(\n",
    "    layer, \n",
    "    rank=20.07, \n",
    "    decompose_weights=True, \n",
    "    factorization='tt',\n",
    "    # decomposition_kwargs={\"init\":\"random\"},\n",
    ")\n",
    "print(f'{layer_nr = }')\n",
    "print(conv_tt.weight.rank)\n",
    "# print(conv_tt.shape)\n",
    "\n",
    "n_param_tt = count_parameters_tt(rank=conv_tt.weight.rank, shape=conv_tt.weight.shape)\n",
    "n_param = np.prod(layer.weight.shape)\n",
    "print(\"param\", n_param_tt/n_param)\n",
    "\n",
    "approximation_tt = conv_tt.weight.to_tensor()\n",
    "tensor = layer.weight\n",
    "error = norm(torch.moveaxis(approximation_tt,3,0)-tensor)/norm(tensor)\n",
    "print(\"error\", error)\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 128 1 1\n"
     ]
    }
   ],
   "source": [
    "garipov_ranks_cifar = { # layernr: {target_percentage_parameters: tt_rank} # approximation_error\n",
    "    2:{\n",
    "        10: 0.16, # 0.8505\n",
    "        25: 0.61, # 0.6562\n",
    "        50: 2.31, # 0.4151\n",
    "        75: 6.60, # 0.2538\n",
    "        90: 10.33, # 0.1969\n",
    "    },\n",
    "    4:{\n",
    "        10: 0.31, # 0.8272\n",
    "        25: 1.43, # 0.6319\n",
    "        50: 3.52, # 0.4728\n",
    "        75: 7.79, # 0.3309\n",
    "        90: 12.28, # 0.2503\n",
    "    },\n",
    "    6:{\n",
    "        10: 0.18, # 0.9334\n",
    "        25: 1.22, # 0.7713\n",
    "        50: 4.57, # 0.5768\n",
    "        75: 12.99, # 0.3873\n",
    "        90: 20.07, # 0.3033\n",
    "    },\n",
    "    8:{\n",
    "        10: 0.18, # 0.9203\n",
    "        25: 1.22, # 0.7452\n",
    "        50: 4.57, # 0.5393\n",
    "        75: 12.99, # 0.3474\n",
    "        90: 20.07, # 0.2667\n",
    "    },\n",
    "    10:{\n",
    "        10: 0.18, # 0.7626\n",
    "        25: 1.22, # 0.2897\n",
    "        50: 4.57, # 0.2346\n",
    "        75: 12.99, # 0.1801\n",
    "        90: 20.07, # 0.1511\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaripovNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garipov_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "garipov_fmnist = torch.load('/bigdata/f_mnist/logs/garipov/baselines/1647955843/gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue/cnn_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaripovNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garipov_fmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.1\n",
      "(14, 14, 3, 3)\n",
      "==========\n",
      "15 0.25\n",
      "(26, 26, 3, 3)\n",
      "==========\n",
      "15 0.5\n",
      "(39, 39, 3, 3)\n",
      "==========\n",
      "15 0.75\n",
      "(49, 49, 3, 3)\n",
      "==========\n",
      "15 0.9\n",
      "(54, 54, 3, 3)\n",
      "==========\n",
      "19 0.1\n",
      "(26, 13, 3, 3)\n",
      "==========\n",
      "19 0.25\n",
      "(49, 24, 3, 3)\n",
      "==========\n",
      "19 0.5\n",
      "(74, 37, 3, 3)\n",
      "==========\n",
      "19 0.75\n",
      "(94, 47, 3, 3)\n",
      "==========\n",
      "19 0.9\n",
      "(105, 52, 3, 3)\n",
      "==========\n",
      "28 0.1\n",
      "(29, 29, 3, 3)\n",
      "==========\n",
      "28 0.25\n",
      "(51, 51, 3, 3)\n",
      "==========\n",
      "28 0.5\n",
      "(77, 77, 3, 3)\n",
      "==========\n",
      "28 0.75\n",
      "(98, 98, 3, 3)\n",
      "==========\n",
      "28 0.9\n",
      "(108, 108, 3, 3)\n",
      "==========\n",
      "38 0.1\n",
      "(57, 57, 3, 3)\n",
      "==========\n",
      "38 0.25\n",
      "(103, 103, 3, 3)\n",
      "==========\n",
      "38 0.5\n",
      "(155, 155, 3, 3)\n",
      "==========\n",
      "38 0.75\n",
      "(195, 195, 3, 3)\n",
      "==========\n",
      "38 0.9\n",
      "(216, 216, 3, 3)\n",
      "==========\n",
      "41 0.1\n",
      "(10, 5, 1, 1)\n",
      "==========\n",
      "41 0.25\n",
      "(25, 12, 1, 1)\n",
      "==========\n",
      "41 0.5\n",
      "(48, 24, 1, 1)\n",
      "==========\n",
      "41 0.75\n",
      "(69, 35, 1, 1)\n",
      "==========\n",
      "41 0.9\n",
      "(82, 41, 1, 1)\n",
      "==========\n",
      "44 0.1\n",
      "(57, 57, 3, 3)\n",
      "==========\n",
      "44 0.25\n",
      "(103, 103, 3, 3)\n",
      "==========\n",
      "44 0.5\n",
      "(155, 155, 3, 3)\n",
      "==========\n",
      "44 0.75\n",
      "(195, 195, 3, 3)\n",
      "==========\n",
      "44 0.9\n",
      "(216, 216, 3, 3)\n",
      "==========\n",
      "60 0.1\n",
      "(115, 115, 3, 3)\n",
      "==========\n",
      "60 0.25\n",
      "(205, 205, 3, 3)\n",
      "==========\n",
      "60 0.5\n",
      "(310, 310, 3, 3)\n",
      "==========\n",
      "60 0.75\n",
      "(390, 390, 3, 3)\n",
      "==========\n",
      "60 0.9\n",
      "(432, 432, 3, 3)\n",
      "==========\n",
      "63 0.1\n",
      "(115, 115, 3, 3)\n",
      "==========\n",
      "63 0.25\n",
      "(205, 205, 3, 3)\n",
      "==========\n",
      "63 0.5\n",
      "(310, 310, 3, 3)\n",
      "==========\n",
      "63 0.75\n",
      "(390, 390, 3, 3)\n",
      "==========\n",
      "63 0.9\n",
      "(432, 432, 3, 3)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compressions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "for layer_nr,layer in layers.items():\n",
    "    for compression in compressions:\n",
    "        conv_t = tltorch.FactorizedConv.from_conv(\n",
    "            layer, \n",
    "            rank=compression, \n",
    "            decompose_weights=True, \n",
    "            factorization='tucker',\n",
    "            fixed_rank_modes = 'spatial',\n",
    "        )\n",
    "        print(layer_nr, compression)\n",
    "        print(conv_t.weight.rank)\n",
    "        # print(conv_t.weight.shape)\n",
    "        print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.1\n",
      "(14, 14, 3, 3)\n",
      "==========\n",
      "2 0.25\n",
      "(26, 26, 3, 3)\n",
      "==========\n",
      "2 0.5\n",
      "(39, 39, 3, 3)\n",
      "==========\n",
      "2 0.75\n",
      "(49, 49, 3, 3)\n",
      "==========\n",
      "2 0.9\n",
      "(54, 54, 3, 3)\n",
      "==========\n",
      "4 0.1\n",
      "(26, 13, 3, 3)\n",
      "==========\n",
      "4 0.25\n",
      "(49, 24, 3, 3)\n",
      "==========\n",
      "4 0.5\n",
      "(74, 37, 3, 3)\n",
      "==========\n",
      "4 0.75\n",
      "(94, 47, 3, 3)\n",
      "==========\n",
      "4 0.9\n",
      "(105, 52, 3, 3)\n",
      "==========\n",
      "6 0.1\n",
      "(29, 29, 3, 3)\n",
      "==========\n",
      "6 0.25\n",
      "(51, 51, 3, 3)\n",
      "==========\n",
      "6 0.5\n",
      "(77, 77, 3, 3)\n",
      "==========\n",
      "6 0.75\n",
      "(98, 98, 3, 3)\n",
      "==========\n",
      "6 0.9\n",
      "(108, 108, 3, 3)\n",
      "==========\n",
      "8 0.1\n",
      "(29, 29, 3, 3)\n",
      "==========\n",
      "8 0.25\n",
      "(51, 51, 3, 3)\n",
      "==========\n",
      "8 0.5\n",
      "(77, 77, 3, 3)\n",
      "==========\n",
      "8 0.75\n",
      "(98, 98, 3, 3)\n",
      "==========\n",
      "8 0.9\n",
      "(108, 108, 3, 3)\n",
      "==========\n",
      "10 0.1\n",
      "(29, 29, 3, 3)\n",
      "==========\n",
      "10 0.25\n",
      "(51, 51, 3, 3)\n",
      "==========\n",
      "10 0.5\n",
      "(77, 77, 3, 3)\n",
      "==========\n",
      "10 0.75\n",
      "(98, 98, 3, 3)\n",
      "==========\n",
      "10 0.9\n",
      "(108, 108, 3, 3)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compressions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "for layer_nr,layer in garipov_layers.items():\n",
    "    for compression in compressions:\n",
    "        conv_t = tltorch.FactorizedConv.from_conv(\n",
    "            layer, \n",
    "            rank=compression, \n",
    "            decompose_weights=True, \n",
    "            factorization='tucker',\n",
    "            fixed_rank_modes = 'spatial',\n",
    "        )\n",
    "        print(layer_nr, compression)\n",
    "        print(conv_t.weight.rank)\n",
    "        # print(conv_t.weight.shape)\n",
    "        print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.1\n",
      "28\n",
      "==========\n",
      "15 0.25\n",
      "69\n",
      "==========\n",
      "15 0.5\n",
      "138\n",
      "==========\n",
      "15 0.75\n",
      "206\n",
      "==========\n",
      "15 0.9\n",
      "248\n",
      "==========\n",
      "19 0.1\n",
      "37\n",
      "==========\n",
      "19 0.25\n",
      "93\n",
      "==========\n",
      "19 0.5\n",
      "186\n",
      "==========\n",
      "19 0.75\n",
      "279\n",
      "==========\n",
      "19 0.9\n",
      "335\n",
      "==========\n",
      "28 0.1\n",
      "56\n",
      "==========\n",
      "28 0.25\n",
      "141\n",
      "==========\n",
      "28 0.5\n",
      "281\n",
      "==========\n",
      "28 0.75\n",
      "422\n",
      "==========\n",
      "28 0.9\n",
      "507\n",
      "==========\n",
      "38 0.1\n",
      "114\n",
      "==========\n",
      "38 0.25\n",
      "285\n",
      "==========\n",
      "38 0.5\n",
      "569\n",
      "==========\n",
      "38 0.75\n",
      "854\n",
      "==========\n",
      "38 0.9\n",
      "1025\n",
      "==========\n",
      "41 0.1\n",
      "8\n",
      "==========\n",
      "41 0.25\n",
      "21\n",
      "==========\n",
      "41 0.5\n",
      "42\n",
      "==========\n",
      "41 0.75\n",
      "64\n",
      "==========\n",
      "41 0.9\n",
      "76\n",
      "==========\n",
      "44 0.1\n",
      "114\n",
      "==========\n",
      "44 0.25\n",
      "285\n",
      "==========\n",
      "44 0.5\n",
      "569\n",
      "==========\n",
      "44 0.75\n",
      "854\n",
      "==========\n",
      "44 0.9\n",
      "1025\n",
      "==========\n",
      "60 0.1\n",
      "229\n",
      "==========\n",
      "60 0.25\n",
      "573\n",
      "==========\n",
      "60 0.5\n",
      "1145\n",
      "==========\n",
      "60 0.75\n",
      "1718\n",
      "==========\n",
      "60 0.9\n",
      "2062\n",
      "==========\n",
      "63 0.1\n",
      "229\n",
      "==========\n",
      "63 0.25\n",
      "573\n",
      "==========\n",
      "63 0.5\n",
      "1145\n",
      "==========\n",
      "63 0.75\n",
      "1718\n",
      "==========\n",
      "63 0.9\n",
      "2062\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compressions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "for layer_nr,layer in layers.items():\n",
    "    for compression in compressions:\n",
    "        conv_t = tltorch.FactorizedConv.from_conv(\n",
    "            layer, \n",
    "            rank=compression, \n",
    "            decompose_weights=True, \n",
    "            factorization='cp',\n",
    "            decomposition_kwargs={\"init\":\"random\"},\n",
    "        )\n",
    "        print(layer_nr, compression)\n",
    "        print(conv_t.weight.rank)\n",
    "        # print(conv_t.weight.shape)\n",
    "        print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.1\n",
      "28\n",
      "==========\n",
      "2 0.25\n",
      "69\n",
      "==========\n",
      "2 0.5\n",
      "138\n",
      "==========\n",
      "2 0.75\n",
      "206\n",
      "==========\n",
      "2 0.9\n",
      "248\n",
      "==========\n",
      "4 0.1\n",
      "37\n",
      "==========\n",
      "4 0.25\n",
      "93\n",
      "==========\n",
      "4 0.5\n",
      "186\n",
      "==========\n",
      "4 0.75\n",
      "279\n",
      "==========\n",
      "4 0.9\n",
      "335\n",
      "==========\n",
      "6 0.1\n",
      "56\n",
      "==========\n",
      "6 0.25\n",
      "141\n",
      "==========\n",
      "6 0.5\n",
      "281\n",
      "==========\n",
      "6 0.75\n",
      "422\n",
      "==========\n",
      "6 0.9\n",
      "507\n",
      "==========\n",
      "8 0.1\n",
      "56\n",
      "==========\n",
      "8 0.25\n",
      "141\n",
      "==========\n",
      "8 0.5\n",
      "281\n",
      "==========\n",
      "8 0.75\n",
      "422\n",
      "==========\n",
      "8 0.9\n",
      "507\n",
      "==========\n",
      "10 0.1\n",
      "56\n",
      "==========\n",
      "10 0.25\n",
      "141\n",
      "==========\n",
      "10 0.5\n",
      "281\n",
      "==========\n",
      "10 0.75\n",
      "422\n",
      "==========\n",
      "10 0.9\n",
      "507\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "compressions = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "for layer_nr,layer in garipov_layers.items():\n",
    "    for compression in compressions:\n",
    "        conv_t = tltorch.FactorizedConv.from_conv(\n",
    "            layer, \n",
    "            rank=compression, \n",
    "            decompose_weights=True, \n",
    "            factorization='cp',\n",
    "            decomposition_kwargs={\"init\":\"random\"},\n",
    "        )\n",
    "        print(layer_nr, compression)\n",
    "        print(conv_t.weight.rank)\n",
    "        # print(conv_t.weight.shape)\n",
    "        print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56ddcafc5f4a65ffc1eba06f4696d06fbf43c848b7a2cf81f3fe8a9e81fc5ea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
