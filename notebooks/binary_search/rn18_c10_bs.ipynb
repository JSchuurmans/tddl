{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 229,\n",
       " 'best_train_acc': 0.9999333333333333,\n",
       " 'best_valid_acc': 0.9216,\n",
       " 'best_valid_loss': 0.005079200401902199,\n",
       " 'test_acc': 0.9137,\n",
       " 'test_loss': 0.005285387974977494,\n",
       " 'n_param': 11173962,\n",
       " 'model_name': 'rn18_18_dNone_128_adam_l0.001_g0.1_w0.0_sTrue'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "baseline_path = Path(\"/bigdata/cifar10/logs/baselines/1646668631/rn18_18_dNone_128_adam_l0.001_g0.1_w0.0_sTrue\")\n",
    "baseline_model = torch.load(baseline_path / \"cnn_best.pth\")\n",
    "with open(baseline_path/'results.json') as json_file:\n",
    "    baseline_result = json.load(json_file)\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tltorch/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n",
      "  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n"
     ]
    }
   ],
   "source": [
    "from tddl.factorizations import number_layers, listify_numbered_layers, get_weights\n",
    "\n",
    "numbered_layers = number_layers(baseline_model)\n",
    "resnet_layers = [6,9,12,15,19,22,25,28,31,35,38,41,44,47,51,54,57,60,63]\n",
    "layers = listify_numbered_layers(numbered_layers, layer_nrs=resnet_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tddl.dbs import find_error_given_c\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=5, maxsize=4096, currsize=5)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=10, maxsize=4096, currsize=10)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=16, maxsize=4096, currsize=16)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=21, maxsize=4096, currsize=21)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=26, maxsize=4096, currsize=26)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=31, maxsize=4096, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=85, maxsize=4096, currsize=85)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=89, maxsize=4096, currsize=89)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=90, maxsize=4096, currsize=90)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=94, maxsize=4096, currsize=94)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=99, maxsize=4096, currsize=99)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=104, maxsize=4096, currsize=104)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1805311/1718908824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# no caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_error_given_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/dbs.py\u001b[0m in \u001b[0;36mfind_error_given_c\u001b[0;34m(layers, desired_c, error, tollerance, max_error, min_error, max_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0machieved_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_layers_with_desired_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtollerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/dbs.py\u001b[0m in \u001b[0;36mcompress_layers_with_desired_error\u001b[0;34m(layers, desired_error, baseline_count, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# param_count += count_parameters(layers[0][2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mfact_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_rank_given_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# fact_layers.append(fact_layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/dbs.py\u001b[0m in \u001b[0;36mfind_rank_given_error\u001b[0;34m(layer, desired_error, rank, tollerance, max_rank, min_rank, max_iter)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(rank)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mfact_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tucker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print(error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_error\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/factorizations.py\u001b[0m in \u001b[0;36mfactorize_layer\u001b[0;34m(module, factorization, rank, decompose_weights, init_std, return_error, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         fact_module = tltorch.FactorizedConv.from_conv(\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36mfrom_conv\u001b[0;34m(cls, conv_layer, rank, implementation, factorization, decompose_weights, decomposition_kwargs, fixed_rank_modes, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mkernel_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecomposition_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_tensors/factorized_tensors.py\u001b[0m in \u001b[0;36minit_from_tensor\u001b[0;34m(self, tensor, unsqueezed_modes, unsqueezed_init, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0munsqueezed_modes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, fixed_factors, n_iter_max, init, svd, tol, random_state, mask, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tucker_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         core, factors = partial_tucker(tensor, modes, rank=rank, n_iter_max=n_iter_max, init=init,\n\u001b[0m\u001b[1;32m    206\u001b[0m                             svd=svd, tol=tol, random_state=random_state, mask=mask, verbose=verbose)\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTuckerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mcore_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;31m# First choose whether to use X * X.T or X.T *X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim_1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdim_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 S, U = scipy.sparse.linalg.eigsh(\n\u001b[0m\u001b[1;32m    908\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                 )\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_eigenvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, return_eigenvectors)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mhowmny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'A'\u001b[0m  \u001b[0;31m# return all eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0msselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         d, z, ierr = self._arpack_extract(rvec, howmny, sselect, self.sigma,\n\u001b[0m\u001b[1;32m    580\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no caching\n",
    "ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=5, maxsize=4096, currsize=5)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=2, maxsize=128, currsize=2)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=10, maxsize=4096, currsize=10)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=3, maxsize=128, currsize=3)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=16, maxsize=4096, currsize=16)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=4, maxsize=128, currsize=4)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=21, maxsize=4096, currsize=21)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=5, maxsize=128, currsize=5)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=26, maxsize=4096, currsize=26)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=6, maxsize=128, currsize=6)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=31, maxsize=4096, currsize=31)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=7, maxsize=128, currsize=7)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=85, maxsize=4096, currsize=85)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=8, maxsize=128, currsize=8)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=89, maxsize=4096, currsize=89)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=9, maxsize=128, currsize=9)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=90, maxsize=4096, currsize=90)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=10, maxsize=128, currsize=10)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=94, maxsize=4096, currsize=94)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=11, maxsize=128, currsize=11)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=99, maxsize=4096, currsize=99)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=12, maxsize=128, currsize=12)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=104, maxsize=4096, currsize=104)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=109, maxsize=4096, currsize=109)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=14, maxsize=128, currsize=14)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=114, maxsize=4096, currsize=114)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=15, maxsize=128, currsize=15)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=116, maxsize=4096, currsize=116)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=16, maxsize=128, currsize=16)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=119, maxsize=4096, currsize=119)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=17, maxsize=128, currsize=17)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=123, maxsize=4096, currsize=123)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=18, maxsize=128, currsize=18)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=132, maxsize=4096, currsize=132)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=19, maxsize=128, currsize=19)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=141, maxsize=4096, currsize=141)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=20, maxsize=128, currsize=20)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=19, maxsize=128, currsize=19)\n",
      "0.1642285878545139\n",
      "0.3357714121454861\n",
      "True\n",
      "----------\n",
      "0.25\n",
      "factorize_layer.cache_info() = CacheInfo(hits=47, misses=145, maxsize=4096, currsize=145)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=21, maxsize=128, currsize=21)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=48, misses=149, maxsize=4096, currsize=149)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=22, maxsize=128, currsize=22)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=49, misses=152, maxsize=4096, currsize=152)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=23, maxsize=128, currsize=23)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=50, misses=155, maxsize=4096, currsize=155)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=24, maxsize=128, currsize=24)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=51, misses=159, maxsize=4096, currsize=159)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=25, maxsize=128, currsize=25)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=53, misses=162, maxsize=4096, currsize=162)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=26, maxsize=128, currsize=26)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=153, misses=162, maxsize=4096, currsize=162)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=26, maxsize=128, currsize=26)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=155, misses=166, maxsize=4096, currsize=166)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=27, maxsize=128, currsize=27)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=156, misses=170, maxsize=4096, currsize=170)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=28, maxsize=128, currsize=28)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=157, misses=174, maxsize=4096, currsize=174)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=29, maxsize=128, currsize=29)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=158, misses=178, maxsize=4096, currsize=178)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=30, maxsize=128, currsize=30)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=209, misses=227, maxsize=4096, currsize=227)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=210, misses=231, maxsize=4096, currsize=231)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=32, maxsize=128, currsize=32)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=211, misses=234, maxsize=4096, currsize=234)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=33, maxsize=128, currsize=33)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=212, misses=237, maxsize=4096, currsize=237)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=34, maxsize=128, currsize=34)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=213, misses=239, maxsize=4096, currsize=239)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=35, maxsize=128, currsize=35)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=261, misses=291, maxsize=4096, currsize=291)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=36, maxsize=128, currsize=36)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=263, misses=293, maxsize=4096, currsize=293)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=37, maxsize=128, currsize=37)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=265, misses=293, maxsize=4096, currsize=293)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=38, maxsize=128, currsize=38)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=38, maxsize=128, currsize=38)\n",
      "0.5726003005916791\n",
      "-0.0726003005916791\n",
      "True\n",
      "----------\n",
      "0.375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=266, misses=293, maxsize=4096, currsize=293)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=39, maxsize=128, currsize=39)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=268, misses=296, maxsize=4096, currsize=296)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=40, maxsize=128, currsize=40)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=270, misses=298, maxsize=4096, currsize=298)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=41, maxsize=128, currsize=41)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=272, misses=302, maxsize=4096, currsize=302)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=42, maxsize=128, currsize=42)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=274, misses=303, maxsize=4096, currsize=303)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=43, maxsize=128, currsize=43)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=276, misses=303, maxsize=4096, currsize=303)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=44, maxsize=128, currsize=44)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=376, misses=303, maxsize=4096, currsize=303)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=44, maxsize=128, currsize=44)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=379, misses=305, maxsize=4096, currsize=305)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=45, maxsize=128, currsize=45)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=381, misses=305, maxsize=4096, currsize=305)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=46, maxsize=128, currsize=46)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=383, misses=307, maxsize=4096, currsize=307)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=47, maxsize=128, currsize=47)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=385, misses=310, maxsize=4096, currsize=310)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=48, maxsize=128, currsize=48)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=485, misses=310, maxsize=4096, currsize=310)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=48, maxsize=128, currsize=48)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=487, misses=313, maxsize=4096, currsize=313)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=49, maxsize=128, currsize=49)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=488, misses=313, maxsize=4096, currsize=313)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=50, maxsize=128, currsize=50)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=489, misses=313, maxsize=4096, currsize=313)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=51, maxsize=128, currsize=51)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=491, misses=315, maxsize=4096, currsize=315)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=52, maxsize=128, currsize=52)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=497, misses=315, maxsize=4096, currsize=315)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=53, maxsize=128, currsize=53)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=501, misses=315, maxsize=4096, currsize=315)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=54, maxsize=128, currsize=54)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=506, misses=315, maxsize=4096, currsize=315)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=55, maxsize=128, currsize=55)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=57, maxsize=128, currsize=57)\n",
      "0.31063529659399236\n",
      "0.18936470340600764\n",
      "True\n",
      "----------\n",
      "0.3125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=508, misses=316, maxsize=4096, currsize=316)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=56, maxsize=128, currsize=56)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=511, misses=318, maxsize=4096, currsize=318)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=57, maxsize=128, currsize=57)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=514, misses=320, maxsize=4096, currsize=320)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=58, maxsize=128, currsize=58)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=517, misses=321, maxsize=4096, currsize=321)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=59, maxsize=128, currsize=59)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=520, misses=323, maxsize=4096, currsize=323)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=60, maxsize=128, currsize=60)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=523, misses=323, maxsize=4096, currsize=323)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=61, maxsize=128, currsize=61)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=623, misses=323, maxsize=4096, currsize=323)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=61, maxsize=128, currsize=61)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=627, misses=324, maxsize=4096, currsize=324)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=62, maxsize=128, currsize=62)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=630, misses=324, maxsize=4096, currsize=324)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=63, maxsize=128, currsize=63)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=633, misses=325, maxsize=4096, currsize=325)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=64, maxsize=128, currsize=64)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=636, misses=327, maxsize=4096, currsize=327)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=65, maxsize=128, currsize=65)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=736, misses=327, maxsize=4096, currsize=327)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=65, maxsize=128, currsize=65)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=739, misses=329, maxsize=4096, currsize=329)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=66, maxsize=128, currsize=66)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=741, misses=332, maxsize=4096, currsize=332)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=67, maxsize=128, currsize=67)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=743, misses=335, maxsize=4096, currsize=335)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=68, maxsize=128, currsize=68)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=746, misses=336, maxsize=4096, currsize=336)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=69, maxsize=128, currsize=69)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=846, misses=336, maxsize=4096, currsize=336)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=69, maxsize=128, currsize=69)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=849, misses=338, maxsize=4096, currsize=338)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=70, maxsize=128, currsize=70)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=853, misses=339, maxsize=4096, currsize=339)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=71, maxsize=128, currsize=71)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=76, maxsize=128, currsize=76)\n",
      "0.41896347956078606\n",
      "0.08103652043921394\n",
      "True\n",
      "----------\n",
      "0.28125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=856, misses=341, maxsize=4096, currsize=341)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=72, maxsize=128, currsize=72)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=860, misses=342, maxsize=4096, currsize=342)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=73, maxsize=128, currsize=73)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=863, misses=342, maxsize=4096, currsize=342)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=74, maxsize=128, currsize=74)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=866, misses=342, maxsize=4096, currsize=342)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=75, maxsize=128, currsize=75)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=870, misses=343, maxsize=4096, currsize=343)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=76, maxsize=128, currsize=76)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=874, misses=345, maxsize=4096, currsize=345)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=77, maxsize=128, currsize=77)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=974, misses=345, maxsize=4096, currsize=345)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=77, maxsize=128, currsize=77)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=978, misses=345, maxsize=4096, currsize=345)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=78, maxsize=128, currsize=78)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=982, misses=346, maxsize=4096, currsize=346)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=79, maxsize=128, currsize=79)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=986, misses=347, maxsize=4096, currsize=347)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=80, maxsize=128, currsize=80)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=990, misses=348, maxsize=4096, currsize=348)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=81, maxsize=128, currsize=81)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1090, misses=348, maxsize=4096, currsize=348)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=81, maxsize=128, currsize=81)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1094, misses=349, maxsize=4096, currsize=349)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=82, maxsize=128, currsize=82)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1096, misses=349, maxsize=4096, currsize=349)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=83, maxsize=128, currsize=83)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1098, misses=349, maxsize=4096, currsize=349)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=84, maxsize=128, currsize=84)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1101, misses=350, maxsize=4096, currsize=350)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=85, maxsize=128, currsize=85)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1201, misses=350, maxsize=4096, currsize=350)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=85, maxsize=128, currsize=85)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1203, misses=350, maxsize=4096, currsize=350)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=86, maxsize=128, currsize=86)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1206, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=87, maxsize=128, currsize=87)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=95, maxsize=128, currsize=95)\n",
      "0.5105706462935886\n",
      "-0.010570646293588615\n",
      "True\n",
      "----------\n",
      "0.296875\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1210, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=88, maxsize=128, currsize=88)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1214, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=89, maxsize=128, currsize=89)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1218, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=90, maxsize=128, currsize=90)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1221, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=10, misses=90, maxsize=128, currsize=90)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1225, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=10, misses=91, maxsize=128, currsize=91)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1230, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=10, misses=92, maxsize=128, currsize=92)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1330, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=11, misses=92, maxsize=128, currsize=92)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1335, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=12, misses=92, maxsize=128, currsize=92)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1338, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=13, misses=92, maxsize=128, currsize=92)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1341, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=13, misses=93, maxsize=128, currsize=93)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1345, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=13, misses=94, maxsize=128, currsize=94)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1445, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=94, maxsize=128, currsize=94)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1449, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=95, maxsize=128, currsize=95)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1453, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=96, maxsize=128, currsize=96)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1457, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=97, maxsize=128, currsize=97)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1458, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=98, maxsize=128, currsize=98)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1558, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=15, misses=98, maxsize=128, currsize=98)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1562, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=15, misses=99, maxsize=128, currsize=99)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1565, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=15, misses=100, maxsize=128, currsize=100)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=114, maxsize=128, currsize=114)\n",
      "0.4561298848161467\n",
      "0.04387011518385331\n",
      "True\n",
      "----------\n",
      "0.2890625\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1569, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=16, misses=100, maxsize=128, currsize=100)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1573, misses=351, maxsize=4096, currsize=351)\n",
      "count_parameters.cache_info() = CacheInfo(hits=17, misses=100, maxsize=128, currsize=100)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1577, misses=352, maxsize=4096, currsize=352)\n",
      "count_parameters.cache_info() = CacheInfo(hits=17, misses=101, maxsize=128, currsize=101)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1580, misses=352, maxsize=4096, currsize=352)\n",
      "count_parameters.cache_info() = CacheInfo(hits=18, misses=101, maxsize=128, currsize=101)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1585, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=18, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1590, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=19, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1690, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=20, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1694, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=21, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1699, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=22, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1702, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=23, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1707, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=24, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1807, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=25, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1811, misses=353, maxsize=4096, currsize=353)\n",
      "count_parameters.cache_info() = CacheInfo(hits=26, misses=102, maxsize=128, currsize=102)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1815, misses=354, maxsize=4096, currsize=354)\n",
      "count_parameters.cache_info() = CacheInfo(hits=26, misses=103, maxsize=128, currsize=103)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1819, misses=355, maxsize=4096, currsize=355)\n",
      "count_parameters.cache_info() = CacheInfo(hits=26, misses=104, maxsize=128, currsize=104)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1820, misses=355, maxsize=4096, currsize=355)\n",
      "count_parameters.cache_info() = CacheInfo(hits=27, misses=104, maxsize=128, currsize=104)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1920, misses=355, maxsize=4096, currsize=355)\n",
      "count_parameters.cache_info() = CacheInfo(hits=28, misses=104, maxsize=128, currsize=104)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1924, misses=355, maxsize=4096, currsize=355)\n",
      "count_parameters.cache_info() = CacheInfo(hits=29, misses=104, maxsize=128, currsize=104)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1928, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=29, misses=105, maxsize=128, currsize=105)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=133, maxsize=128, currsize=128)\n",
      "0.46988373506192344\n",
      "0.030116264938076565\n",
      "True\n",
      "----------\n",
      "0.28515625\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1932, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=30, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1937, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=31, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1942, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=32, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1945, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=33, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1950, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=34, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1955, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=35, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2055, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=36, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2059, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=37, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2064, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=38, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2067, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=39, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2072, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=40, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2172, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=41, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2177, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=42, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2179, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=43, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2181, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=44, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2185, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=45, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2285, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=46, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2289, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=47, misses=105, maxsize=128, currsize=105)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2293, misses=356, maxsize=4096, currsize=356)\n",
      "count_parameters.cache_info() = CacheInfo(hits=48, misses=105, maxsize=128, currsize=105)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=152, maxsize=128, currsize=128)\n",
      "0.4962715999929121\n",
      "0.0037284000070879064\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# with caching find_rank_given_error, count_parameters, factorize_layers\n",
    "ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1699150/1395079106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_error_given_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/dbs.py\u001b[0m in \u001b[0;36mfind_error_given_c\u001b[0;34m(layers, desired_c, error, tollerance, max_error, min_error, max_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0machieved_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_layers_with_desired_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtollerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from tddl.dbs import find_error_given_c\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n",
    "ranks, c, error = find_error_given_c(layers, desired_c = 0.5, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "rank = 0.5\n",
    "errors = np.array([])\n",
    "for layer in layers:\n",
    "    with torch.no_grad():\n",
    "        fact_layer, error = factorize_layer(layer[2], 'tucker', rank, return_error=True)\n",
    "    errors = np.append(errors, float(error.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = errors.mean()\n",
    "max_error = errors.max()\n",
    "min_error = errors.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35240626633167266\n",
      "-0.41636698440207964\n",
      "0.9163669844020796\n",
      "True\n",
      "----------\n",
      "0.4085878893733025\n",
      "-0.1684683708838821\n",
      "0.6684683708838821\n",
      "True\n",
      "----------\n",
      "0.43667870089411737\n",
      "-0.07165294627383023\n",
      "0.5716529462738302\n",
      "True\n",
      "----------\n",
      "0.4507241066545248\n",
      "0.0006878249566724115\n",
      "0.4993121750433276\n",
      "True\n",
      "----------\n",
      "0.4577468095347285\n",
      "0.035934792027729645\n",
      "0.46406520797227035\n",
      "True\n",
      "----------\n",
      "0.4612581609748304\n",
      "0.043224653379549394\n",
      "0.4567753466204506\n",
      "True\n",
      "----------\n",
      "0.46301383669488133\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46389167455490676\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4643305934849195\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4645500529499259\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4646597826824291\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46471464754868064\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46474207998180644\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647557961983694\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647626543066508\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647660833607915\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647677978878619\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647686551513971\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476908378316467\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476929809904843\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476940525699034\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694588359613\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694856254468\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647694990201895\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476950571756087\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695090662466\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695107405894\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695115777608\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951199634653\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695122056394\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951231028585\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951236260905\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695123887706\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951240185144\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124083918\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241166203\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124132971\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124141147\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241452347\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241472786\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241483005\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124148812\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149067\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149195\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241492587\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241492903\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493064\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149315\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493186\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493203\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493214\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.4647695124149322\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n",
      "0.06800259965337951\n",
      "0.4319974003466205\n",
      "True\n",
      "----------\n",
      "0.46476951241493225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_406364/2323451973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_error_given_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_406364/2046359927.py\u001b[0m in \u001b[0;36mfind_error_given_c\u001b[0;34m(layers, desired_c, error, tollerance, max_error, min_error, max_iter, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_layers_with_desired_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtollerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_c\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_406364/3590224019.py\u001b[0m in \u001b[0;36mcompress_layers_with_desired_error\u001b[0;34m(layers, desired_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mparam_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfact_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_rank_given_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesired_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfact_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfact_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_406364/1777859090.py\u001b[0m in \u001b[0;36mfind_rank_given_error\u001b[0;34m(layer, desired_error, rank, tollerance, max_rank, min_rank, max_iter)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print(rank)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfact_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tucker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# print(error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_error\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtollerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/src/tddl/factorizations.py\u001b[0m in \u001b[0;36mfactorize_layer\u001b[0;34m(module, factorization, rank, decompose_weights, init_std, return_error, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         fact_module = tltorch.FactorizedConv.from_conv(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_layers/factorized_convolution.py\u001b[0m in \u001b[0;36mfrom_conv\u001b[0;34m(cls, conv_layer, rank, implementation, factorization, decompose_weights, decomposition_kwargs, fixed_rank_modes, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mkernel_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecomposition_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tltorch/tltorch/factorized_tensors/factorized_tensors.py\u001b[0m in \u001b[0;36minit_from_tensor\u001b[0;34m(self, tensor, unsqueezed_modes, unsqueezed_init, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0munsqueezed_modes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, fixed_factors, n_iter_max, init, svd, tol, random_state, mask, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tucker_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         core, factors = partial_tucker(tensor, modes, rank=rank, n_iter_max=n_iter_max, init=init,\n\u001b[0m\u001b[1;32m    206\u001b[0m                             svd=svd, tol=tol, random_state=random_state, mask=mask, verbose=verbose)\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTuckerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mcore_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mfull_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_eigenvecs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_eigenvecs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;31m# If n_eigenvecs == min_dim, we don't want full_matrices=True, it's super slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[1;32m    126\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "find_error_given_c(layers, desired_c = 0.5, error=error, max_error=max_error, min_error=min_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48aac2a9a49c39ebb4503a423316524ff978d67c54926a1d8595b999b29100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
