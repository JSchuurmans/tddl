{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tltorch/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n",
      "  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 38,\n",
       " 'best_train_acc': 0.9749333333333333,\n",
       " 'best_valid_acc': 0.9078,\n",
       " 'best_valid_loss': 0.003568341651931405,\n",
       " 'test_acc': 0.891,\n",
       " 'test_loss': 0.004007616302371025,\n",
       " 'n_param': 557642,\n",
       " 'model_name': 'gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "baseline_path = Path(\"/bigdata/cifar10/logs/garipov/baselines/1647358615/gar_18_dNone_128_sgd_l0.1_g0.1_w0.0_sTrue\")\n",
    "baseline_model = torch.load(baseline_path / \"cnn_best.pth\")\n",
    "with open(baseline_path/'results.json') as json_file:\n",
    "    baseline_result = json.load(json_file)\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaripovNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=6, maxsize=4096, currsize=6)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=2, maxsize=128, currsize=2)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=11, maxsize=4096, currsize=11)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=3, maxsize=128, currsize=3)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=15, maxsize=4096, currsize=15)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=4, maxsize=128, currsize=4)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=18, maxsize=4096, currsize=18)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=5, maxsize=128, currsize=5)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=0, misses=26, maxsize=4096, currsize=26)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=6, maxsize=128, currsize=6)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=5, maxsize=128, currsize=5)\n",
      "0.2735034305163528\n",
      "0.22649656948364721\n",
      "True\n",
      "----------\n",
      "0.25\n",
      "factorize_layer.cache_info() = CacheInfo(hits=1, misses=29, maxsize=4096, currsize=29)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=7, maxsize=128, currsize=7)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=2, misses=30, maxsize=4096, currsize=30)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=8, maxsize=128, currsize=8)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=3, misses=34, maxsize=4096, currsize=34)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=9, maxsize=128, currsize=9)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=4, misses=36, maxsize=4096, currsize=36)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=10, maxsize=128, currsize=10)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=6, misses=36, maxsize=4096, currsize=36)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=11, maxsize=128, currsize=11)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=10, maxsize=128, currsize=10)\n",
      "0.6774041410080303\n",
      "-0.17740414100803026\n",
      "True\n",
      "----------\n",
      "0.375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=8, misses=37, maxsize=4096, currsize=37)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=12, maxsize=128, currsize=12)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=11, misses=39, maxsize=4096, currsize=39)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=13, maxsize=128, currsize=13)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=13, misses=42, maxsize=4096, currsize=42)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=14, maxsize=128, currsize=14)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=15, misses=44, maxsize=4096, currsize=44)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=15, maxsize=128, currsize=15)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=19, misses=44, maxsize=4096, currsize=44)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=16, maxsize=128, currsize=16)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=15, maxsize=128, currsize=15)\n",
      "0.4269280290939348\n",
      "0.07307197090606521\n",
      "True\n",
      "----------\n",
      "0.3125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=20, misses=44, maxsize=4096, currsize=44)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=17, maxsize=128, currsize=17)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=22, misses=45, maxsize=4096, currsize=45)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=18, maxsize=128, currsize=18)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=25, misses=47, maxsize=4096, currsize=47)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=19, maxsize=128, currsize=19)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=28, misses=49, maxsize=4096, currsize=49)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=20, maxsize=128, currsize=20)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=32, misses=51, maxsize=4096, currsize=51)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=21, maxsize=128, currsize=21)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=20, maxsize=128, currsize=20)\n",
      "0.5415122964195667\n",
      "-0.04151229641956666\n",
      "True\n",
      "----------\n",
      "0.34375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=35, misses=52, maxsize=4096, currsize=52)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=22, maxsize=128, currsize=22)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=38, misses=54, maxsize=4096, currsize=54)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=23, maxsize=128, currsize=23)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=42, misses=55, maxsize=4096, currsize=55)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=24, maxsize=128, currsize=24)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=46, misses=56, maxsize=4096, currsize=56)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=25, maxsize=128, currsize=25)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=51, misses=57, maxsize=4096, currsize=57)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=26, maxsize=128, currsize=26)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=25, maxsize=128, currsize=25)\n",
      "0.48262146681921375\n",
      "0.01737853318078625\n",
      "True\n",
      "----------\n",
      "0.328125\n",
      "factorize_layer.cache_info() = CacheInfo(hits=55, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=27, maxsize=128, currsize=27)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=59, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=28, maxsize=128, currsize=28)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=61, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=29, maxsize=128, currsize=29)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=65, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=30, maxsize=128, currsize=30)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=70, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=0, misses=31, maxsize=128, currsize=31)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=30, maxsize=128, currsize=30)\n",
      "0.5128182597437065\n",
      "-0.01281825974370654\n",
      "True\n",
      "----------\n",
      "0.3359375\n",
      "factorize_layer.cache_info() = CacheInfo(hits=74, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=1, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=78, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=2, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=80, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=3, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=85, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=4, misses=31, maxsize=128, currsize=31)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=90, misses=58, maxsize=4096, currsize=58)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=31, maxsize=128, currsize=31)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=35, maxsize=128, currsize=35)\n",
      "0.5011727954494102\n",
      "-0.00117279544941018\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tddl.utils.model_stats import count_parameters\n",
    "from tddl.factorizations import number_layers, listify_numbered_layers, get_weights\n",
    "from tddl.dbs import find_error_given_c\n",
    "\n",
    "baseline_count = count_parameters(baseline_model)\n",
    "model = copy.deepcopy(baseline_model)\n",
    "gar_layers = [2,4,6,8,10]\n",
    "rank = 0.5\n",
    "\n",
    "numbered_layers = number_layers(model)\n",
    "listed_layers = listify_numbered_layers(numbered_layers, layer_nrs=gar_layers)\n",
    "rank, c, error = find_error_given_c(listed_layers, desired_c = rank, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do constant compression\n",
    "\n",
    "# get the approximation error\n",
    "\n",
    "# get the min and max of the approximation error\n",
    "\n",
    "# set min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tddl.factorizations import number_layers, listify_numbered_layers, get_weights\n",
    "\n",
    "numbered_layers = number_layers(baseline_model)\n",
    "gar_layers = [2,4,6,8,10]\n",
    "layers = listify_numbered_layers(numbered_layers, layer_nrs=gar_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tddl.factorizations import factorize_layer\n",
    "\n",
    "DESIRED_COMPRESSION = 0.5\n",
    "\n",
    "rank = DESIRED_COMPRESSION\n",
    "errors = np.array([])\n",
    "for layer in layers:\n",
    "    with torch.no_grad():\n",
    "        fact_layer, error = factorize_layer(layer[2], 'tucker', rank, return_error=True)\n",
    "    errors = np.append(errors, float(error.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31196895, 0.36436999, 0.46476951, 0.42094678, 0.1999761 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = errors.mean()\n",
    "max_error = errors.max()\n",
    "min_error = errors.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35240626633167266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35240626633167266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jetzeschuurman/gitProjects/phd/tddl/venv/lib/python3.8/site-packages/tensorly/backend/core.py:885: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n",
      "  warnings.warn('In partial_svd: converting to NumPy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize_layer.cache_info() = CacheInfo(hits=91, misses=66, maxsize=4096, currsize=66)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=32, maxsize=128, currsize=32)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=92, misses=70, maxsize=4096, currsize=70)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=33, maxsize=128, currsize=33)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=93, misses=73, maxsize=4096, currsize=73)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=34, maxsize=128, currsize=34)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=94, misses=75, maxsize=4096, currsize=75)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=35, maxsize=128, currsize=35)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=95, misses=80, maxsize=4096, currsize=80)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=36, maxsize=128, currsize=36)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=5, maxsize=128, currsize=5)\n",
      "0.46897113201659846\n",
      "0.031028867983401542\n",
      "True\n",
      "----------\n",
      "0.276191183924675\n",
      "factorize_layer.cache_info() = CacheInfo(hits=96, misses=84, maxsize=4096, currsize=84)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=37, maxsize=128, currsize=37)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=99, misses=85, maxsize=4096, currsize=85)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=38, maxsize=128, currsize=38)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=101, misses=86, maxsize=4096, currsize=86)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=39, maxsize=128, currsize=39)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=103, misses=88, maxsize=4096, currsize=88)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=40, maxsize=128, currsize=40)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=106, misses=89, maxsize=4096, currsize=89)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=41, maxsize=128, currsize=41)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=10, maxsize=128, currsize=10)\n",
      "0.6264198177325238\n",
      "-0.12641981773252375\n",
      "True\n",
      "----------\n",
      "0.3142987251281738\n",
      "factorize_layer.cache_info() = CacheInfo(hits=107, misses=89, maxsize=4096, currsize=89)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=42, maxsize=128, currsize=42)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=110, misses=89, maxsize=4096, currsize=89)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=43, maxsize=128, currsize=43)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=113, misses=91, maxsize=4096, currsize=91)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=44, maxsize=128, currsize=44)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=116, misses=92, maxsize=4096, currsize=92)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=45, maxsize=128, currsize=45)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=121, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=5, misses=46, maxsize=128, currsize=46)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=15, maxsize=128, currsize=15)\n",
      "0.5345257351490741\n",
      "-0.03452573514907409\n",
      "True\n",
      "----------\n",
      "0.3333524957299232\n",
      "factorize_layer.cache_info() = CacheInfo(hits=125, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=46, maxsize=128, currsize=46)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=129, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=47, maxsize=128, currsize=47)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=131, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=6, misses=48, maxsize=128, currsize=48)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=135, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=48, maxsize=128, currsize=48)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=140, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=7, misses=49, maxsize=128, currsize=49)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=20, maxsize=128, currsize=20)\n",
      "0.5114105465513716\n",
      "-0.011410546551371636\n",
      "True\n",
      "----------\n",
      "0.34287938103079796\n",
      "factorize_layer.cache_info() = CacheInfo(hits=144, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=8, misses=49, maxsize=128, currsize=49)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=149, misses=93, maxsize=4096, currsize=93)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=49, maxsize=128, currsize=49)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=153, misses=94, maxsize=4096, currsize=94)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=50, maxsize=128, currsize=50)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=157, misses=95, maxsize=4096, currsize=95)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=51, maxsize=128, currsize=51)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=163, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=9, misses=52, maxsize=128, currsize=52)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=25, maxsize=128, currsize=25)\n",
      "0.4851535573002034\n",
      "0.014846442699796625\n",
      "True\n",
      "----------\n",
      "0.3381159383803606\n",
      "factorize_layer.cache_info() = CacheInfo(hits=167, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=10, misses=52, maxsize=128, currsize=52)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=171, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=11, misses=52, maxsize=128, currsize=52)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=173, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=12, misses=52, maxsize=128, currsize=52)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=178, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=13, misses=52, maxsize=128, currsize=52)\n",
      "factorize_layer.cache_info() = CacheInfo(hits=183, misses=96, maxsize=4096, currsize=96)\n",
      "count_parameters.cache_info() = CacheInfo(hits=14, misses=52, maxsize=128, currsize=52)\n",
      "find_rank_given_error.cache_info() = CacheInfo(hits=0, misses=30, maxsize=128, currsize=30)\n",
      "0.5011727954494102\n",
      "-0.00117279544941018\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.4375, 0.5625, 0.75, 0.65625, 0.09375],\n",
       " 0.5011727954494102,\n",
       " tensor(0.3323, device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_error_given_c(layers, desired_c = DESIRED_COMPRESSION, error=error, max_error=max_error, min_error=min_error, baseline_count=baseline_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48aac2a9a49c39ebb4503a423316524ff978d67c54926a1d8595b999b29100c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
